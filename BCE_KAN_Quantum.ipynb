{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pennylane\n",
      "  Using cached PennyLane-0.36.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: numpy<2.0 in c:\\users\\pad33\\anaconda3\\envs\\kan\\lib\\site-packages (from pennylane) (1.26.4)\n",
      "Collecting scipy (from pennylane)\n",
      "  Using cached scipy-1.13.0-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: networkx in c:\\users\\pad33\\anaconda3\\envs\\kan\\lib\\site-packages (from pennylane) (3.3)\n",
      "Collecting rustworkx (from pennylane)\n",
      "  Using cached rustworkx-0.14.2-cp310-cp310-win_amd64.whl.metadata (10 kB)\n",
      "Collecting autograd (from pennylane)\n",
      "  Using cached autograd-1.6.2-py3-none-any.whl.metadata (706 bytes)\n",
      "Requirement already satisfied: toml in c:\\users\\pad33\\anaconda3\\envs\\kan\\lib\\site-packages (from pennylane) (0.10.2)\n",
      "Requirement already satisfied: appdirs in c:\\users\\pad33\\anaconda3\\envs\\kan\\lib\\site-packages (from pennylane) (1.4.4)\n",
      "Requirement already satisfied: semantic-version>=2.7 in c:\\users\\pad33\\anaconda3\\envs\\kan\\lib\\site-packages (from pennylane) (2.10.0)\n",
      "Requirement already satisfied: autoray>=0.6.1 in c:\\users\\pad33\\anaconda3\\envs\\kan\\lib\\site-packages (from pennylane) (0.6.10)\n",
      "Requirement already satisfied: cachetools in c:\\users\\pad33\\anaconda3\\envs\\kan\\lib\\site-packages (from pennylane) (5.3.3)\n",
      "Collecting pennylane-lightning>=0.36 (from pennylane)\n",
      "  Using cached PennyLane_Lightning-0.36.0-cp310-cp310-win_amd64.whl.metadata (21 kB)\n",
      "Collecting requests (from pennylane)\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\pad33\\anaconda3\\envs\\kan\\lib\\site-packages (from pennylane) (4.11.0)\n",
      "Requirement already satisfied: future>=0.15.2 in c:\\users\\pad33\\anaconda3\\envs\\kan\\lib\\site-packages (from autograd->pennylane) (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pad33\\anaconda3\\envs\\kan\\lib\\site-packages (from requests->pennylane) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pad33\\anaconda3\\envs\\kan\\lib\\site-packages (from requests->pennylane) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pad33\\anaconda3\\envs\\kan\\lib\\site-packages (from requests->pennylane) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pad33\\anaconda3\\envs\\kan\\lib\\site-packages (from requests->pennylane) (2024.2.2)\n",
      "Using cached PennyLane-0.36.0-py3-none-any.whl (1.7 MB)\n",
      "Using cached PennyLane_Lightning-0.36.0-cp310-cp310-win_amd64.whl (5.6 MB)\n",
      "Using cached autograd-1.6.2-py3-none-any.whl (49 kB)\n",
      "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Using cached rustworkx-0.14.2-cp310-cp310-win_amd64.whl (1.6 MB)\n",
      "Using cached scipy-1.13.0-cp310-cp310-win_amd64.whl (46.2 MB)\n",
      "Installing collected packages: scipy, rustworkx, requests, autograd, pennylane-lightning, pennylane\n",
      "Successfully installed autograd-1.6.2 pennylane-0.36.0 pennylane-lightning-0.36.0 requests-2.31.0 rustworkx-0.14.2 scipy-1.13.0\n",
      "Collecting pykan\n",
      "  Using cached pykan-0.0.5-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached pykan-0.0.5-py3-none-any.whl (33 kB)\n",
      "Installing collected packages: pykan\n",
      "Successfully installed pykan-0.0.5\n",
      "Collecting torch\n",
      "  Downloading torch-2.3.0-cp310-cp310-win_amd64.whl.metadata (26 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\pad33\\anaconda3\\envs\\kan\\lib\\site-packages (from torch) (4.11.0)\n",
      "Collecting sympy (from torch)\n",
      "  Using cached sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in c:\\users\\pad33\\anaconda3\\envs\\kan\\lib\\site-packages (from torch) (3.3)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting mkl<=2021.4.0,>=2021.1.1 (from torch)\n",
      "  Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.4 kB)\n",
      "Collecting intel-openmp==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch)\n",
      "  Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting tbb==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch)\n",
      "  Using cached tbb-2021.12.0-py3-none-win_amd64.whl.metadata (1.1 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Downloading MarkupSafe-2.1.5-cp310-cp310-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting mpmath>=0.19 (from sympy->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading torch-2.3.0-cp310-cp310-win_amd64.whl (159.8 MB)\n",
      "   ---------------------------------------- 0.0/159.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/159.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/159.8 MB 7.6 MB/s eta 0:00:21\n",
      "   ---------------------------------------- 1.4/159.8 MB 12.4 MB/s eta 0:00:13\n",
      "    --------------------------------------- 2.7/159.8 MB 19.4 MB/s eta 0:00:09\n",
      "    --------------------------------------- 3.3/159.8 MB 17.6 MB/s eta 0:00:09\n",
      "    --------------------------------------- 3.4/159.8 MB 14.6 MB/s eta 0:00:11\n",
      "    --------------------------------------- 3.7/159.8 MB 13.1 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 4.4/159.8 MB 13.5 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 5.4/159.8 MB 14.5 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 5.9/159.8 MB 14.0 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 7.6/159.8 MB 16.2 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 9.4/159.8 MB 18.3 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 12.1/159.8 MB 24.2 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 14.7/159.8 MB 38.5 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 17.4/159.8 MB 54.4 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 19.0/159.8 MB 59.5 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 19.1/159.8 MB 43.5 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 19.3/159.8 MB 36.3 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 19.6/159.8 MB 31.2 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 21.4/159.8 MB 29.8 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 23.9/159.8 MB 29.7 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 26.5/159.8 MB 31.2 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 29.1/159.8 MB 31.2 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 31.7/159.8 MB 59.5 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 34.2/159.8 MB 59.5 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 36.8/159.8 MB 59.5 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 39.5/159.8 MB 59.5 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 42.0/159.8 MB 54.4 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 44.6/159.8 MB 54.4 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 47.3/159.8 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 49.9/159.8 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 52.6/159.8 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 55.2/159.8 MB 59.8 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 57.9/159.8 MB 59.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 60.5/159.8 MB 59.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 63.1/159.8 MB 59.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 65.0/159.8 MB 50.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 67.6/159.8 MB 54.7 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 70.3/159.8 MB 54.7 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 72.9/159.8 MB 54.4 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 75.6/159.8 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 77.5/159.8 MB 54.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 80.1/159.8 MB 54.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 82.8/159.8 MB 54.7 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 85.4/159.8 MB 54.7 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 88.1/159.8 MB 59.5 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 90.7/159.8 MB 59.8 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 93.3/159.8 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 96.0/159.8 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 98.6/159.8 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------------------ -------------- 101.3/159.8 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------- ------------- 103.9/159.8 MB 59.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------ 106.6/159.8 MB 59.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------ 109.2/159.8 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------- ----------- 111.8/159.8 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------- ----------- 114.5/159.8 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ---------- 117.1/159.8 MB 59.5 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 119.8/159.8 MB 59.8 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 122.4/159.8 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------ -------- 125.0/159.8 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 127.6/159.8 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 130.3/159.8 MB 59.5 MB/s eta 0:00:01\n",
      "   -------------------------------- ------ 132.9/159.8 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 135.6/159.8 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 138.0/159.8 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 140.1/159.8 MB 54.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 142.2/159.8 MB 50.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 144.1/159.8 MB 46.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 145.0/159.8 MB 40.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 147.1/159.8 MB 40.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 149.2/159.8 MB 40.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 151.7/159.8 MB 43.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 153.8/159.8 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  155.8/159.8 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  158.1/159.8 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 50.4 MB/s eta 0:00:01\n",
      "   --------------------------------------- 159.8/159.8 MB 11.9 MB/s eta 0:00:00\n",
      "Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl (228.5 MB)\n",
      "Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl (3.5 MB)\n",
      "Using cached tbb-2021.12.0-py3-none-win_amd64.whl (286 kB)\n",
      "Using cached filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Using cached fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Downloading MarkupSafe-2.1.5-cp310-cp310-win_amd64.whl (17 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: tbb, mpmath, intel-openmp, sympy, mkl, MarkupSafe, fsspec, filelock, jinja2, torch\n",
      "Successfully installed MarkupSafe-2.1.5 filelock-3.14.0 fsspec-2024.3.1 intel-openmp-2021.4.0 jinja2-3.1.4 mkl-2021.4.0 mpmath-1.3.0 sympy-1.12 tbb-2021.12.0 torch-2.3.0\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py egg_info did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [15 lines of output]\n",
      "      The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "      rather than 'sklearn' for pip commands.\n",
      "      \n",
      "      Here is how to fix this error in the main use cases:\n",
      "      - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "      - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "        (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "      - if the 'sklearn' package is used by one of your dependencies,\n",
      "        it would be great if you take some time to track which package uses\n",
      "        'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "      - as a last resort, set the environment variable\n",
      "        SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "      \n",
      "      More information is available at\n",
      "      https://github.com/scikit-learn/sklearn-pypi-package\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchvision\n",
      "  Downloading torchvision-0.18.0-cp310-cp310-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\pad33\\anaconda3\\envs\\kan\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.3.0 in c:\\users\\pad33\\anaconda3\\envs\\kan\\lib\\site-packages (from torchvision) (2.3.0)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Downloading pillow-10.3.0-cp310-cp310-win_amd64.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\pad33\\anaconda3\\envs\\kan\\lib\\site-packages (from torch==2.3.0->torchvision) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\pad33\\anaconda3\\envs\\kan\\lib\\site-packages (from torch==2.3.0->torchvision) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\pad33\\anaconda3\\envs\\kan\\lib\\site-packages (from torch==2.3.0->torchvision) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\pad33\\anaconda3\\envs\\kan\\lib\\site-packages (from torch==2.3.0->torchvision) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\pad33\\anaconda3\\envs\\kan\\lib\\site-packages (from torch==2.3.0->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\pad33\\anaconda3\\envs\\kan\\lib\\site-packages (from torch==2.3.0->torchvision) (2024.3.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\pad33\\anaconda3\\envs\\kan\\lib\\site-packages (from torch==2.3.0->torchvision) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\pad33\\anaconda3\\envs\\kan\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.0->torchvision) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\pad33\\anaconda3\\envs\\kan\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch==2.3.0->torchvision) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\pad33\\anaconda3\\envs\\kan\\lib\\site-packages (from jinja2->torch==2.3.0->torchvision) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\pad33\\anaconda3\\envs\\kan\\lib\\site-packages (from sympy->torch==2.3.0->torchvision) (1.3.0)\n",
      "Downloading torchvision-0.18.0-cp310-cp310-win_amd64.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.1/1.2 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.6/1.2 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.2/1.2 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.2/1.2 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.2/1.2 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.2/1.2 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.2/1.2 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.2/1.2 MB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 2.9 MB/s eta 0:00:00\n",
      "Downloading pillow-10.3.0-cp310-cp310-win_amd64.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 1.2/2.5 MB 36.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.5/2.5 MB 32.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 26.8 MB/s eta 0:00:00\n",
      "Installing collected packages: pillow, torchvision\n",
      "Successfully installed pillow-10.3.0 torchvision-0.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pennylane\n",
    "!pip install pykan\n",
    "!pip install torch\n",
    "!pip install sklearn\n",
    "!pip install torchvision\n",
    "!pip install -U pandas\n",
    "#!git clone https://github.com/pop756/Quantum_machine.git\n",
    "#%cd Quantum_machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import sys\n",
    "import copy\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "lr = 0.01\n",
    "PCA_dim = 8\n",
    "CLS_num = 2\n",
    "\n",
    "\n",
    "\n",
    "with open('./data/data.pkl','rb') as file:\n",
    "    data = pickle.load(file)\n",
    "X = data['X']\n",
    "y = data['Y']\n",
    "\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "def Fit_to_quantum(X,PCA_dim):\n",
    "    pca = PCA(n_components=PCA_dim)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    return X_pca\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# PyTorch Tensor로 변환\n",
    "x_train_pca, y_train = torch.tensor(x_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long)\n",
    "x_test_pca, y_test = torch.tensor(x_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "\n",
    "class Feature_data_loader(Dataset):\n",
    "    def __init__(self,x_train,y_train):\n",
    "        self.feature1 = x_train\n",
    "        temp = copy.deepcopy(x_train)\n",
    "        shuffle = torch.randperm(len(temp))\n",
    "        self.feature2 = temp[shuffle]\n",
    "        self.y1 = y_train\n",
    "        temp_y = copy.deepcopy(y_train)\n",
    "        self.y2 = temp_y[shuffle]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.feature1)\n",
    "    def __getitem__(self,idx):\n",
    "        input1 = self.feature1[idx]\n",
    "        input2 = self.feature2[idx]\n",
    "        if self.y1[idx] == self.y2[idx]:\n",
    "            label = torch.tensor(1.).float()\n",
    "        else:\n",
    "            label = torch.tensor(0.).float()\n",
    "        return [input1,input2],label\n",
    "\n",
    "\n",
    "# DataLoader 생성\n",
    "\n",
    "\n",
    "feature_loader = DataLoader(Feature_data_loader(x_train_pca, y_train.float()),batch_size=batch_size,shuffle=True)\n",
    "test_feature_loader = DataLoader(Feature_data_loader(x_test_pca, y_test.float()),batch_size=batch_size,shuffle=False)\n",
    "train_loader = DataLoader(TensorDataset(x_train_pca, y_train.float()), batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(x_test_pca, y_test.float()), batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.0904, Accuracy: 34.999998807907104/60 (58%)\n",
      "Epoch 1 Loss 2.525198 acc : 0.472222 reg : 0.661982 stop count : 0\n",
      "Test set: Average loss: 1.9735, Accuracy: 36.000001430511475/60 (60%)\n",
      "Epoch 2 Loss 2.486759 acc : 0.482639 reg : 0.654521 stop count : 0\n",
      "Test set: Average loss: 1.9437, Accuracy: 36.000001430511475/60 (60%)\n",
      "Epoch 3 Loss 2.275712 acc : 0.505208 reg : 0.603031 stop count : 0\n",
      "Test set: Average loss: 1.9116, Accuracy: 36.000001430511475/60 (60%)\n",
      "Epoch 4 Loss 2.204223 acc : 0.498264 reg : 0.588237 stop count : 0\n",
      "Test set: Average loss: 1.8381, Accuracy: 36.000001430511475/60 (60%)\n",
      "Epoch 5 Loss 2.115621 acc : 0.536458 reg : 0.516335 stop count : 0\n",
      "Test set: Average loss: 1.7821, Accuracy: 36.000001430511475/60 (60%)\n",
      "Epoch 6 Loss 2.092198 acc : 0.564236 reg : 0.550549 stop count : 0\n",
      "Test set: Average loss: 1.7138, Accuracy: 37.99999952316284/60 (63%)\n",
      "Epoch 7 Loss 2.078303 acc : 0.586806 reg : 0.570284 stop count : 0\n",
      "Test set: Average loss: 1.6339, Accuracy: 37.99999952316284/60 (63%)\n",
      "Epoch 8 Loss 2.401440 acc : 0.524306 reg : 0.598779 stop count : 0\n",
      "Test set: Average loss: 1.5858, Accuracy: 37.99999952316284/60 (63%)\n",
      "Epoch 9 Loss 2.109050 acc : 0.557292 reg : 0.530926 stop count : 0\n",
      "Test set: Average loss: 1.5720, Accuracy: 37.99999952316284/60 (63%)\n",
      "Epoch 10 Loss 2.115768 acc : 0.590278 reg : 0.518504 stop count : 0\n",
      "Test set: Average loss: 1.5693, Accuracy: 37.99999952316284/60 (63%)\n",
      "Epoch 11 Loss 1.833961 acc : 0.595486 reg : 0.549963 stop count : 0\n",
      "Test set: Average loss: 1.5807, Accuracy: 37.00000047683716/60 (62%)\n",
      "Epoch 12 Loss 1.838335 acc : 0.583333 reg : 0.522815 stop count : 1\n",
      "Test set: Average loss: 1.5484, Accuracy: 37.00000047683716/60 (62%)\n",
      "Epoch 13 Loss 1.780548 acc : 0.651042 reg : 0.454583 stop count : 0\n",
      "Test set: Average loss: 1.5333, Accuracy: 37.99999952316284/60 (63%)\n",
      "Epoch 14 Loss 1.789062 acc : 0.651042 reg : 0.523427 stop count : 0\n",
      "Test set: Average loss: 1.5261, Accuracy: 38.999998569488525/60 (65%)\n",
      "Epoch 15 Loss 1.775947 acc : 0.605903 reg : 0.473755 stop count : 0\n",
      "Test set: Average loss: 1.5257, Accuracy: 40.000001192092896/60 (67%)\n",
      "Epoch 16 Loss 1.843916 acc : 0.616319 reg : 0.519181 stop count : 0\n",
      "Test set: Average loss: 1.5196, Accuracy: 41.00000023841858/60 (68%)\n",
      "Epoch 17 Loss 1.590032 acc : 0.633681 reg : 0.455066 stop count : 0\n",
      "Test set: Average loss: 1.5133, Accuracy: 40.000001192092896/60 (67%)\n",
      "Epoch 18 Loss 1.815321 acc : 0.611111 reg : 0.521779 stop count : 0\n",
      "Test set: Average loss: 1.5290, Accuracy: 40.000001192092896/60 (67%)\n",
      "Epoch 19 Loss 1.501507 acc : 0.638889 reg : 0.435438 stop count : 1\n",
      "Test set: Average loss: 1.5494, Accuracy: 40.000001192092896/60 (67%)\n",
      "Epoch 20 Loss 1.770527 acc : 0.598958 reg : 0.450535 stop count : 2\n",
      "Test set: Average loss: 1.5676, Accuracy: 40.000001192092896/60 (67%)\n",
      "Epoch 21 Loss 1.747001 acc : 0.621528 reg : 0.408193 stop count : 3\n",
      "Test set: Average loss: 1.5970, Accuracy: 40.000001192092896/60 (67%)\n",
      "Epoch 22 Loss 1.701080 acc : 0.644097 reg : 0.471916 stop count : 4\n",
      "Test set: Average loss: 1.6523, Accuracy: 40.000001192092896/60 (67%)\n",
      "Epoch 23 Loss 1.776749 acc : 0.621528 reg : 0.431223 stop count : 5\n",
      "Test set: Average loss: 1.6297, Accuracy: 40.000001192092896/60 (67%)\n",
      "Epoch 24 Loss 1.910542 acc : 0.553819 reg : 0.475690 stop count : 6\n",
      "Test set: Average loss: 1.6327, Accuracy: 40.000001192092896/60 (67%)\n",
      "Epoch 25 Loss 1.546710 acc : 0.671875 reg : 0.411866 stop count : 7\n",
      "Test set: Average loss: 1.6445, Accuracy: 40.000001192092896/60 (67%)\n",
      "Epoch 26 Loss 1.517895 acc : 0.649306 reg : 0.432796 stop count : 8\n",
      "Test set: Average loss: 1.6680, Accuracy: 40.000001192092896/60 (67%)\n",
      "Epoch 27 Loss 1.606079 acc : 0.654514 reg : 0.379078 stop count : 9\n",
      "Test set: Average loss: 1.7041, Accuracy: 40.000001192092896/60 (67%)\n",
      "Epoch 28 Loss 1.564649 acc : 0.609375 reg : 0.360683 stop count : 10\n",
      "Test set: Average loss: 1.7215, Accuracy: 40.000001192092896/60 (67%)\n",
      "Epoch 29 Loss 1.584418 acc : 0.670139 reg : 0.459820 stop count : 11\n",
      "Test set: Average loss: 1.7139, Accuracy: 40.000001192092896/60 (67%)\n",
      "Epoch 30 Loss 1.914794 acc : 0.647569 reg : 0.373086 stop count : 12\n",
      "Test set: Average loss: 1.6781, Accuracy: 40.000001192092896/60 (67%)\n",
      "Epoch 31 Loss 1.561796 acc : 0.670139 reg : 0.378506 stop count : 13\n",
      "Test set: Average loss: 1.6668, Accuracy: 40.000001192092896/60 (67%)\n",
      "Epoch 32 Loss 1.563139 acc : 0.647569 reg : 0.358651 stop count : 14\n",
      "Test set: Average loss: 1.6654, Accuracy: 40.000001192092896/60 (67%)\n",
      "Epoch 33 Loss 1.340897 acc : 0.710069 reg : 0.317939 stop count : 15\n",
      "Test set: Average loss: 1.5133, Accuracy: 40.000001192092896/60 (67%)\n",
      "\n",
      " Pretrain acc : 40.000001192092896\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import math\n",
    "from functions.training import Early_stop_train_KAN,Early_stop_train\n",
    "from kan import KAN\n",
    "\n",
    "\n",
    "\n",
    "lamb_list = [0.005*(i+1) for i in range(100)]\n",
    "lamb_entropy_list = [0.2*(i+1) for i in range(10)]\n",
    "grid=1\n",
    "device = 'cpu'\n",
    "result_dict  = []\n",
    "\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "\"\"\"\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components=PCA_dim)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.PCA_dim, random_state=seed)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\"\"\"\n",
    "\n",
    "# Pennylane 장치 설정\n",
    "dev = qml.device(\"default.qubit\", wires=PCA_dim)\n",
    "\n",
    "\n",
    "def ZZFeatureMapLayer(features, wires):\n",
    "    \"\"\"사용자 정의 ZZFeatureMap 레이어\"\"\"\n",
    "    index = 0\n",
    "    for i in wires:\n",
    "        qml.Hadamard(wires=i)\n",
    "        qml.RZ(features[:,index], wires=i)\n",
    "        index += 1\n",
    "    \n",
    "    for j in range(0, len(wires)-1):\n",
    "        qml.CNOT(wires=[j, j+1])\n",
    "        qml.RZ((features[:,index]), wires=j+1)\n",
    "        qml.CNOT(wires=[j, j+1])\n",
    "        index+=1\n",
    "def ZZFeatureMapLayer_fixed(features, wires):\n",
    "    \"\"\"사용자 정의 ZZFeatureMap 레이어\"\"\"\n",
    "    index = 0\n",
    "    for i in wires:\n",
    "        qml.Hadamard(wires=i)\n",
    "        qml.RZ(features[:,index], wires=i)\n",
    "        index += 1\n",
    "    index=0\n",
    "    for j in range(0, len(wires)-1):\n",
    "        qml.CNOT(wires=[j, j+1])\n",
    "        qml.RZ((np.pi-features[:,index])*(np.pi-features[:,index+1]), wires=j+1)\n",
    "        qml.CNOT(wires=[j, j+1])\n",
    "        index+=1\n",
    "def ansatz(params):\n",
    "    for j in range(len(params)):\n",
    "        # 각 큐비트에 대해 RX, RY, RZ 회전 적용\n",
    "        for i in range(len(params[0])):\n",
    "            qml.RY(params[j, i, 0], wires=i)\n",
    "            qml.RZ(params[j, i, 1], wires=i)\n",
    "            \n",
    "        # 인접한 큐비트 간 CNOT 게이트로 엔탱글링\n",
    "        if j == len(params)-1:\n",
    "            pass\n",
    "        else:\n",
    "            for i in range(len(params[0])-1):\n",
    "                qml.CNOT(wires=[i, i+1])\n",
    "\n",
    "\n",
    "# 양자 레이어 정의\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def QuantumLayer(features,params):\n",
    "    ZZFeatureMapLayer(features, wires=range(PCA_dim))\n",
    "    ansatz(params)\n",
    "    return qml.probs(wires=range(math.ceil(math.log2(CLS_num))))\n",
    "\n",
    "\n",
    "## 양자 커널\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def Kernal(features1,features2):\n",
    "    ZZFeatureMapLayer(features1, wires=range(PCA_dim))\n",
    "    qml.adjoint(ZZFeatureMapLayer)(features2,wires=range(PCA_dim))\n",
    "    return qml.probs(wires=range(PCA_dim))\n",
    "\n",
    "\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def Kernal_fixed(features1,features2):\n",
    "    ZZFeatureMapLayer_fixed(features1, wires=range(PCA_dim))\n",
    "    qml.adjoint(ZZFeatureMapLayer_fixed)(features2,wires=range(PCA_dim))\n",
    "    return qml.probs(wires=range(PCA_dim))\n",
    "\n",
    "class Feature_model(nn.Module):\n",
    "    def __init__(self,grid,device='cpu'):\n",
    "        super(Feature_model,self).__init__()\n",
    "        KAN2 = KAN([2,3,2],grid=grid,device=device)\n",
    "        KAN1 = KAN([1,1],grid=grid,device=device)\n",
    "        self.KAN = KAN2\n",
    "        self.KAN1 = KAN1\n",
    "        self.Kernal = Kernal\n",
    "        \n",
    "    def sliding_window(self,data, window_size=2):\n",
    "        return torch.stack([data[:,i:i+window_size] for i in range(len(data[0]) - window_size + 1)],dim=1)\n",
    "    \n",
    "    def KAN_reaction(self,inputs):\n",
    "        batch = inputs.shape[0]\n",
    "        slide_inputs = self.sliding_window(inputs)\n",
    "        slide_inputs = torch.reshape(slide_inputs,[-1,2])\n",
    "        KAN2_output = self.KAN(slide_inputs)\n",
    "        KAN2_output = torch.reshape(KAN2_output,[batch,-1])\n",
    "        \n",
    "        input1 = torch.reshape(inputs,[-1,1])\n",
    "        input1 = self.KAN1(input1)\n",
    "        input1 = torch.reshape(input1,[batch,-1])\n",
    "        \n",
    "        return torch.concat([input1,KAN2_output],dim=1)\n",
    "    def forward(self,inputs):\n",
    "        \n",
    "        \n",
    "        epsilon = 1e-6\n",
    "        input1 = inputs[0]\n",
    "        input2 = inputs[1]\n",
    "        \n",
    "        input1 = self.KAN_reaction(input1)\n",
    "        input2 = self.KAN_reaction(input2)\n",
    "\n",
    "        output = self.Kernal(input1,input2)\n",
    "        output = output.type(torch.float32)\n",
    "        \n",
    "        return output[:,0].clamp(min=epsilon, max=1-epsilon)\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# 하이브리드 모델 정의\n",
    "\n",
    "\n",
    "feature_model = Feature_model(grid,device); criterion = nn.BCELoss()\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(feature_model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "\n",
    "# 모델 학습 및 평가\n",
    "train_process = Early_stop_train_KAN(feature_model, optimizer, criterion)\n",
    "train_process.train_model(feature_loader,test_feature_loader,epochs=50,res=15,lamb=0.05)\n",
    "#feature_model.KAN = feature_model.KAN.prune()\n",
    "res,pretrain_acc = train_process.test(test_feature_loader)\n",
    "print(f\"\\n Pretrain acc : {pretrain_acc}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature_model_fixed(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Feature_model_fixed,self).__init__()\n",
    "        self.Kernal = Kernal_fixed\n",
    "    def forward(self,inputs):\n",
    "        epsilon = 1e-6\n",
    "        input1 = inputs[0]\n",
    "        input2 = inputs[1]\n",
    "        output = self.Kernal(input1,input2)\n",
    "        output = output.type(torch.float32)\n",
    "        \n",
    "        return output[:,0].clamp(min=epsilon, max=1-epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Test start\n",
      "\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.7082, Accuracy: 20.99999964237213/60 (35%)\n",
      "Epoch 1 Loss 0.687154 acc : 0.520833 stop count : 0\n",
      "Test set: Average loss: 0.6274, Accuracy: 45.0/60 (75%)\n",
      "Epoch 2 Loss 0.617474 acc : 0.711806 stop count : 0\n",
      "Test set: Average loss: 0.5717, Accuracy: 44.000000953674316/60 (73%)\n",
      "Epoch 3 Loss 0.576896 acc : 0.765625 stop count : 0\n",
      "Test set: Average loss: 0.5394, Accuracy: 47.000001668930054/60 (78%)\n",
      "Epoch 4 Loss 0.538528 acc : 0.824653 stop count : 0\n",
      "Test set: Average loss: 0.5220, Accuracy: 48.00000071525574/60 (80%)\n",
      "Epoch 5 Loss 0.527676 acc : 0.807292 stop count : 0\n",
      "Test set: Average loss: 0.5096, Accuracy: 47.000001668930054/60 (78%)\n",
      "Epoch 6 Loss 0.477716 acc : 0.845486 stop count : 0\n",
      "Test set: Average loss: 0.4990, Accuracy: 48.00000071525574/60 (80%)\n",
      "Epoch 7 Loss 0.517542 acc : 0.828125 stop count : 0\n",
      "Test set: Average loss: 0.4889, Accuracy: 48.00000071525574/60 (80%)\n",
      "Epoch 8 Loss 0.483416 acc : 0.838542 stop count : 0\n",
      "Test set: Average loss: 0.4822, Accuracy: 48.99999976158142/60 (82%)\n",
      "Epoch 9 Loss 0.456615 acc : 0.921875 stop count : 0\n",
      "Test set: Average loss: 0.4769, Accuracy: 49.999998807907104/60 (83%)\n",
      "Epoch 10 Loss 0.429786 acc : 0.921875 stop count : 0\n",
      "Test set: Average loss: 0.4710, Accuracy: 51.000001430511475/60 (85%)\n",
      "Epoch 11 Loss 0.456959 acc : 0.899306 stop count : 0\n",
      "Test set: Average loss: 0.4652, Accuracy: 51.000001430511475/60 (85%)\n",
      "Epoch 12 Loss 0.496972 acc : 0.826389 stop count : 0\n",
      "Test set: Average loss: 0.4605, Accuracy: 49.999998807907104/60 (83%)\n",
      "Epoch 13 Loss 0.436236 acc : 0.876736 stop count : 0\n",
      "Test set: Average loss: 0.4586, Accuracy: 49.999998807907104/60 (83%)\n",
      "Epoch 14 Loss 0.440335 acc : 0.876736 stop count : 0\n",
      "Test set: Average loss: 0.4566, Accuracy: 49.999998807907104/60 (83%)\n",
      "Epoch 15 Loss 0.406817 acc : 0.899306 stop count : 0\n",
      "Test set: Average loss: 0.4537, Accuracy: 49.999998807907104/60 (83%)\n",
      "Epoch 16 Loss 0.437540 acc : 0.932292 stop count : 0\n",
      "Test set: Average loss: 0.4496, Accuracy: 49.999998807907104/60 (83%)\n",
      "Epoch 17 Loss 0.409500 acc : 0.914931 stop count : 0\n",
      "Test set: Average loss: 0.4464, Accuracy: 49.999998807907104/60 (83%)\n",
      "Epoch 18 Loss 0.425784 acc : 0.892361 stop count : 0\n",
      "Test set: Average loss: 0.4444, Accuracy: 48.99999976158142/60 (82%)\n",
      "Epoch 19 Loss 0.402736 acc : 0.906250 stop count : 0"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTest start\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m train_process \u001b[38;5;241m=\u001b[39m Early_stop_train(model, optimizer, criterion)\n\u001b[1;32m---> 28\u001b[0m \u001b[43mtrain_process\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m _,acc \u001b[38;5;241m=\u001b[39m train_process\u001b[38;5;241m.\u001b[39mtest(test_loader)\n",
      "File \u001b[1;32mc:\\Users\\pop75\\OneDrive\\Desktop\\Project\\AI_quantum_project\\Quantum_KAN_modif\\functions\\training.py:65\u001b[0m, in \u001b[0;36mEarly_stop_train.train_model\u001b[1;34m(self, train_loader, test_loader, epochs, res, device)\u001b[0m\n\u001b[0;32m     61\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(X_train)\n\u001b[0;32m     63\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(output\u001b[38;5;241m.\u001b[39msqueeze(), y_train)\n\u001b[1;32m---> 65\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     67\u001b[0m loss_list\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[1;32mc:\\Users\\pop75\\anaconda3\\envs\\Lee\\Lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pop75\\anaconda3\\envs\\Lee\\Lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pop75\\anaconda3\\envs\\Lee\\Lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 하이브리드 모델 정의\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HybridModel, self).__init__()\n",
    "        self.cls = feature_model.KAN_reaction\n",
    "        @qml.qnode(dev, interface='torch')\n",
    "        def QuantumLayer(features,params):\n",
    "            for i in range(len(params)):\n",
    "                ZZFeatureMapLayer(features, wires=range(PCA_dim))\n",
    "                ansatz(params[i])\n",
    "            return qml.probs(wires=range(math.ceil(math.log2(CLS_num))))\n",
    "        self.quantum_layer = QuantumLayer\n",
    "        self.Q_params = nn.Parameter((torch.rand([3,PCA_dim,PCA_dim,2])*2-1)*np.pi,requires_grad=True)\n",
    "    def forward(self, x):\n",
    "        epsilon = 1e-6\n",
    "        x = self.cls(x)\n",
    "        #print(qml.draw(self.quantum_layer)(x,self.Q_params))\n",
    "        quantum_output = self.quantum_layer(x,self.Q_params)\n",
    "        quantum_output = quantum_output.type(torch.float32)\n",
    "        return quantum_output[:,0].clamp(min=epsilon, max=1-epsilon)\n",
    "model = HybridModel(); criterion = nn.BCELoss()\n",
    "\n",
    "\n",
    "    \n",
    "optimizer = optim.Adam([model.Q_params], lr=0.01)\n",
    "print(\"\\n\\nTest start\\n\\n\")\n",
    "train_process = Early_stop_train(model, optimizer, criterion)\n",
    "train_process.train_model(train_loader,test_loader,epochs=25)\n",
    "\n",
    "_,acc = train_process.test(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_model.KAN1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 13 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#feature_model.KAN = feature_model.KAN.prune()\n",
    "feature_model.KAN.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.0134, Accuracy: 82.00000005960464/133 (62%)\n",
      "Epoch 1 Loss 0.675897 acc : 0.620873 stop count : 0\n",
      "Test set: Average loss: 1.8967, Accuracy: 87.00000005960464/133 (65%)\n",
      "Epoch 2 Loss 0.636764 acc : 0.731545 stop count : 0\n",
      "Test set: Average loss: 1.8481, Accuracy: 92.0/133 (69%)\n",
      "Epoch 3 Loss 0.615194 acc : 0.758491 stop count : 0\n",
      "Test set: Average loss: 1.8212, Accuracy: 91.0/133 (68%)\n",
      "Epoch 4 Loss 0.603542 acc : 0.765389 stop count : 0\n",
      "Test set: Average loss: 1.8098, Accuracy: 91.0/133 (68%)\n",
      "Epoch 5 Loss 0.592995 acc : 0.790389 stop count : 0\n",
      "Test set: Average loss: 1.8213, Accuracy: 89.0/133 (67%)\n",
      "Epoch 6 Loss 0.586422 acc : 0.769163 stop count : 1\n",
      "Test set: Average loss: 1.7998, Accuracy: 91.0/133 (68%)\n",
      "Epoch 7 Loss 0.579742 acc : 0.787264 stop count : 0\n",
      "Test set: Average loss: 1.7916, Accuracy: 92.0/133 (69%)\n",
      "Epoch 8 Loss 0.579748 acc : 0.784670 stop count : 0\n",
      "Test set: Average loss: 1.7791, Accuracy: 90.0/133 (68%)\n",
      "Epoch 9 Loss 0.573021 acc : 0.806663 stop count : 0\n",
      "Test set: Average loss: 1.7869, Accuracy: 90.0/133 (68%)\n",
      "Epoch 10 Loss 0.568261 acc : 0.794811 stop count : 1\n",
      "Test set: Average loss: 1.7699, Accuracy: 89.0/133 (67%)\n",
      "Epoch 11 Loss 0.564983 acc : 0.801061 stop count : 0\n",
      "Test set: Average loss: 1.7609, Accuracy: 89.0/133 (67%)\n",
      "Epoch 12 Loss 0.562754 acc : 0.803538 stop count : 0\n",
      "Test set: Average loss: 1.7571, Accuracy: 89.0/133 (67%)\n",
      "Epoch 13 Loss 0.561386 acc : 0.802241 stop count : 0\n",
      "Test set: Average loss: 1.7513, Accuracy: 89.0/133 (67%)\n",
      "Epoch 14 Loss 0.559437 acc : 0.806663 stop count : 0\n",
      "Test set: Average loss: 1.7696, Accuracy: 89.0/133 (67%)\n",
      "Epoch 15 Loss 0.557473 acc : 0.797288 stop count : 1\n",
      "Test set: Average loss: 1.7612, Accuracy: 90.0/133 (68%)\n",
      "Epoch 16 Loss 0.554164 acc : 0.808608 stop count : 2\n",
      "Test set: Average loss: 1.7530, Accuracy: 90.0/133 (68%)\n",
      "Epoch 17 Loss 0.554688 acc : 0.812264 stop count : 3\n",
      "Test set: Average loss: 1.7515, Accuracy: 90.0/133 (68%)\n",
      "Epoch 18 Loss 0.553895 acc : 0.804717 stop count : 4\n",
      "Test set: Average loss: 1.7499, Accuracy: 91.0/133 (68%)\n",
      "Epoch 19 Loss 0.555338 acc : 0.801061 stop count : 0\n",
      "Test set: Average loss: 1.7438, Accuracy: 90.0/133 (68%)\n",
      "Epoch 20 Loss 0.552924 acc : 0.814092 stop count : 0\n",
      "Test set: Average loss: 1.7622, Accuracy: 91.0/133 (68%)\n",
      "Epoch 21 Loss 0.549561 acc : 0.795460 stop count : 1\n",
      "Test set: Average loss: 1.7571, Accuracy: 90.0/133 (68%)\n",
      "Epoch 22 Loss 0.547650 acc : 0.824233 stop count : 2\n",
      "Test set: Average loss: 1.7464, Accuracy: 90.0/133 (68%)\n",
      "Epoch 23 Loss 0.547334 acc : 0.810436 stop count : 3\n",
      "Test set: Average loss: 1.7470, Accuracy: 90.0/133 (68%)\n",
      "Epoch 24 Loss 0.548164 acc : 0.802889 stop count : 4\n",
      "Test set: Average loss: 1.7596, Accuracy: 89.0/133 (67%)\n",
      "Epoch 25 Loss 0.548408 acc : 0.799116 stop count : 5\n",
      "Test set: Average loss: 1.7319, Accuracy: 92.0/133 (69%)\n"
     ]
    }
   ],
   "source": [
    "class HybridModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HybridModel, self).__init__()\n",
    "        self.cls = feature_model.KAN_reaction\n",
    "        @qml.qnode(dev, interface='torch')\n",
    "        def QuantumLayer(features,params):\n",
    "            for i in range(5):\n",
    "                ZZFeatureMapLayer(features, wires=range(PCA_dim))\n",
    "                ansatz(params[i])\n",
    "            return qml.probs(wires=range(math.ceil(math.log2(CLS_num))))\n",
    "        self.quantum_layer = QuantumLayer\n",
    "        self.Q_params = nn.Parameter((torch.rand([5,PCA_dim,PCA_dim,2])*2-1)*np.pi,requires_grad=True)\n",
    "    def forward(self, x):\n",
    "        epsilon = 1e-6\n",
    "        x = self.cls(x)\n",
    "        #print(qml.draw(self.quantum_layer)(x,self.Q_params))\n",
    "        quantum_output = self.quantum_layer(x,self.Q_params)\n",
    "        quantum_output = quantum_output.type(torch.float32)\n",
    "        return quantum_output[:,0].clamp(min=epsilon, max=1-epsilon)\n",
    "model = HybridModel(); criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam([model.Q_params], lr=0.01)\n",
    "from functions.training import Early_stop_train\n",
    "train_process = Early_stop_train(model, optimizer, criterion)\n",
    "train_process.train_model(train_loader,test_loader,epochs=25)\n",
    "\n",
    "_,acc = train_process.test(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZZFeatureMapLayer_fixed(features, wires):\n",
    "    \"\"\"사용자 정의 ZZFeatureMap 레이어\"\"\"\n",
    "    index = 0\n",
    "    for i in wires:\n",
    "        qml.Hadamard(wires=i)\n",
    "        qml.RZ(features[:,index], wires=i)\n",
    "        index += 1\n",
    "    index=0\n",
    "    for j in range(0, len(wires)-1):\n",
    "        qml.CNOT(wires=[j, j+1])\n",
    "        qml.RZ((features[:,index])*(features[:,index+1]), wires=j+1)\n",
    "        qml.CNOT(wires=[j, j+1])\n",
    "        index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 2.1247, Accuracy: 64.00000001490116/133 (48%)\n",
      "Epoch 1 Loss 0.702060 acc : 0.389583 stop count : 0\n",
      "Test set: Average loss: 1.9923, Accuracy: 89.00000005960464/133 (67%)\n",
      "Epoch 2 Loss 0.640876 acc : 0.796875 stop count : 0\n",
      "Test set: Average loss: 1.8581, Accuracy: 105.0/133 (79%)\n",
      "Epoch 3 Loss 0.601796 acc : 0.859375 stop count : 0\n",
      "Test set: Average loss: 1.7631, Accuracy: 111.0/133 (83%)\n",
      "Epoch 4 Loss 0.575146 acc : 0.890625 stop count : 0\n",
      "Test set: Average loss: 1.6956, Accuracy: 114.0/133 (86%)\n",
      "Epoch 5 Loss 0.555958 acc : 0.901042 stop count : 0\n",
      "Test set: Average loss: 1.6448, Accuracy: 117.0/133 (88%)\n",
      "Epoch 6 Loss 0.541319 acc : 0.916667 stop count : 0\n",
      "Test set: Average loss: 1.6053, Accuracy: 117.0/133 (88%)\n",
      "Epoch 7 Loss 0.529705 acc : 0.921875 stop count : 0"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[149], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Early_stop_train\n\u001b[0;32m     23\u001b[0m train_process \u001b[38;5;241m=\u001b[39m Early_stop_train(model, optimizer, criterion)\n\u001b[1;32m---> 24\u001b[0m \u001b[43mtrain_process\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m _,acc \u001b[38;5;241m=\u001b[39m train_process\u001b[38;5;241m.\u001b[39mtest(test_loader)\n",
      "File \u001b[1;32mc:\\Users\\pop75\\OneDrive\\Desktop\\Project\\AI_quantum_project\\Quantum_KAN\\functions\\training.py:43\u001b[0m, in \u001b[0;36mEarly_stop_train.train_model\u001b[1;34m(self, train_loader, test_loader, epochs, res, device)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_count\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39mres:\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m loss_val,_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_list\u001b[38;5;241m.\u001b[39mappend(loss_val)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_list[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mmin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_list[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]):\n",
      "File \u001b[1;32mc:\\Users\\pop75\\OneDrive\\Desktop\\Project\\AI_quantum_project\\Quantum_KAN\\functions\\training.py:89\u001b[0m, in \u001b[0;36mEarly_stop_train.test\u001b[1;34m(self, test_loader, device)\u001b[0m\n\u001b[0;32m     87\u001b[0m target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     88\u001b[0m data, target \u001b[38;5;241m=\u001b[39m data, target\n\u001b[1;32m---> 89\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m test_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(output\u001b[38;5;241m.\u001b[39msqueeze(), target)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     92\u001b[0m correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m accuracy(output,target)\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(output)\n",
      "File \u001b[1;32mc:\\Users\\pop75\\anaconda3\\envs\\Lee\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pop75\\anaconda3\\envs\\Lee\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[149], line 17\u001b[0m, in \u001b[0;36mHybridModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     14\u001b[0m epsilon \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-6\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#x = self.cls(x)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#print(qml.draw(self.quantum_layer)(x,self.Q_params))\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m quantum_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantum_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mQ_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m quantum_output \u001b[38;5;241m=\u001b[39m quantum_output\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m quantum_output[:,\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39mepsilon, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mepsilon)\n",
      "File \u001b[1;32mc:\\Users\\pop75\\anaconda3\\envs\\Lee\\Lib\\site-packages\\pennylane\\qnode.py:1027\u001b[0m, in \u001b[0;36mQNode.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1022\u001b[0m         full_transform_program\u001b[38;5;241m.\u001b[39m_set_all_argnums(\n\u001b[0;32m   1023\u001b[0m             \u001b[38;5;28mself\u001b[39m, args, kwargs, argnums\n\u001b[0;32m   1024\u001b[0m         )  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# pylint: disable=unexpected-keyword-arg\u001b[39;00m\n\u001b[1;32m-> 1027\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mqml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransform_program\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_transform_program\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1033\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1034\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1035\u001b[0m \u001b[43m    \u001b[49m\u001b[43moverride_shots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_shots\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1036\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1037\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1039\u001b[0m res \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;66;03m# convert result to the interface in case the qfunc has no parameters\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pop75\\anaconda3\\envs\\Lee\\Lib\\site-packages\\pennylane\\interfaces\\execution.py:616\u001b[0m, in \u001b[0;36mexecute\u001b[1;34m(tapes, device, gradient_fn, interface, transform_program, config, grad_on_execution, gradient_kwargs, cache, cachesize, max_diff, override_shots, expand_fn, max_expansion, device_batch_transform)\u001b[0m\n\u001b[0;32m    614\u001b[0m \u001b[38;5;66;03m# Exiting early if we do not need to deal with an interface boundary\u001b[39;00m\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_interface_boundary_required:\n\u001b[1;32m--> 616\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43minner_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m post_processing(results)\n\u001b[0;32m    619\u001b[0m _grad_on_execution \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pop75\\anaconda3\\envs\\Lee\\Lib\\site-packages\\pennylane\\interfaces\\execution.py:249\u001b[0m, in \u001b[0;36m_make_inner_execute.<locals>.inner_execute\u001b[1;34m(tapes, **_)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m numpy_only:\n\u001b[0;32m    248\u001b[0m     tapes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(qml\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mconvert_to_numpy_parameters(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tapes)\n\u001b[1;32m--> 249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcached_device_execution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtapes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pop75\\anaconda3\\envs\\Lee\\Lib\\site-packages\\pennylane\\interfaces\\execution.py:332\u001b[0m, in \u001b[0;36mcache_execute.<locals>.wrapper\u001b[1;34m(tapes, **kwargs)\u001b[0m\n\u001b[0;32m    329\u001b[0m repeated \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, tape \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tapes):\n\u001b[1;32m--> 332\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhash\u001b[49m\n\u001b[0;32m    334\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hashes\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m    335\u001b[0m         \u001b[38;5;66;03m# Tape already exists within ``tapes``. Determine the\u001b[39;00m\n\u001b[0;32m    336\u001b[0m         \u001b[38;5;66;03m# index of the first occurrence of the tape, store this,\u001b[39;00m\n\u001b[0;32m    337\u001b[0m         \u001b[38;5;66;03m# and continue to the next iteration.\u001b[39;00m\n\u001b[0;32m    338\u001b[0m         idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(hashes\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;28mlist\u001b[39m(hashes\u001b[38;5;241m.\u001b[39mvalues())\u001b[38;5;241m.\u001b[39mindex(h)]\n",
      "File \u001b[1;32mc:\\Users\\pop75\\anaconda3\\envs\\Lee\\Lib\\site-packages\\pennylane\\tape\\qscript.py:237\u001b[0m, in \u001b[0;36mQuantumScript.hash\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"int: returns an integer hash uniquely representing the quantum script\"\"\"\u001b[39;00m\n\u001b[0;32m    236\u001b[0m fingerprint \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 237\u001b[0m fingerprint\u001b[38;5;241m.\u001b[39mextend(op\u001b[38;5;241m.\u001b[39mhash \u001b[38;5;28;01mfor\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moperations)\n\u001b[0;32m    238\u001b[0m fingerprint\u001b[38;5;241m.\u001b[39mextend(m\u001b[38;5;241m.\u001b[39mhash \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeasurements)\n\u001b[0;32m    239\u001b[0m fingerprint\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable_params)\n",
      "File \u001b[1;32mc:\\Users\\pop75\\anaconda3\\envs\\Lee\\Lib\\site-packages\\pennylane\\tape\\qscript.py:237\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"int: returns an integer hash uniquely representing the quantum script\"\"\"\u001b[39;00m\n\u001b[0;32m    236\u001b[0m fingerprint \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 237\u001b[0m fingerprint\u001b[38;5;241m.\u001b[39mextend(\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhash\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m op \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moperations)\n\u001b[0;32m    238\u001b[0m fingerprint\u001b[38;5;241m.\u001b[39mextend(m\u001b[38;5;241m.\u001b[39mhash \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeasurements)\n\u001b[0;32m    239\u001b[0m fingerprint\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable_params)\n",
      "File \u001b[1;32mc:\\Users\\pop75\\anaconda3\\envs\\Lee\\Lib\\site-packages\\pennylane\\operation.py:718\u001b[0m, in \u001b[0;36mOperator.hash\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    711\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhash\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    712\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"int: Integer hash that uniquely represents the operator.\"\"\"\u001b[39;00m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mhash\u001b[39m(\n\u001b[0;32m    714\u001b[0m         (\n\u001b[0;32m    715\u001b[0m             \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    716\u001b[0m             \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwires\u001b[38;5;241m.\u001b[39mtolist()),\n\u001b[0;32m    717\u001b[0m             \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhyperparameters\u001b[38;5;241m.\u001b[39mvalues()),\n\u001b[1;32m--> 718\u001b[0m             \u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    719\u001b[0m         )\n\u001b[0;32m    720\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\pop75\\anaconda3\\envs\\Lee\\Lib\\site-packages\\pennylane\\operation.py:383\u001b[0m, in \u001b[0;36m_process_data\u001b[1;34m(op)\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_process_data\u001b[39m(op):\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;66;03m# Use qml.math.real to take the real part. We may get complex inputs for\u001b[39;00m\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;66;03m# example when differentiating holomorphic functions with JAX: a complex\u001b[39;00m\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;66;03m# valued QNode (one that returns qml.state) requires complex typed inputs.\u001b[39;00m\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m op\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRZ\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPhaseShift\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRot\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 383\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(\u001b[43m[\u001b[49m\u001b[43mqml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreal\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m op\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCRX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCRY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCRZ\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCRot\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m([qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mround(qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mreal(d) \u001b[38;5;241m%\u001b[39m (\u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mpi), \u001b[38;5;241m10\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m op\u001b[38;5;241m.\u001b[39mdata])\n",
      "File \u001b[1;32mc:\\Users\\pop75\\anaconda3\\envs\\Lee\\Lib\\site-packages\\pennylane\\operation.py:383\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_process_data\u001b[39m(op):\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;66;03m# Use qml.math.real to take the real part. We may get complex inputs for\u001b[39;00m\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;66;03m# example when differentiating holomorphic functions with JAX: a complex\u001b[39;00m\n\u001b[0;32m    381\u001b[0m     \u001b[38;5;66;03m# valued QNode (one that returns qml.state) requires complex typed inputs.\u001b[39;00m\n\u001b[0;32m    382\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m op\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRZ\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPhaseShift\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRot\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 383\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m([\u001b[43mqml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreal\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m op\u001b[38;5;241m.\u001b[39mdata])\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m op\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCRX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCRY\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCRZ\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCRot\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m([qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mround(qml\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mreal(d) \u001b[38;5;241m%\u001b[39m (\u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mpi), \u001b[38;5;241m10\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m op\u001b[38;5;241m.\u001b[39mdata])\n",
      "File \u001b[1;32mc:\\Users\\pop75\\anaconda3\\envs\\Lee\\Lib\\site-packages\\autoray\\autoray.py:80\u001b[0m, in \u001b[0;36mdo\u001b[1;34m(fn, like, *args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Do function named ``fn`` on ``(*args, **kwargs)``, peforming single\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03mdispatch to retrieve ``fn`` based on whichever library defines the class of\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;124;03mthe ``args[0]``, or the ``like`` keyword argument if specified.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;124;03m    <tf.Tensor: id=91, shape=(3, 3), dtype=float32>\u001b[39;00m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     79\u001b[0m backend \u001b[38;5;241m=\u001b[39m choose_backend(fn, \u001b[38;5;241m*\u001b[39margs, like\u001b[38;5;241m=\u001b[39mlike, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_lib_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pop75\\anaconda3\\envs\\Lee\\Lib\\site-packages\\pennylane\\math\\single_dispatch.py:562\u001b[0m, in \u001b[0;36m_round_torch\u001b[1;34m(tensor, decimals)\u001b[0m\n\u001b[0;32m    560\u001b[0m torch \u001b[38;5;241m=\u001b[39m _i(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    561\u001b[0m tol \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecimals\n\u001b[1;32m--> 562\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m/\u001b[39m tol\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class HybridModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HybridModel, self).__init__()\n",
    "        self.cls = feature_model.KAN_reaction\n",
    "        @qml.qnode(dev, interface='torch')\n",
    "        def QuantumLayer(features,params):\n",
    "            for i in range(5):\n",
    "                ZZFeatureMapLayer_fixed(features, wires=range(PCA_dim))\n",
    "                ansatz(params[i])\n",
    "            return qml.probs(wires=range(math.ceil(math.log2(CLS_num))))\n",
    "        self.quantum_layer = QuantumLayer\n",
    "        self.Q_params = nn.Parameter((torch.rand([5,PCA_dim,PCA_dim,2])*2-1)*np.pi,requires_grad=True)\n",
    "    def forward(self, x):\n",
    "        epsilon = 1e-6\n",
    "        #x = self.cls(x)\n",
    "        #print(qml.draw(self.quantum_layer)(x,self.Q_params))\n",
    "        quantum_output = self.quantum_layer(x,self.Q_params)\n",
    "        quantum_output = quantum_output.type(torch.float32)\n",
    "        return quantum_output[:,1].clamp(min=epsilon, max=1-epsilon)\n",
    "model = HybridModel(); criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam([model.Q_params], lr=0.01)\n",
    "from functions.training import Early_stop_train\n",
    "train_process = Early_stop_train(model, optimizer, criterion)\n",
    "train_process.train_model(train_loader,test_loader,epochs=25)\n",
    "\n",
    "_,acc = train_process.test(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_feature = Feature_model_fixed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.training import Kernal_method\n",
    "fixed_kernal  = Kernal_method(fix_feature)\n",
    "keranl = Kernal_method(feature_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 140/140 [00:13<00:00, 10.16it/s]\n",
      "c:\\Users\\pop75\\OneDrive\\Desktop\\Project\\AI_quantum_project\\Quantum_KAN_modif\\functions\\training.py:221: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(y_train).float()\n",
      "c:\\Users\\pop75\\OneDrive\\Desktop\\Project\\AI_quantum_project\\Quantum_KAN_modif\\functions\\training.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_test = torch.tensor(x_test).float()\n",
      "100%|██████████| 140/140 [00:08<00:00, 17.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " acc :  0.6000000238418579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0000e+00, 1.8912e-03, 5.0535e-04,  ..., 1.2684e-03, 7.5125e-04,\n",
       "          1.8131e-04],\n",
       "         [1.8912e-03, 1.0000e+00, 7.6415e-05,  ..., 9.9448e-03, 8.1960e-03,\n",
       "          1.3097e-03],\n",
       "         [5.0535e-04, 7.6415e-05, 1.0000e+00,  ..., 9.0930e-03, 1.9711e-03,\n",
       "          2.9987e-04],\n",
       "         ...,\n",
       "         [1.2684e-03, 9.9448e-03, 9.0930e-03,  ..., 1.0000e+00, 6.5076e-03,\n",
       "          1.4271e-03],\n",
       "         [7.5125e-04, 8.1960e-03, 1.9711e-03,  ..., 6.5076e-03, 1.0000e+00,\n",
       "          1.1036e-03],\n",
       "         [1.8131e-04, 1.3097e-03, 2.9987e-04,  ..., 1.4271e-03, 1.1036e-03,\n",
       "          1.0000e+00]]),\n",
       " tensor([[1.5505e-03, 1.4807e-03, 5.3824e-04,  ..., 2.9100e-03, 1.6180e-02,\n",
       "          3.8593e-03],\n",
       "         [4.0501e-03, 1.8477e-03, 2.7761e-04,  ..., 1.7834e-04, 2.3242e-03,\n",
       "          4.2579e-04],\n",
       "         [7.5070e-04, 2.0937e-04, 1.4447e-03,  ..., 5.2230e-04, 6.8123e-04,\n",
       "          4.6159e-04],\n",
       "         ...,\n",
       "         [1.1546e-03, 1.5077e-05, 1.7329e-04,  ..., 1.0888e-04, 5.1500e-03,\n",
       "          1.4598e-03],\n",
       "         [4.7818e-04, 2.7836e-02, 1.0763e-04,  ..., 2.0955e-04, 1.8212e-05,\n",
       "          1.0629e-04],\n",
       "         [2.5209e-02, 4.4860e-03, 2.8975e-04,  ..., 2.2073e-03, 3.3457e-03,\n",
       "          1.8198e-04]]),\n",
       " tensor([0.4928, 0.5071, 0.5071, 0.5071, 0.5071, 0.4928, 0.5071, 0.4928, 0.5071,\n",
       "         0.4928, 0.5071, 0.4928, 0.4928, 0.5071, 0.4928, 0.4928, 0.5071, 0.4929,\n",
       "         0.4928, 0.4928, 0.5071, 0.5071, 0.5071, 0.4928, 0.4928, 0.5071, 0.4928,\n",
       "         0.5071, 0.4928, 0.5071, 0.5071, 0.4928, 0.4928, 0.5071, 0.5071, 0.4928,\n",
       "         0.4928, 0.5071, 0.5071, 0.4928, 0.5071, 0.5071, 0.4928, 0.4929, 0.4928,\n",
       "         0.4928, 0.5071, 0.5071, 0.4928, 0.4928, 0.4928, 0.5071, 0.4928, 0.4928,\n",
       "         0.5071, 0.4928, 0.5071, 0.5071, 0.4928, 0.5071, 0.5071, 0.4928, 0.4928,\n",
       "         0.4928, 0.5071, 0.5071, 0.4928, 0.4928, 0.5071, 0.5071, 0.4928, 0.5071,\n",
       "         0.5071, 0.4929, 0.5071, 0.4928, 0.5071, 0.4928, 0.5071, 0.4929, 0.4929,\n",
       "         0.4928, 0.4928, 0.5071, 0.5071, 0.5071, 0.5071, 0.4928, 0.5071, 0.5071,\n",
       "         0.4928, 0.4928, 0.5071, 0.5071, 0.5071, 0.5071, 0.4928, 0.4928, 0.5071,\n",
       "         0.5071, 0.4929, 0.4929, 0.4928, 0.4928, 0.5071, 0.5071, 0.4928, 0.5071,\n",
       "         0.4928, 0.5071, 0.5071, 0.5071, 0.5071, 0.5071, 0.4928, 0.4929, 0.4929,\n",
       "         0.5071, 0.4928, 0.4928, 0.5071, 0.5071, 0.4928, 0.4928, 0.4928, 0.4928,\n",
       "         0.5071, 0.4929, 0.5071, 0.5071, 0.4928, 0.4929, 0.5071, 0.4928, 0.5071,\n",
       "         0.4928, 0.5071, 0.5071, 0.4928, 0.4928], requires_grad=True),\n",
       " tensor([-1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1., -1., -1.,  1.,\n",
       "         -1., -1.,  1., -1., -1., -1.,  1.,  1.,  1., -1., -1.,  1., -1.,  1.,\n",
       "         -1.,  1.,  1., -1., -1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1.,\n",
       "         -1., -1., -1., -1.,  1.,  1., -1., -1., -1.,  1., -1., -1.,  1., -1.,\n",
       "          1.,  1., -1.,  1.,  1., -1., -1., -1.,  1.,  1., -1., -1.,  1.,  1.,\n",
       "         -1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1., -1., -1., -1., -1.,  1.,\n",
       "          1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1., -1.,\n",
       "          1.,  1., -1., -1., -1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1.,\n",
       "          1.,  1., -1., -1., -1.,  1., -1., -1.,  1.,  1., -1., -1., -1., -1.,\n",
       "          1., -1.,  1.,  1., -1., -1.,  1., -1.,  1., -1.,  1.,  1., -1., -1.]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_kernal.train(x_train_pca, y_train,x_test_pca,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 140/140 [00:19<00:00,  7.33it/s]\n",
      "100%|██████████| 140/140 [00:12<00:00, 11.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " acc :  0.8166666626930237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0000e+00, 2.9079e-01, 3.2818e-04,  ..., 4.9283e-03, 4.5539e-03,\n",
       "          2.2526e-03],\n",
       "         [2.9079e-01, 1.0000e+00, 1.0359e-01,  ..., 1.5651e-02, 3.2630e-02,\n",
       "          3.8122e-02],\n",
       "         [3.2818e-04, 1.0359e-01, 1.0000e+00,  ..., 5.6618e-02, 1.4505e-01,\n",
       "          2.6624e-01],\n",
       "         ...,\n",
       "         [4.9283e-03, 1.5651e-02, 5.6618e-02,  ..., 1.0000e+00, 6.5909e-03,\n",
       "          6.3408e-03],\n",
       "         [4.5539e-03, 3.2630e-02, 1.4505e-01,  ..., 6.5909e-03, 1.0000e+00,\n",
       "          4.5919e-01],\n",
       "         [2.2526e-03, 3.8122e-02, 2.6624e-01,  ..., 6.3408e-03, 4.5919e-01,\n",
       "          1.0000e+00]]),\n",
       " tensor([[1.7328e-01, 5.8218e-01, 4.4450e-03,  ..., 2.5288e-02, 3.5210e-04,\n",
       "          1.7879e-03],\n",
       "         [4.1552e-03, 1.6051e-02, 1.1078e-01,  ..., 1.0602e-01, 1.7650e-01,\n",
       "          7.3827e-02],\n",
       "         [5.1204e-04, 1.0565e-01, 9.1702e-01,  ..., 3.9144e-02, 3.6351e-01,\n",
       "          4.1598e-01],\n",
       "         ...,\n",
       "         [2.1033e-01, 9.1527e-01, 1.7932e-01,  ..., 5.0263e-03, 1.1392e-01,\n",
       "          9.9788e-02],\n",
       "         [2.9479e-03, 4.3324e-02, 7.0503e-02,  ..., 1.2927e-02, 8.9415e-01,\n",
       "          4.1584e-01],\n",
       "         [2.0623e-01, 5.3967e-01, 1.3034e-03,  ..., 3.0530e-02, 1.0724e-03,\n",
       "          9.8258e-04]]),\n",
       " tensor([0.4908, 0.5098, 0.5110, 0.5099, 0.5106, 0.4971, 0.5152, 0.4925, 0.5104,\n",
       "         0.4971, 0.5107, 0.4971, 0.4971, 0.5123, 0.4908, 0.4964, 0.5094, 0.4971,\n",
       "         0.4968, 0.4937, 0.5147, 0.5096, 0.5094, 0.4962, 0.4972, 0.5102, 0.4970,\n",
       "         0.5146, 0.4971, 0.5108, 0.5124, 0.4972, 0.4972, 0.5114, 0.5140, 0.4953,\n",
       "         0.4972, 0.5093, 0.5100, 0.4965, 0.5093, 0.5106, 0.4968, 0.4972, 0.4970,\n",
       "         0.4958, 0.5103, 0.5110, 0.4972, 0.4971, 0.4972, 0.5104, 0.4968, 0.4966,\n",
       "         0.5096, 0.4960, 0.5108, 0.5091, 0.4963, 0.5099, 0.5134, 0.4971, 0.4962,\n",
       "         0.4970, 0.5094, 0.5124, 0.4972, 0.4973, 0.5093, 0.5120, 0.4970, 0.5103,\n",
       "         0.5103, 0.4971, 0.5092, 0.4971, 0.5102, 0.4968, 0.5111, 0.4973, 0.4973,\n",
       "         0.4969, 0.4957, 0.5104, 0.5094, 0.5100, 0.5095, 0.4972, 0.5108, 0.5096,\n",
       "         0.4972, 0.4972, 0.5144, 0.5095, 0.5104, 0.5102, 0.4969, 0.4971, 0.5104,\n",
       "         0.5098, 0.4971, 0.4973, 0.4969, 0.4964, 0.5110, 0.5113, 0.4971, 0.5105,\n",
       "         0.4945, 0.5100, 0.5102, 0.5117, 0.5139, 0.5106, 0.4968, 0.4972, 0.4969,\n",
       "         0.5152, 0.4970, 0.4969, 0.5103, 0.5109, 0.4970, 0.4969, 0.4909, 0.4973,\n",
       "         0.5108, 0.4970, 0.5093, 0.5098, 0.4922, 0.4973, 0.5100, 0.4950, 0.5097,\n",
       "         0.4973, 0.5094, 0.5098, 0.4969, 0.4944], requires_grad=True),\n",
       " tensor([-1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1., -1., -1.,  1.,\n",
       "         -1., -1.,  1., -1., -1., -1.,  1.,  1.,  1., -1., -1.,  1., -1.,  1.,\n",
       "         -1.,  1.,  1., -1., -1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1.,\n",
       "         -1., -1., -1., -1.,  1.,  1., -1., -1., -1.,  1., -1., -1.,  1., -1.,\n",
       "          1.,  1., -1.,  1.,  1., -1., -1., -1.,  1.,  1., -1., -1.,  1.,  1.,\n",
       "         -1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1., -1., -1., -1., -1.,  1.,\n",
       "          1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1., -1.,\n",
       "          1.,  1., -1., -1., -1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1.,\n",
       "          1.,  1., -1., -1., -1.,  1., -1., -1.,  1.,  1., -1., -1., -1., -1.,\n",
       "          1., -1.,  1.,  1., -1., -1.,  1., -1.,  1., -1.,  1.,  1., -1., -1.]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keranl.train(x_train_pca, y_train,x_test_pca,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
