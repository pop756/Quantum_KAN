{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import sys\n",
    "import copy\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "lr = 0.01\n",
    "PCA_dim = 8\n",
    "CLS_num = 2\n",
    "\n",
    "\n",
    "\n",
    "with open('./data/data.pkl','rb') as file:\n",
    "    data = pickle.load(file)\n",
    "X = data['X']\n",
    "y = data['Y']\n",
    "\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "def Fit_to_quantum(X,PCA_dim):\n",
    "    pca = PCA(n_components=PCA_dim)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    return X_pca\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# PyTorch Tensor로 변환\n",
    "x_train_pca, y_train = torch.tensor(x_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long)\n",
    "x_test_pca, y_test = torch.tensor(x_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "\n",
    "class Feature_data_loader(Dataset):\n",
    "    def __init__(self,x_train,y_train):\n",
    "        self.feature1 = x_train\n",
    "        temp = copy.deepcopy(x_train)\n",
    "        shuffle = torch.randperm(len(temp))\n",
    "        self.feature2 = temp[shuffle]\n",
    "        self.y1 = y_train\n",
    "        temp_y = copy.deepcopy(y_train)\n",
    "        self.y2 = temp_y[shuffle]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.feature1)\n",
    "    def __getitem__(self,idx):\n",
    "        input1 = self.feature1[idx]\n",
    "        input2 = self.feature2[idx]\n",
    "        if self.y1[idx] == self.y2[idx]:\n",
    "            label = torch.tensor(1.).float()\n",
    "        else:\n",
    "            label = torch.tensor(0.).float()\n",
    "        return [input1,input2],label\n",
    "\n",
    "\n",
    "# DataLoader 생성\n",
    "\n",
    "\n",
    "feature_loader = DataLoader(Feature_data_loader(x_train_pca, y_train.float()),batch_size=batch_size,shuffle=True)\n",
    "test_feature_loader = DataLoader(Feature_data_loader(x_test_pca, y_test.float()),batch_size=batch_size,shuffle=False)\n",
    "train_loader = DataLoader(TensorDataset(x_train_pca, y_train.float()), batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(x_test_pca, y_test.float()), batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid=1\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 4.8628, Accuracy: 156.00000071525574/300 (52%)\n",
      "Epoch 1 Loss 0.765622 acc : 0.600568 reg : 0.000000 stop count : 0\n",
      "Test set: Average loss: 3.4188, Accuracy: 188.9999988079071/300 (63%)\n",
      "Epoch 2 Loss 0.578161 acc : 0.705587 reg : 0.000000 stop count : 0\n",
      "Test set: Average loss: 3.2568, Accuracy: 201.00000023841858/300 (67%)\n",
      "Epoch 3 Loss 0.522701 acc : 0.731723 reg : 0.000000 stop count : 0\n",
      "Test set: Average loss: 3.0613, Accuracy: 207.0000011920929/300 (69%)\n",
      "Epoch 4 Loss 0.480870 acc : 0.761837 reg : 0.000000 stop count : 0\n",
      "Test set: Average loss: 2.9001, Accuracy: 204.00000023841858/300 (68%)\n",
      "Epoch 5 Loss 0.450186 acc : 0.794508 reg : 0.000000 stop count : 0\n",
      "Test set: Average loss: 2.7848, Accuracy: 212.00000095367432/300 (71%)\n",
      "Epoch 6 Loss 0.420805 acc : 0.804072 reg : 0.000000 stop count : 0\n",
      "Test set: Average loss: 2.6658, Accuracy: 213.99999904632568/300 (71%)\n",
      "Epoch 7 Loss 0.381212 acc : 0.841572 reg : 0.000000 stop count : 0\n",
      "Test set: Average loss: 2.5774, Accuracy: 212.99999976158142/300 (71%)\n",
      "Epoch 8 Loss 0.346466 acc : 0.855777 reg : 0.000000 stop count : 0\n",
      "Test set: Average loss: 2.5337, Accuracy: 222.00000071525574/300 (74%)\n",
      "Epoch 9 Loss 0.312267 acc : 0.875189 reg : 0.000000 stop count : 0\n",
      "Test set: Average loss: 2.3761, Accuracy: 222.00000071525574/300 (74%)\n",
      "Epoch 10 Loss 0.280485 acc : 0.892519 reg : 0.000000 stop count : 0\n",
      "Test set: Average loss: 2.3525, Accuracy: 226.00000071525574/300 (75%)\n",
      "Epoch 11 Loss 0.247416 acc : 0.904356 reg : 0.000000 stop count : 0\n",
      "Test set: Average loss: 2.4018, Accuracy: 230.00000071525574/300 (77%)\n",
      "Epoch 12 Loss 0.218999 acc : 0.917235 reg : 0.000000 stop count : 1\n",
      "Test set: Average loss: 2.4028, Accuracy: 229.9999988079071/300 (77%)\n",
      "Epoch 13 Loss 0.187934 acc : 0.938920 reg : 0.000000 stop count : 2\n",
      "Test set: Average loss: 2.5397, Accuracy: 231.99999976158142/300 (77%)\n",
      "Epoch 14 Loss 0.183816 acc : 0.932955 reg : 0.000000 stop count : 3\n",
      "Test set: Average loss: 2.5643, Accuracy: 240.00000047683716/300 (80%)\n",
      "Epoch 15 Loss 0.168354 acc : 0.944413 reg : 0.000000 stop count : 4\n",
      "Test set: Average loss: 2.8063, Accuracy: 231.99999976158142/300 (77%)\n",
      "Epoch 16 Loss 0.147765 acc : 0.952652 reg : 0.000000 stop count : 5\n",
      "Test set: Average loss: 2.6757, Accuracy: 234.00000047683716/300 (78%)\n",
      "Epoch 17 Loss 0.129163 acc : 0.952746 reg : 0.000000 stop count : 6\n",
      "Test set: Average loss: 2.7936, Accuracy: 235.99999952316284/300 (79%)\n",
      "Epoch 18 Loss 0.109674 acc : 0.968655 reg : 0.000000 stop count : 7\n",
      "Test set: Average loss: 2.7735, Accuracy: 232.99999952316284/300 (78%)\n",
      "Epoch 19 Loss 0.100104 acc : 0.964205 reg : 0.000000 stop count : 8\n",
      "Test set: Average loss: 2.8526, Accuracy: 238.00000047683716/300 (79%)\n",
      "Epoch 20 Loss 0.100324 acc : 0.961553 reg : 0.000000 stop count : 9\n",
      "Test set: Average loss: 2.8498, Accuracy: 234.99999976158142/300 (78%)\n",
      "Epoch 21 Loss 0.075546 acc : 0.980114 reg : 0.000000 stop count : 10\n",
      "Test set: Average loss: 2.8521, Accuracy: 244.99999952316284/300 (82%)\n",
      "Epoch 22 Loss 0.063786 acc : 0.985701 reg : 0.000000 stop count : 11\n",
      "Test set: Average loss: 2.9386, Accuracy: 238.00000047683716/300 (79%)\n",
      "Epoch 23 Loss 0.060481 acc : 0.982860 reg : 0.000000 stop count : 12\n",
      "Test set: Average loss: 2.9702, Accuracy: 241.99999952316284/300 (81%)\n",
      "Epoch 24 Loss 0.053763 acc : 0.984280 reg : 0.000000 stop count : 13\n",
      "Test set: Average loss: 3.0313, Accuracy: 240.99999952316284/300 (80%)\n",
      "Epoch 25 Loss 0.049840 acc : 0.987027 reg : 0.000000 stop count : 14\n",
      "Test set: Average loss: 3.0701, Accuracy: 240.99999952316284/300 (80%)\n",
      "Epoch 26 Loss 0.043683 acc : 0.992898 reg : 0.000000 stop count : 15\n",
      "Test set: Average loss: 3.2429, Accuracy: 238.00000047683716/300 (79%)\n",
      "\n",
      " Pretrain acc : 238.00000047683716\n",
      "\n",
      "\n",
      "Test start\n",
      "\n",
      "\n",
      "\n",
      "Test set: Average loss: 3.5206, Accuracy: 150.99999964237213/300 (50%)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'HybridModel' object has no attribute 'KAN'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 142\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTest start\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    141\u001b[0m train_process \u001b[38;5;241m=\u001b[39m Early_stop_train_KAN(model, optimizer, criterion)\n\u001b[1;32m--> 142\u001b[0m \u001b[43mtrain_process\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mlamb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m _,acc \u001b[38;5;241m=\u001b[39m train_process\u001b[38;5;241m.\u001b[39mtest(test_loader)\n",
      "File \u001b[1;32mc:\\Users\\pop75\\OneDrive\\Desktop\\Quantum_KAN\\functions\\training.py:153\u001b[0m, in \u001b[0;36mEarly_stop_train_KAN.train_model\u001b[1;34m(self, train_loader, test_loader, epochs, res, lamb, device)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m    152\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(X_train)\n\u001b[1;32m--> 153\u001b[0m reg_ \u001b[38;5;241m=\u001b[39m lamb\u001b[38;5;241m*\u001b[39mreg(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mKAN\u001b[49m\u001b[38;5;241m.\u001b[39macts_scale,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mKAN)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(output\u001b[38;5;241m.\u001b[39msqueeze(), y_train)\u001b[38;5;241m+\u001b[39mreg_\n",
      "File \u001b[1;32mc:\\Users\\pop75\\anaconda3\\envs\\Lee\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1709\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1707\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1708\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1709\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'HybridModel' object has no attribute 'KAN'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import math\n",
    "from functions.training import Early_stop_train_KAN\n",
    "from kan import KAN\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "\"\"\"\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components=PCA_dim)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.PCA_dim, random_state=seed)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\"\"\"\n",
    "\n",
    "# Pennylane 장치 설정\n",
    "dev = qml.device(\"default.qubit\", wires=PCA_dim)\n",
    "\n",
    "\n",
    "def ZZFeatureMapLayer(features, wires):\n",
    "    \"\"\"사용자 정의 ZZFeatureMap 레이어\"\"\"\n",
    "    index = 0\n",
    "    for i in wires:\n",
    "        qml.Hadamard(wires=i)\n",
    "        qml.RZ(features[:,index], wires=i)\n",
    "        index += 1\n",
    "\n",
    "    for j in range(0, len(wires)-1):\n",
    "        qml.CNOT(wires=[j, j+1])\n",
    "        qml.RZ((features[:,index]), wires=j+1)\n",
    "        qml.CNOT(wires=[j, j+1])\n",
    "        index+=1\n",
    "\n",
    "def ansatz(params):\n",
    "    for j in range(len(params)):\n",
    "        # 각 큐비트에 대해 RX, RY, RZ 회전 적용\n",
    "        for i in range(len(params[0])):\n",
    "            qml.RY(params[j, i, 0], wires=i)\n",
    "            qml.RZ(params[j, i, 1], wires=i)\n",
    "            \n",
    "        # 인접한 큐비트 간 CNOT 게이트로 엔탱글링\n",
    "        if j == len(params)-1:\n",
    "            pass\n",
    "        else:\n",
    "            for i in range(len(params[0])-1):\n",
    "                qml.CNOT(wires=[i, i+1])\n",
    "\n",
    "\n",
    "# 양자 레이어 정의\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def QuantumLayer(features,params):\n",
    "    ZZFeatureMapLayer(features, wires=range(PCA_dim))\n",
    "    ansatz(params)\n",
    "    return qml.probs(wires=range(math.ceil(math.log2(CLS_num))))\n",
    "\n",
    "\n",
    "## 양자 커널\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def Kernal(features1,features2):\n",
    "    ZZFeatureMapLayer(features1, wires=range(PCA_dim))\n",
    "    qml.adjoint(ZZFeatureMapLayer)(features2,wires=range(PCA_dim))\n",
    "    return qml.probs(wires=range(PCA_dim))\n",
    "\n",
    "\n",
    "class Feature_model(nn.Module):\n",
    "    def __init__(self,grid,device='cpu'):\n",
    "        super(Feature_model,self).__init__()\n",
    "        KAN_model = KAN([PCA_dim,2*PCA_dim+1,PCA_dim*2-1],grid=grid,device=device)\n",
    "        self.KAN = KAN_model\n",
    "        self.Kernal = Kernal\n",
    "    def forward(self,inputs):\n",
    "        epsilon = 1e-6\n",
    "        input1 = inputs[0]\n",
    "        input2 = inputs[1]\n",
    "\n",
    "        input1 = nn.Sigmoid()(self.KAN(input1))*np.pi\n",
    "        input2 = nn.Sigmoid()(self.KAN(input2))*np.pi\n",
    "\n",
    "        output = self.Kernal(input1,input2)\n",
    "        output = output.type(torch.float32)\n",
    "        \n",
    "        return output[:,0].clamp(min=epsilon, max=1-epsilon)\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# 하이브리드 모델 정의\n",
    "\n",
    "grid = 2\n",
    "feature_model = Feature_model(grid,device); criterion = nn.BCELoss()\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(feature_model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "\n",
    "# 모델 학습 및 평가\n",
    "train_process = Early_stop_train_KAN(feature_model, optimizer, criterion)\n",
    "train_process.train_model(feature_loader,test_feature_loader,epochs=50,res=15,lamb=0)\n",
    "feature_model.KAN = feature_model.KAN.prune()\n",
    "res,pretrain_acc = train_process.test(test_feature_loader)\n",
    "print(f\"\\n Pretrain acc : {pretrain_acc}\")\n",
    "\n",
    "\n",
    "# 하이브리드 모델 정의\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HybridModel, self).__init__()\n",
    "        self.KAN = feature_model.KAN\n",
    "\n",
    "        self.quantum_layer = QuantumLayer\n",
    "        self.Q_params = nn.Parameter((torch.rand([PCA_dim,PCA_dim,2])*2-1)*np.pi,requires_grad=True)\n",
    "    def forward(self, x):\n",
    "        epsilon = 1e-6\n",
    "        x = self.KAN(x)*np.pi\n",
    "        #print(qml.draw(self.quantum_layer)(x,self.Q_params))\n",
    "        quantum_output = self.quantum_layer(x,self.Q_params)\n",
    "        quantum_output = quantum_output.type(torch.float32)\n",
    "        return quantum_output[:,0].clamp(min=epsilon, max=1-epsilon)\n",
    "    \n",
    "model = HybridModel(); criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam([model.Q_params], lr=0.01)\n",
    "print(\"\\n\\nTest start\\n\\n\")\n",
    "train_process = Early_stop_train_KAN(model, optimizer, criterion)\n",
    "train_process.train_model(train_loader,test_loader,epochs=25,lamb=0)\n",
    "\n",
    "_,acc = train_process.test(test_loader)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [07:41<00:00,  1.52it/s]\n",
      "c:\\Users\\pop75\\OneDrive\\Desktop\\Quantum_KAN\\functions\\training.py:215: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(y_train).float()\n",
      "c:\\Users\\pop75\\OneDrive\\Desktop\\Quantum_KAN\\functions\\training.py:231: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_test = torch.tensor(x_test).float()\n",
      "100%|██████████| 700/700 [04:57<00:00,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " acc :  0.8899999856948853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0000, 0.9539, 0.0398,  ..., 0.9406, 0.9788, 0.0257],\n",
       "         [0.9539, 1.0000, 0.1100,  ..., 0.8054, 0.8819, 0.0811],\n",
       "         [0.0398, 0.1100, 1.0000,  ..., 0.0071, 0.0172, 0.9944],\n",
       "         ...,\n",
       "         [0.9406, 0.8054, 0.0071,  ..., 1.0000, 0.9856, 0.0035],\n",
       "         [0.9788, 0.8819, 0.0172,  ..., 0.9856, 1.0000, 0.0099],\n",
       "         [0.0257, 0.0811, 0.9944,  ..., 0.0035, 0.0099, 1.0000]]),\n",
       " tensor([[0.0714, 0.1680, 0.9721,  ..., 0.0173, 0.0352, 0.9502],\n",
       "         [0.9432, 0.9952, 0.1210,  ..., 0.7925, 0.8705, 0.0911],\n",
       "         [0.9423, 0.8126, 0.0079,  ..., 0.9956, 0.9899, 0.0040],\n",
       "         ...,\n",
       "         [0.9476, 0.8191, 0.0084,  ..., 0.9983, 0.9915, 0.0043],\n",
       "         [0.4532, 0.6489, 0.5807,  ..., 0.2522, 0.3370, 0.5130],\n",
       "         [0.8459, 0.9556, 0.2047,  ..., 0.6598, 0.7494, 0.1646]]),\n",
       " tensor([0.5157, 0.5150, 0.5215, 0.5152, 0.5151, 0.5153, 0.5210, 0.5155, 0.5155,\n",
       "         0.5210, 0.5153, 0.5156, 0.5215, 0.5216, 0.5153, 0.5157, 0.5155, 0.5196,\n",
       "         0.5104, 0.5154, 0.5153, 0.5217, 0.5155, 0.5157, 0.5217, 0.5208, 0.5215,\n",
       "         0.5208, 0.5213, 0.5211, 0.5213, 0.5209, 0.5122, 0.5156, 0.5213, 0.5217,\n",
       "         0.5155, 0.5154, 0.5216, 0.5215, 0.5156, 0.5215, 0.5157, 0.5157, 0.5205,\n",
       "         0.5211, 0.5210, 0.5152, 0.5198, 0.5211, 0.5153, 0.5157, 0.5154, 0.5125,\n",
       "         0.5211, 0.5211, 0.5156, 0.5217, 0.5211, 0.5211, 0.5211, 0.5155, 0.5215,\n",
       "         0.5213, 0.5157, 0.5153, 0.5214, 0.5152, 0.5156, 0.5214, 0.5216, 0.5154,\n",
       "         0.5211, 0.5150, 0.5155, 0.5153, 0.5156, 0.5153, 0.5153, 0.5151, 0.5154,\n",
       "         0.5215, 0.5213, 0.5185, 0.5157, 0.5214, 0.5157, 0.5148, 0.5214, 0.5211,\n",
       "         0.5214, 0.5216, 0.5153, 0.5215, 0.5156, 0.5209, 0.5213, 0.5210, 0.5216,\n",
       "         0.5154, 0.5206, 0.5201, 0.5217, 0.5214, 0.5151, 0.5211, 0.5131, 0.5214,\n",
       "         0.5215, 0.5133, 0.5213, 0.5216, 0.5213, 0.5154, 0.5155, 0.5156, 0.5150,\n",
       "         0.5152, 0.5213, 0.5151, 0.5212, 0.5152, 0.5156, 0.5212, 0.5157, 0.5209,\n",
       "         0.5141, 0.5210, 0.5214, 0.5152, 0.5153, 0.5215, 0.5216, 0.5211, 0.5209,\n",
       "         0.5157, 0.5146, 0.5156, 0.5155, 0.5210, 0.5212, 0.5210, 0.5210, 0.5157,\n",
       "         0.5211, 0.5217, 0.5155, 0.5152, 0.5152, 0.5210, 0.5155, 0.5214, 0.5213,\n",
       "         0.5208, 0.5216, 0.5209, 0.5151, 0.5216, 0.5211, 0.5152, 0.5153, 0.5213,\n",
       "         0.5148, 0.5214, 0.5211, 0.5214, 0.5156, 0.5153, 0.5210, 0.5152, 0.5214,\n",
       "         0.5154, 0.5209, 0.5215, 0.5210, 0.5217, 0.5152, 0.5142, 0.5150, 0.5157,\n",
       "         0.5212, 0.5207, 0.5215, 0.5214, 0.5153, 0.5152, 0.5208, 0.5216, 0.5156,\n",
       "         0.5156, 0.5150, 0.5151, 0.5153, 0.5151, 0.5209, 0.5191, 0.5198, 0.5216,\n",
       "         0.5176, 0.5213, 0.5157, 0.5211, 0.5147, 0.5207, 0.5134, 0.5155, 0.5212,\n",
       "         0.5208, 0.5153, 0.5215, 0.5189, 0.5157, 0.5155, 0.5212, 0.5212, 0.5206,\n",
       "         0.5212, 0.5156, 0.5156, 0.5156, 0.5216, 0.5215, 0.5153, 0.5157, 0.5214,\n",
       "         0.5052, 0.5216, 0.5211, 0.5144, 0.5152, 0.5152, 0.5152, 0.5150, 0.5153,\n",
       "         0.5156, 0.5214, 0.5217, 0.5156, 0.5152, 0.5211, 0.5157, 0.5116, 0.5156,\n",
       "         0.5152, 0.5156, 0.5152, 0.5156, 0.5153, 0.5112, 0.5208, 0.5156, 0.5217,\n",
       "         0.5151, 0.5216, 0.5215, 0.5206, 0.5217, 0.5156, 0.5155, 0.5217, 0.5215,\n",
       "         0.5217, 0.5211, 0.5217, 0.5217, 0.5152, 0.5146, 0.5212, 0.5155, 0.5156,\n",
       "         0.5152, 0.5196, 0.5156, 0.5213, 0.5152, 0.5216, 0.5216, 0.5152, 0.5217,\n",
       "         0.5157, 0.5215, 0.5209, 0.5210, 0.5151, 0.5152, 0.5157, 0.5153, 0.5217,\n",
       "         0.5150, 0.5128, 0.5156, 0.5152, 0.5218, 0.5215, 0.5155, 0.5217, 0.5151,\n",
       "         0.5148, 0.5156, 0.5216, 0.5151, 0.5210, 0.5157, 0.5155, 0.5211, 0.5146,\n",
       "         0.5154, 0.5213, 0.5205, 0.5157, 0.5216, 0.5156, 0.5151, 0.5217, 0.5211,\n",
       "         0.5139, 0.5216, 0.5152, 0.5214, 0.5156, 0.5216, 0.5156, 0.5189, 0.5213,\n",
       "         0.5149, 0.5193, 0.5214, 0.5152, 0.5152, 0.5207, 0.5211, 0.5156, 0.5216,\n",
       "         0.5209, 0.5125, 0.5155, 0.5215, 0.5153, 0.5155, 0.5210, 0.5207, 0.5213,\n",
       "         0.5214, 0.5154, 0.5215, 0.5153, 0.5212, 0.5157, 0.5212, 0.5196, 0.5151,\n",
       "         0.5213, 0.5157, 0.5156, 0.5212, 0.5156, 0.5156, 0.5204, 0.5156, 0.5156,\n",
       "         0.5157, 0.5207, 0.5157, 0.5156, 0.5153, 0.5154, 0.5144, 0.5216, 0.5211,\n",
       "         0.5156, 0.5155, 0.5211, 0.5154, 0.5153, 0.5152, 0.5208, 0.5193, 0.5188,\n",
       "         0.5217, 0.5209, 0.5150, 0.5143, 0.5152, 0.5213, 0.5152, 0.5156, 0.5157,\n",
       "         0.5210, 0.5210, 0.5142, 0.5151, 0.5155, 0.5153, 0.5217, 0.5215, 0.5213,\n",
       "         0.5210, 0.5156, 0.5155, 0.5209, 0.5215, 0.5152, 0.5156, 0.5152, 0.5205,\n",
       "         0.5156, 0.5216, 0.5216, 0.5150, 0.5209, 0.5212, 0.5139, 0.5214, 0.5216,\n",
       "         0.5214, 0.5217, 0.5217, 0.5157, 0.5156, 0.5153, 0.5156, 0.5213, 0.5213,\n",
       "         0.5154, 0.5142, 0.5151, 0.5211, 0.5151, 0.5217, 0.5215, 0.5193, 0.5156,\n",
       "         0.5153, 0.5157, 0.5152, 0.5206, 0.5215, 0.5214, 0.5213, 0.5210, 0.5216,\n",
       "         0.5211, 0.5212, 0.5213, 0.5212, 0.5155, 0.5215, 0.5212, 0.5216, 0.5214,\n",
       "         0.5152, 0.5217, 0.5218, 0.5153, 0.5211, 0.5217, 0.5199, 0.5212, 0.5214,\n",
       "         0.5156, 0.5156, 0.5153, 0.5209, 0.5217, 0.5154, 0.5217, 0.5156, 0.5156,\n",
       "         0.5155, 0.5215, 0.5157, 0.5209, 0.5157, 0.5217, 0.5152, 0.5142, 0.5152,\n",
       "         0.5212, 0.5154, 0.5215, 0.5212, 0.5212, 0.5151, 0.5211, 0.5216, 0.5156,\n",
       "         0.5156, 0.5151, 0.5199, 0.5216, 0.5214, 0.5153, 0.5217, 0.5155, 0.5217,\n",
       "         0.5211, 0.5154, 0.5157, 0.5209, 0.5211, 0.5211, 0.5144, 0.5213, 0.5157,\n",
       "         0.5157, 0.5211, 0.5214, 0.5156, 0.5215, 0.5157, 0.5214, 0.5143, 0.5206,\n",
       "         0.5212, 0.5216, 0.5156, 0.5217, 0.5155, 0.5154, 0.5215, 0.5156, 0.5155,\n",
       "         0.5156, 0.5155, 0.5213, 0.5156, 0.5151, 0.5154, 0.5156, 0.5217, 0.5154,\n",
       "         0.5210, 0.5152, 0.5155, 0.5153, 0.5151, 0.5210, 0.5207, 0.5158, 0.5156,\n",
       "         0.5215, 0.5193, 0.5151, 0.5155, 0.5214, 0.5157, 0.5188, 0.5152, 0.5157,\n",
       "         0.5209, 0.5216, 0.5154, 0.5218, 0.5217, 0.5210, 0.5152, 0.5152, 0.5210,\n",
       "         0.5156, 0.5153, 0.5153, 0.5154, 0.5217, 0.5151, 0.5155, 0.5202, 0.5210,\n",
       "         0.5212, 0.5212, 0.5152, 0.5157, 0.5139, 0.5133, 0.5157, 0.5211, 0.5157,\n",
       "         0.5210, 0.5155, 0.5215, 0.5212, 0.5151, 0.5211, 0.5151, 0.5198, 0.5212,\n",
       "         0.5157, 0.5156, 0.5155, 0.5216, 0.5216, 0.5157, 0.5157, 0.5152, 0.5216,\n",
       "         0.5148, 0.5210, 0.5154, 0.5151, 0.5155, 0.5217, 0.5158, 0.5152, 0.5078,\n",
       "         0.5151, 0.5157, 0.5216, 0.5153, 0.5211, 0.5207, 0.5183, 0.5157, 0.5212,\n",
       "         0.5213, 0.5214, 0.5154, 0.5211, 0.5190, 0.5157, 0.5157, 0.5215, 0.5144,\n",
       "         0.5216, 0.5157, 0.5153, 0.5156, 0.5214, 0.5212, 0.5157, 0.5152, 0.5151,\n",
       "         0.5216, 0.5214, 0.5213, 0.5151, 0.5152, 0.5141, 0.5213, 0.5154, 0.5214,\n",
       "         0.5156, 0.5216, 0.5209, 0.5215, 0.5211, 0.5215, 0.5155, 0.5210, 0.5216,\n",
       "         0.5215, 0.5151, 0.5151, 0.5153, 0.5212, 0.5217, 0.5200, 0.5214, 0.5154,\n",
       "         0.5156, 0.5154, 0.5209, 0.5156, 0.5153, 0.5214, 0.5152, 0.5156, 0.5217,\n",
       "         0.5217, 0.5120, 0.5214, 0.5212, 0.5152, 0.5215, 0.5155, 0.5198, 0.5153,\n",
       "         0.5154, 0.5209, 0.5199, 0.5217, 0.5156, 0.5133, 0.5151, 0.5157, 0.5152,\n",
       "         0.5153, 0.5157, 0.5151, 0.5208, 0.5213, 0.5156, 0.5216, 0.5215, 0.5123,\n",
       "         0.5154, 0.5212, 0.5157, 0.5213, 0.5151, 0.5156, 0.5216],\n",
       "        requires_grad=True),\n",
       " tensor([ 1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1., -1.,\n",
       "          1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1., -1., -1., -1., -1.,\n",
       "         -1., -1., -1., -1., -1.,  1., -1., -1.,  1.,  1., -1., -1.,  1., -1.,\n",
       "          1.,  1., -1., -1., -1.,  1., -1., -1.,  1.,  1.,  1.,  1., -1., -1.,\n",
       "          1., -1., -1., -1., -1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1., -1.,\n",
       "         -1.,  1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1., -1.,\n",
       "          1., -1.,  1.,  1., -1., -1., -1., -1.,  1., -1.,  1., -1., -1., -1.,\n",
       "         -1.,  1., -1., -1., -1., -1.,  1., -1.,  1., -1., -1.,  1., -1., -1.,\n",
       "         -1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1., -1.,\n",
       "          1., -1., -1.,  1.,  1., -1., -1., -1., -1.,  1.,  1.,  1.,  1., -1.,\n",
       "         -1., -1., -1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1., -1., -1., -1.,\n",
       "         -1., -1.,  1., -1., -1.,  1.,  1., -1.,  1., -1., -1., -1.,  1.,  1.,\n",
       "         -1.,  1., -1.,  1., -1., -1., -1., -1.,  1.,  1.,  1.,  1., -1., -1.,\n",
       "         -1., -1.,  1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1.,\n",
       "         -1., -1., -1., -1.,  1., -1.,  1., -1.,  1.,  1., -1., -1.,  1., -1.,\n",
       "         -1.,  1.,  1., -1., -1., -1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1.,\n",
       "         -1.,  1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1., -1.,  1.,\n",
       "          1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1., -1.,  1., -1.,\n",
       "          1., -1., -1., -1., -1.,  1.,  1., -1., -1., -1., -1., -1., -1.,  1.,\n",
       "          1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1., -1.,  1., -1.,  1.,\n",
       "         -1., -1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1., -1.,\n",
       "          1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1.,  1.,  1., -1.,\n",
       "         -1.,  1., -1.,  1.,  1., -1., -1.,  1., -1.,  1., -1.,  1., -1.,  1.,\n",
       "         -1., -1.,  1., -1., -1.,  1.,  1., -1., -1.,  1., -1., -1.,  1.,  1.,\n",
       "         -1.,  1.,  1., -1., -1., -1., -1.,  1., -1.,  1., -1.,  1., -1., -1.,\n",
       "          1., -1.,  1.,  1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
       "          1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1.,  1.,  1., -1., -1., -1.,\n",
       "         -1., -1.,  1.,  1.,  1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,\n",
       "          1., -1., -1., -1., -1.,  1.,  1., -1., -1.,  1.,  1.,  1., -1.,  1.,\n",
       "         -1., -1.,  1., -1., -1.,  1., -1., -1., -1., -1., -1.,  1.,  1.,  1.,\n",
       "          1., -1., -1.,  1.,  1.,  1., -1.,  1., -1., -1., -1.,  1.,  1.,  1.,\n",
       "          1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,  1., -1., -1.,\n",
       "         -1., -1.,  1., -1., -1.,  1., -1., -1., -1., -1., -1.,  1.,  1.,  1.,\n",
       "         -1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1.,  1.,  1.,\n",
       "          1., -1.,  1., -1., -1., -1.,  1., -1., -1.,  1.,  1.,  1., -1., -1.,\n",
       "         -1.,  1., -1.,  1., -1., -1.,  1.,  1., -1., -1., -1.,  1., -1.,  1.,\n",
       "          1., -1., -1.,  1., -1.,  1., -1.,  1., -1., -1., -1.,  1., -1.,  1.,\n",
       "          1., -1.,  1.,  1.,  1.,  1., -1.,  1.,  1.,  1.,  1., -1.,  1., -1.,\n",
       "          1., -1.,  1.,  1., -1., -1.,  1.,  1., -1., -1.,  1.,  1., -1.,  1.,\n",
       "         -1.,  1.,  1., -1., -1.,  1., -1., -1., -1.,  1.,  1., -1.,  1.,  1.,\n",
       "          1.,  1., -1.,  1.,  1., -1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,\n",
       "         -1.,  1., -1.,  1., -1., -1.,  1., -1.,  1., -1., -1.,  1.,  1.,  1.,\n",
       "         -1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1.,  1.,  1.,\n",
       "          1.,  1.,  1., -1.,  1., -1., -1., -1.,  1., -1., -1., -1.,  1., -1.,\n",
       "         -1.,  1.,  1., -1.,  1., -1.,  1.,  1.,  1., -1., -1.,  1.,  1.,  1.,\n",
       "         -1., -1., -1.,  1.,  1.,  1., -1.,  1., -1.,  1., -1., -1., -1., -1.,\n",
       "         -1.,  1., -1., -1., -1.,  1.,  1.,  1., -1., -1., -1., -1.,  1.,  1.,\n",
       "          1., -1.,  1.,  1., -1.,  1.,  1., -1., -1.,  1., -1., -1.,  1., -1.,\n",
       "          1., -1.,  1.,  1., -1., -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "          1., -1., -1.,  1., -1., -1.,  1.,  1., -1.,  1., -1.,  1.,  1., -1.]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 커널 메소드\n",
    "from functions.training import Kernal_method\n",
    "\n",
    "kernal = Kernal_method(feature_model)\n",
    "\n",
    "kernel_matrix,test_kernel_matrix,alpha,labels = kernal.train(x_train_pca,y_train,x_test_pca,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
