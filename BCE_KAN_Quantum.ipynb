{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pennylane\n",
      "  Obtaining dependency information for pennylane from https://files.pythonhosted.org/packages/c0/c1/37d745789378cd2d8a48a6e2ecc9deb9948b984c074b87daa721ac0f6cf8/PennyLane-0.36.0-py3-none-any.whl.metadata\n",
      "  Downloading PennyLane-0.36.0-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: numpy<2.0 in c:\\users\\pad33\\anaconda3\\lib\\site-packages (from pennylane) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\pad33\\anaconda3\\lib\\site-packages (from pennylane) (1.10.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\pad33\\anaconda3\\lib\\site-packages (from pennylane) (3.1)\n",
      "Collecting rustworkx (from pennylane)\n",
      "  Obtaining dependency information for rustworkx from https://files.pythonhosted.org/packages/49/2a/caeba6c6f0ce37f96dadf329d1d06db7c48cd9dea065df5543a2cdf3b776/rustworkx-0.14.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading rustworkx-0.14.2-cp311-cp311-win_amd64.whl.metadata (10 kB)\n",
      "Collecting autograd (from pennylane)\n",
      "  Obtaining dependency information for autograd from https://files.pythonhosted.org/packages/81/70/d5c7c2a458b8be96495c8b1634c2155beab58cbe864b7a9a5c06c2e52520/autograd-1.6.2-py3-none-any.whl.metadata\n",
      "  Downloading autograd-1.6.2-py3-none-any.whl.metadata (706 bytes)\n",
      "Requirement already satisfied: toml in c:\\users\\pad33\\anaconda3\\lib\\site-packages (from pennylane) (0.10.2)\n",
      "Requirement already satisfied: appdirs in c:\\users\\pad33\\anaconda3\\lib\\site-packages (from pennylane) (1.4.4)\n",
      "Collecting semantic-version>=2.7 (from pennylane)\n",
      "  Obtaining dependency information for semantic-version>=2.7 from https://files.pythonhosted.org/packages/6a/23/8146aad7d88f4fcb3a6218f41a60f6c2d4e3a72de72da1825dc7c8f7877c/semantic_version-2.10.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting autoray>=0.6.1 (from pennylane)\n",
      "  Obtaining dependency information for autoray>=0.6.1 from https://files.pythonhosted.org/packages/e4/b4/51bab53d8b74f4c5bc3b3b8e6f93e3f5ad32e6f3475dbc90facd0957f125/autoray-0.6.10-py3-none-any.whl.metadata\n",
      "  Downloading autoray-0.6.10-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting cachetools (from pennylane)\n",
      "  Obtaining dependency information for cachetools from https://files.pythonhosted.org/packages/fb/2b/a64c2d25a37aeb921fddb929111413049fc5f8b9a4c1aefaffaafe768d54/cachetools-5.3.3-py3-none-any.whl.metadata\n",
      "  Downloading cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pennylane-lightning>=0.36 (from pennylane)\n",
      "  Obtaining dependency information for pennylane-lightning>=0.36 from https://files.pythonhosted.org/packages/b3/ca/334844dae89ca23b7a091623cb346e7c8ac07e3831383de1bf1b0ab0f647/PennyLane_Lightning-0.36.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading PennyLane_Lightning-0.36.0-cp311-cp311-win_amd64.whl.metadata (21 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\pad33\\anaconda3\\lib\\site-packages (from pennylane) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\pad33\\anaconda3\\lib\\site-packages (from pennylane) (4.7.1)\n",
      "Requirement already satisfied: future>=0.15.2 in c:\\users\\pad33\\anaconda3\\lib\\site-packages (from autograd->pennylane) (0.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pad33\\anaconda3\\lib\\site-packages (from requests->pennylane) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pad33\\anaconda3\\lib\\site-packages (from requests->pennylane) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pad33\\anaconda3\\lib\\site-packages (from requests->pennylane) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pad33\\anaconda3\\lib\\site-packages (from requests->pennylane) (2023.7.22)\n",
      "Downloading PennyLane-0.36.0-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   --------------------------------- ------ 1.4/1.7 MB 45.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 35.7 MB/s eta 0:00:00\n",
      "Downloading autoray-0.6.10-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.8/50.8 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading PennyLane_Lightning-0.36.0-cp311-cp311-win_amd64.whl (5.6 MB)\n",
      "   ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 2.4/5.6 MB 78.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 4.2/5.6 MB 67.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.6/5.6 MB 59.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.6/5.6 MB 44.7 MB/s eta 0:00:00\n",
      "Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading autograd-1.6.2-py3-none-any.whl (49 kB)\n",
      "   ---------------------------------------- 0.0/49.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 49.3/49.3 kB ? eta 0:00:00\n",
      "Downloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Downloading rustworkx-0.14.2-cp311-cp311-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ---------------------------------------  1.6/1.6 MB 48.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 33.0 MB/s eta 0:00:00\n",
      "Installing collected packages: semantic-version, rustworkx, cachetools, autoray, autograd, pennylane-lightning, pennylane\n",
      "Successfully installed autograd-1.6.2 autoray-0.6.10 cachetools-5.3.3 pennylane-0.36.0 pennylane-lightning-0.36.0 rustworkx-0.14.2 semantic-version-2.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pennylane\n",
    "!pip install pykan\n",
    "#!git clone https://github.com/pop756/Quantum_machine.git\n",
    "#%cd Quantum_machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import sys\n",
    "import copy\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from functions import training\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "lr = 0.01\n",
    "PCA_dim = 8\n",
    "CLS_num = 2\n",
    "device = 'cpu'\n",
    "\n",
    "\n",
    "with open('./data/data.pkl','rb') as file:\n",
    "    data = pickle.load(file)\n",
    "X = data['X']\n",
    "y = data['Y']\n",
    "\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "def Fit_to_quantum(X,PCA_dim):\n",
    "    pca = PCA(n_components=PCA_dim)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    return X_pca\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# PyTorch Tensor로 변환\n",
    "x_train_pca, y_train = torch.tensor(x_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long)\n",
    "x_test_pca, y_test = torch.tensor(x_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "\n",
    "class Feature_data_loader(Dataset):\n",
    "    def __init__(self,x_train,y_train):\n",
    "        self.feature1 = x_train\n",
    "        temp = copy.deepcopy(x_train)\n",
    "        shuffle = torch.randperm(len(temp))\n",
    "        self.feature2 = temp[shuffle]\n",
    "        self.y1 = y_train\n",
    "        temp_y = copy.deepcopy(y_train)\n",
    "        self.y2 = temp_y[shuffle]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.feature1)\n",
    "    def __getitem__(self,idx):\n",
    "        input1 = self.feature1[idx]\n",
    "        input2 = self.feature2[idx]\n",
    "        if self.y1[idx] == self.y2[idx]:\n",
    "            label = torch.tensor(1.).float()\n",
    "        else:\n",
    "            label = torch.tensor(0.).float()\n",
    "        return [input1,input2],label\n",
    "\n",
    "\n",
    "# DataLoader 생성\n",
    "\n",
    "\n",
    "feature_loader = DataLoader(Feature_data_loader(x_train_pca, y_train.float()),batch_size=batch_size,shuffle=True)\n",
    "test_feature_loader = DataLoader(Feature_data_loader(x_test_pca, y_test.float()),batch_size=batch_size,shuffle=False)\n",
    "train_loader = DataLoader(TensorDataset(x_train_pca, y_train), batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(x_test_pca, y_test), batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (operation.py, line 1471)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"c:\\Users\\pad33\\anaconda3\\envs\\LEE\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m3457\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[0;32m\"C:\\Users\\pad33\\AppData\\Local\\Temp\\ipykernel_14908\\3885169768.py\"\u001b[0m, line \u001b[0;32m8\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    import pennylane as qml\n",
      "  File \u001b[0;32m\"c:\\Users\\pad33\\anaconda3\\envs\\LEE\\lib\\site-packages\\pennylane\\__init__.py\"\u001b[0m, line \u001b[0;32m31\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    import pennylane.kernels\n",
      "  File \u001b[0;32m\"c:\\Users\\pad33\\anaconda3\\envs\\LEE\\lib\\site-packages\\pennylane\\kernels\\__init__.py\"\u001b[0m, line \u001b[0;32m18\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    from .cost_functions import (\n",
      "  File \u001b[0;32m\"c:\\Users\\pad33\\anaconda3\\envs\\LEE\\lib\\site-packages\\pennylane\\kernels\\cost_functions.py\"\u001b[0m, line \u001b[0;32m18\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    from pennylane import numpy as np\n",
      "  File \u001b[0;32m\"c:\\Users\\pad33\\anaconda3\\envs\\LEE\\lib\\site-packages\\pennylane\\numpy\\__init__.py\"\u001b[0m, line \u001b[0;32m87\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    from .wrapper import wrap_arrays, extract_tensors, tensor_wrapper\n",
      "  File \u001b[0;32m\"c:\\Users\\pad33\\anaconda3\\envs\\LEE\\lib\\site-packages\\pennylane\\numpy\\wrapper.py\"\u001b[0m, line \u001b[0;32m23\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    from .tensor import tensor\n",
      "\u001b[1;36m  File \u001b[1;32m\"c:\\Users\\pad33\\anaconda3\\envs\\LEE\\lib\\site-packages\\pennylane\\numpy\\tensor.py\"\u001b[1;36m, line \u001b[1;32m25\u001b[1;36m, in \u001b[1;35m<module>\u001b[1;36m\u001b[0m\n\u001b[1;33m    from pennylane.operation import Operator\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"c:\\Users\\pad33\\anaconda3\\envs\\LEE\\lib\\site-packages\\pennylane\\operation.py\"\u001b[1;36m, line \u001b[1;32m1471\u001b[0m\n\u001b[1;33m    if (p_rep := new_op._pauli_rep) is not None:\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import math\n",
    "lamb_list = [0.005*(i+1) for i in range(100)]\n",
    "lamb_entropy_list = [0.2*(i+1) for i in range(10)]\n",
    "grid=1\n",
    "\n",
    "result_dict  = []\n",
    "\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "\"\"\"\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components=PCA_dim)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.PCA_dim, random_state=seed)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\"\"\"\n",
    "\n",
    "# Pennylane 장치 설정\n",
    "dev = qml.device(\"default.qubit\", wires=PCA_dim)\n",
    "\n",
    "\n",
    "def ZZFeatureMapLayer(features, wires):\n",
    "    \"\"\"사용자 정의 ZZFeatureMap 레이어\"\"\"\n",
    "    index = 0\n",
    "    for i in wires:\n",
    "        qml.Hadamard(wires=i)\n",
    "        qml.RZ(features[:,index], wires=i)\n",
    "        index += 1\n",
    "\n",
    "    for j in range(0, len(wires)-1):\n",
    "        qml.CNOT(wires=[j, j+1])\n",
    "        qml.RZ((features[:,index]), wires=j+1)\n",
    "        qml.CNOT(wires=[j, j+1])\n",
    "        index+=1\n",
    "\n",
    "def ansatz(params):\n",
    "    for j in range(len(params)):\n",
    "        # 각 큐비트에 대해 RX, RY, RZ 회전 적용\n",
    "        for i in range(len(params[0])):\n",
    "            qml.RY(params[j, i, 0], wires=i)\n",
    "            qml.RZ(params[j, i, 1], wires=i)\n",
    "            \n",
    "        # 인접한 큐비트 간 CNOT 게이트로 엔탱글링\n",
    "        if j == len(params)-1:\n",
    "            pass\n",
    "        else:\n",
    "            for i in range(len(params[0])-1):\n",
    "                qml.CNOT(wires=[i, i+1])\n",
    "\n",
    "\n",
    "# 양자 레이어 정의\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def QuantumLayer(features,params):\n",
    "    ZZFeatureMapLayer(features, wires=range(PCA_dim))\n",
    "    ansatz(params)\n",
    "    return qml.probs(wires=range(math.ceil(math.log2(CLS_num))))\n",
    "\n",
    "\n",
    "## 양자 커널\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def Kernal(features1,features2):\n",
    "    ZZFeatureMapLayer(features1, wires=range(PCA_dim))\n",
    "    qml.adjoint(ZZFeatureMapLayer)(features2,wires=range(PCA_dim))\n",
    "    return qml.probs(wires=range(PCA_dim))\n",
    "\n",
    "\n",
    "class Feature_model(nn.Module):\n",
    "    def __init__(self,grid,device='cpu'):\n",
    "        super(Feature_model,self).__init__()\n",
    "        KAN_model = KAN([PCA_dim,2*PCA_dim+1,PCA_dim*2-1],grid=grid,device=device)\n",
    "        self.KAN = KAN_model\n",
    "        self.Kernal = Kernal\n",
    "    def forward(self,inputs):\n",
    "        epsilon = 1e-6\n",
    "        input1 = inputs[0]\n",
    "        #input1_copy = input1.clone().detach().requires_grad_(True)\n",
    "        input2 = inputs[1]\n",
    "        #input2_copy = input2.clone().detach().requires_grad_(True)\n",
    "        input1 = nn.Sigmoid()(self.KAN(input1))*np.pi\n",
    "        #input1 = torch.concat([input1,input1_copy],dim=1)\n",
    "        input2 = nn.Sigmoid()(self.KAN(input2))*np.pi\n",
    "        #input2 = torch.concat([input2,input2_copy],dim=1)\n",
    "        output = self.Kernal(input1,input2)\n",
    "        output = output.type(torch.float32)\n",
    "        \n",
    "        return output[:,0].clamp(min=epsilon, max=1-epsilon)\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# 하이브리드 모델 정의\n",
    "\n",
    "    \n",
    "def search(params):\n",
    "    print(f\"Test set \\n lamb : {params['lamb']} \\n lamb_enp :  {params['lamb_entropy']} \\n grid : {params['grid']}\")\n",
    "    grid = params['grid']\n",
    "    feature_model = Feature_model(grid,device); criterion = nn.BCELoss()\n",
    "\n",
    "\n",
    "    optimizer = optim.Adam(feature_model.parameters(), lr=0.01)\n",
    "\n",
    "    \n",
    "    \n",
    "    # 모델 학습 및 평가\n",
    "    train_process = training.Early_stop_train_KAN(feature_model, optimizer, criterion)\n",
    "    train_process.train_model(feature_loader,test_feature_loader,epochs=50,res=15,lamb=params['lamb'],lamb_entropy=params['lamb_entropy'])\n",
    "    #feature_model.KAN.plot(beta=3,scale=2)\n",
    "    feature_model.KAN = feature_model.KAN.prune()\n",
    "    res,pretrain_acc = train_process.test(test_feature_loader)\n",
    "    print(f\"\\n Pretrain acc : {pretrain_acc}\")\n",
    "    class HybridModel(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(HybridModel, self).__init__()\n",
    "            self.KAN = feature_model.KAN\n",
    "            \n",
    "            self.quantum_layer = QuantumLayer\n",
    "            self.Q_params = nn.Parameter((torch.rand([PCA_dim,PCA_dim,2])*2-1)*np.pi,requires_grad=True)\n",
    "        def forward(self, x):\n",
    "            x = nn.Sigmoid()(self.KAN(x))*np.pi\n",
    "            quantum_output = self.quantum_layer(x,self.Q_params)\n",
    "            quantum_output = quantum_output.type(torch.float32)\n",
    "            return torch.log(quantum_output)\n",
    "    model = HybridModel(); criterion = nn.NLLLoss()\n",
    "\n",
    "    for param in model.KAN.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    optimizer = optim.Adam([model.Q_params], lr=0.01)\n",
    "    print(\"\\n\\nTest start\\n\\n\")\n",
    "    train_process = Early_stop_train(model, optimizer, criterion)\n",
    "    train_process.train_model(train_loader,test_loader,epochs=25,lamb=0)\n",
    "\n",
    "    _,acc = train_process.test(test_loader)\n",
    "    print(f\"Test Accuracy: {acc:.2f}\")\n",
    "    result_dict.append({\"lamb\":params['lamb'],\"lamb_entropy\":f\"{params['lamb_entropy']:.1f}\", \"grid\":grid,\"acc\" : acc,\"pretrain_acc\" : pretrain_acc})\n",
    "    result = pd.DataFrame(result_dict)\n",
    "    result.to_csv('./Results.csv',index=False)\n",
    "    return -res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hyperopt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14908\\2292203063.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mhyperopt\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSTATUS_OK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTrials\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m space = {\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'hyperopt'"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "space = {\n",
    "    'lamb': hp.uniform('lamb',0,0.1),\n",
    "    'lamb_entropy': hp.uniform('lamb_entropy',0,2),\n",
    "    'grid' : hp.choice('grid',range(1,9))\n",
    "}\n",
    "\n",
    "best = fmin(fn=search, space=space, algo=tpe.suggest, max_evals=100,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
