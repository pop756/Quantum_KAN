{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pennylane\n",
    "!pip install pykan\n",
    "!git clone https://github.com/pop756/Quantum_machine.git\n",
    "%cd Quantum_machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import sys\n",
    "import copy\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "batch_size = 64\n",
    "epochs = 10\n",
    "lr = 0.01\n",
    "PCA_dim = 8\n",
    "CLS_num = 2\n",
    "\n",
    "\n",
    "\n",
    "with open('./data.pkl','rb') as file:\n",
    "    data = pickle.load(file)\n",
    "X = data['X']\n",
    "y = data['Y']\n",
    "\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "def Fit_to_quantum(X,PCA_dim):\n",
    "    pca = PCA(n_components=PCA_dim)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    return X_pca\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# PyTorch Tensor로 변환\n",
    "x_train_pca, y_train = torch.tensor(x_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long)\n",
    "x_test_pca, y_test = torch.tensor(x_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "\n",
    "class Feature_data_loader(Dataset):\n",
    "    def __init__(self,x_train,y_train):\n",
    "        self.feature1 = x_train\n",
    "        temp = copy.deepcopy(x_train)\n",
    "        shuffle = torch.randperm(len(temp))\n",
    "        self.feature2 = temp[shuffle]\n",
    "        self.y1 = y_train\n",
    "        temp_y = copy.deepcopy(y_train)\n",
    "        self.y2 = temp_y[shuffle]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.feature1)\n",
    "    def __getitem__(self,idx):\n",
    "        input1 = self.feature1[idx]\n",
    "        input2 = self.feature2[idx]\n",
    "        if self.y1[idx] == self.y2[idx]:\n",
    "            label = torch.tensor(1.).float()\n",
    "        else:\n",
    "            label = torch.tensor(0.).float()\n",
    "        return [input1,input2],label\n",
    "\n",
    "\n",
    "# DataLoader 생성\n",
    "\n",
    "\n",
    "feature_loader = DataLoader(Feature_data_loader(x_train_pca, y_train.float()),batch_size=batch_size,shuffle=True)\n",
    "test_feature_loader = DataLoader(Feature_data_loader(x_test_pca, y_test.float()),batch_size=batch_size,shuffle=False)\n",
    "train_loader = DataLoader(TensorDataset(x_train_pca, y_train), batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(TensorDataset(x_test_pca, y_test), batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kan import KAN, create_dataset\n",
    "def reg(acts_scale,KAN_layer, factor=1,lamb_l1=1.,lamb_entropy=2.,lamb_coef=0.,lamb_coefdiff=0.):\n",
    "\n",
    "    def nonlinear(x, th=1e-16):\n",
    "        return (x < th) * x * factor + (x > th) * (x + (factor - 1) * th)\n",
    "\n",
    "    reg_ = 0.\n",
    "    for i in range(len(acts_scale)):\n",
    "        vec = acts_scale[i].reshape(-1, )\n",
    "\n",
    "        p = vec / torch.sum(vec)\n",
    "        l1 = torch.sum(nonlinear(vec))\n",
    "        entropy = - torch.sum(p * torch.log2(p + 1e-4))\n",
    "        reg_ += lamb_l1 * l1 + lamb_entropy * entropy  # both l1 and entropy\n",
    "\n",
    "    # regularize coefficient to encourage spline to be zero\n",
    "    for i in range(len(KAN_layer.act_fun)):\n",
    "        coeff_l1 = torch.sum(torch.mean(torch.abs(KAN_layer.act_fun[i].coef), dim=1))\n",
    "        coeff_diff_l1 = torch.sum(torch.mean(torch.abs(torch.diff(KAN_layer.act_fun[i].coef)), dim=1))\n",
    "        reg_ += lamb_coef * coeff_l1 + lamb_coefdiff * coeff_diff_l1\n",
    "\n",
    "    return reg_\n",
    "def accuracy(pred, true):\n",
    "    # 예측값이 로짓 혹은 확률값인 경우, 최대 값을 가진 인덱스를 구함 (가장 확률이 높은 클래스)\n",
    "    pred = pred.detach().cpu()\n",
    "    true = true.cpu()\n",
    "    try:\n",
    "        pred_labels = torch.argmax(pred, dim=1)\n",
    "    except:\n",
    "        pred_labels = torch.round(pred)\n",
    "    # 예측 레이블과 실제 레이블이 일치하는 경우를 계산\n",
    "    correct = (pred_labels == true).sum()\n",
    "    # 정확도를 계산\n",
    "    acc = correct / true.size(0)\n",
    "    return acc.item() \n",
    "\n",
    "class Early_stop_train():\n",
    "    def __init__(self,model, optimizer, criterion):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        \n",
    "\n",
    "        \n",
    "        self.loss_list = [1e100]\n",
    "        self.acc_list = []\n",
    "        self.stop_count = 0\n",
    "        \n",
    "    def train_model(self,train_loader,test_loader=None ,epochs=200,res = 10,lamb=0.,lamb_entropy=2.):\n",
    "        #self.model.train()\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            if self.stop_count>=res:\n",
    "                break\n",
    "            loss_val,_ = self.test(test_loader)\n",
    "            self.loss_list.append(loss_val)\n",
    "            \n",
    "            if self.loss_list[-1]>=np.min(self.loss_list[:-1]):\n",
    "                self.stop_count+=1\n",
    "            else:\n",
    "                self.optimal = copy.deepcopy(self.model.state_dict())\n",
    "                self.stop_count = 0\n",
    "            loss_list = []\n",
    "            acc_list = []\n",
    "            for X_train,y_train in train_loader:\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.model(X_train)\n",
    "                reg_ = lamb*reg(self.model.KAN.acts_scale,self.model.KAN,lamb_entropy=lamb_entropy)\n",
    "                try:\n",
    "                    loss = self.criterion(output.squeeze(), y_train)+reg_\n",
    "                except:\n",
    "                    print(output)\n",
    "                    raise\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                loss_list.append(loss.item())\n",
    "                acc = accuracy(output,y_train)\n",
    "                acc_list.append(acc)\n",
    "                sys.stdout.write(f\"\\rEpoch {epoch+1} Loss {np.mean(loss_list):4f} acc : {np.mean(acc_list):4f} reg : {reg_:4f} stop count : {self.stop_count} lamb : {lamb} lamb_enp : {lamb_entropy}\")\n",
    "        self.model.load_state_dict(self.optimal)\n",
    "    def test(self,test_loader):\n",
    "        if test_loader is None:\n",
    "            return 0,0\n",
    "        else:\n",
    "            #self.model.eval()\n",
    "            test_loss = 0\n",
    "            correct = 0\n",
    "            with torch.no_grad():\n",
    "                for data, target in test_loader:\n",
    "                    output = self.model(data)\n",
    "\n",
    "                    test_loss += self.criterion(output.squeeze(), target).item()\n",
    "                    \n",
    "                    correct += accuracy(output,target)*len(output)\n",
    "\n",
    "            print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)')\n",
    "            return test_loss,correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import math\n",
    "lamb_list = [0.005*(i+1) for i in range(100)]\n",
    "lamb_entropy_list = [0.2*(i+1) for i in range(10)]\n",
    "\n",
    "\n",
    "result_dict  = []\n",
    "\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "\"\"\"\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components=PCA_dim)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.PCA_dim, random_state=seed)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\"\"\"\n",
    "\n",
    "# Pennylane 장치 설정\n",
    "dev = qml.device(\"default.qubit\", wires=PCA_dim)\n",
    "\n",
    "\n",
    "def ZZFeatureMapLayer(features, wires):\n",
    "    \"\"\"사용자 정의 ZZFeatureMap 레이어\"\"\"\n",
    "    index = 0\n",
    "    for i in wires:\n",
    "        qml.Hadamard(wires=i)\n",
    "        qml.RZ(features[:,index], wires=i)\n",
    "        index += 1\n",
    "\n",
    "    for j in range(0, len(wires)-1):\n",
    "        qml.CNOT(wires=[j, j+1])\n",
    "        qml.RZ((features[:,index]), wires=j+1)\n",
    "        qml.CNOT(wires=[j, j+1])\n",
    "        index+=1\n",
    "\n",
    "def ansatz(params):\n",
    "    for j in range(len(params)):\n",
    "        # 각 큐비트에 대해 RX, RY, RZ 회전 적용\n",
    "        for i in range(len(params[0])):\n",
    "            qml.RY(params[j, i, 0], wires=i)\n",
    "            qml.RZ(params[j, i, 1], wires=i)\n",
    "            \n",
    "        # 인접한 큐비트 간 CNOT 게이트로 엔탱글링\n",
    "        if j == len(params)-1:\n",
    "            pass\n",
    "        else:\n",
    "            for i in range(len(params[0])-1):\n",
    "                qml.CNOT(wires=[i, i+1])\n",
    "\n",
    "\n",
    "# 양자 레이어 정의\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def QuantumLayer(features,params):\n",
    "    ZZFeatureMapLayer(features, wires=range(PCA_dim))\n",
    "    ansatz(params)\n",
    "    return qml.probs(wires=range(math.ceil(math.log2(CLS_num))))\n",
    "\n",
    "\n",
    "## 양자 커널\n",
    "@qml.qnode(dev, interface='torch')\n",
    "def Kernal(features1,features2):\n",
    "    ZZFeatureMapLayer(features1, wires=range(PCA_dim))\n",
    "    qml.adjoint(ZZFeatureMapLayer)(features2,wires=range(PCA_dim))\n",
    "    return qml.probs(wires=range(PCA_dim))\n",
    "\n",
    "\n",
    "class Feature_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Feature_model,self).__init__()\n",
    "        KAN_model = KAN([PCA_dim,PCA_dim*4+1,PCA_dim*2-1],grid=5,)\n",
    "        \"\"\"\n",
    "        for i in range(PCA_dim):\n",
    "            temp_list = [i for i in range(PCA_dim*2-1)]\n",
    "            temp_list.remove(i)\n",
    "            for j in temp_list:\n",
    "                KAN_model.remove_edge(0,i,j)\n",
    "        for i in range(PCA_dim-1):\n",
    "            if i == 0:\n",
    "                temp_list = [i for i in range(PCA_dim*2-1)]\n",
    "                temp_list.remove(i+PCA_dim)\n",
    "                for j in temp_list:\n",
    "                    KAN_model.remove_edge(0,i,j)\n",
    "            elif i == PCA_dim-2:\n",
    "                temp_list = [i for i in range(PCA_dim*2-1)]\n",
    "                temp_list.remove(PCA_dim*2-2)\n",
    "                for j in temp_list:\n",
    "                    KAN_model.remove_edge(0,i,j)\n",
    "            else:\n",
    "                temp_list = [i for i in range(PCA_dim*2-1)]\n",
    "                temp_list.remove(i+PCA_dim)\n",
    "                temp_list.remove(i+PCA_dim-1)\n",
    "                for j in temp_list:\n",
    "                    KAN_model.remove_edge(0,i,j)\n",
    "                    \n",
    "        for i in range(2*PCA_dim-1):\n",
    "            temp_list = [i for i in range(PCA_dim*2-1)]\n",
    "            temp_list.remove(i)\n",
    "            for j in temp_list:\n",
    "                KAN_model.remove_edge(1,i,j)\n",
    "        \"\"\"\n",
    "        self.KAN = KAN_model\n",
    "        self.Kernal = Kernal\n",
    "    def forward(self,inputs):\n",
    "        epsilon = 1e-6\n",
    "        input1 = inputs[0]\n",
    "        #input1_copy = input1.clone().detach().requires_grad_(True)\n",
    "        input2 = inputs[1]\n",
    "        #input2_copy = input2.clone().detach().requires_grad_(True)\n",
    "        input1 = nn.Sigmoid()(self.KAN(input1))*np.pi\n",
    "        #input1 = torch.concat([input1,input1_copy],dim=1)\n",
    "        input2 = nn.Sigmoid()(self.KAN(input2))*np.pi\n",
    "        #input2 = torch.concat([input2,input2_copy],dim=1)\n",
    "        output = self.Kernal(input1,input2)\n",
    "        output = output.type(torch.float32)\n",
    "        \n",
    "        return output[:,0].clamp(min=epsilon, max=1-epsilon)\n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# 하이브리드 모델 정의\n",
    "class HybridModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HybridModel, self).__init__()\n",
    "        self.KAN = feature_model.KAN\n",
    "        \n",
    "        self.quantum_layer = QuantumLayer\n",
    "        self.Q_params = nn.Parameter((torch.rand([PCA_dim,PCA_dim,2])*2-1)*np.pi,requires_grad=True)\n",
    "    def forward(self, x):\n",
    "        x = nn.Sigmoid()(self.KAN(x))*np.pi\n",
    "        #print(qml.draw(self.quantum_layer)(x,self.Q_params))\n",
    "        quantum_output = self.quantum_layer(x,self.Q_params)\n",
    "        quantum_output = quantum_output.type(torch.float32)\n",
    "        return torch.log(quantum_output)\n",
    "    \n",
    "def search(params):\n",
    "    print(f\"Test set \\n lamb : {params['lamb']} \\n lamb_enp :  {params['lamb_entropy']}\")\n",
    "    \n",
    "    feature_model = Feature_model(); criterion = nn.BCELoss()\n",
    "\n",
    "\n",
    "    optimizer = optim.Adam(feature_model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "    \n",
    "    # 모델 학습 및 평가\n",
    "    train_process = Early_stop_train(feature_model, optimizer, criterion)\n",
    "    train_process.train_model(feature_loader,test_feature_loader,epochs=50,res=15,**params)\n",
    "    #feature_model.KAN.plot(beta=3,scale=2)\n",
    "    feature_model.KAN = feature_model.KAN.prune()\n",
    "    _,pretrain_acc = train_process.test(test_feature_loader)\n",
    "    print(f\"\\n Pretrain acc : {pretrain_acc}\")\n",
    "\n",
    "    model = HybridModel(); criterion = nn.NLLLoss()\n",
    "\n",
    "    for param in model.KAN.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    optimizer = optim.Adam([model.Q_params], lr=0.01)\n",
    "    print(\"\\n\\nTest start\\n\\n\")\n",
    "    train_process = Early_stop_train(model, optimizer, criterion)\n",
    "    train_process.train_model(train_loader,test_loader,epochs=25,lamb=0)\n",
    "\n",
    "    _,acc = train_process.test(test_loader)\n",
    "    print(f\"Test Accuracy: {acc:.2f}\")\n",
    "    result_dict.append({\"lamb\":params['lamb'],\"lamb_entropy\":f\"{params['lamb_entropy']:.1f}\",\"acc\" : acc,\"pretrain_acc\" : pretrain_acc})\n",
    "    result = pd.DataFrame(result_dict)\n",
    "    result.to_csv('./Results.csv',index=False)\n",
    "    return -result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set                                               \n",
      " lamb : 0.8659721768663098 \n",
      " lamb_enp :  3.263178723042085\n",
      "                                                       \n",
      "Test set: Average loss: 4.8315, Accuracy: 167.00000071525574/300 (56%)\n",
      "Epoch 1 Loss 80.642052 acc : 0.625000 reg : 79.750870 stop count : 0 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 1 Loss 79.879551 acc : 0.531250 reg : 77.844452 stop count : 0 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 1 Loss 77.570429 acc : 0.520833 reg : 72.012489 stop count : 0 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 1 Loss 75.304792 acc : 0.511719 reg : 67.238586 stop count : 0 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 1 Loss 73.805344 acc : 0.515625 reg : 66.602783 stop count : 0 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 1 Loss 72.135420 acc : 0.502604 reg : 62.227966 stop count : 0 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 1 Loss 70.781422 acc : 0.522321 reg : 61.624992 stop count : 0 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 1 Loss 69.707447 acc : 0.525391 reg : 61.071678 stop count : 0 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 1 Loss 68.601949 acc : 0.522569 reg : 58.388241 stop count : 0 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 1 Loss 67.669854 acc : 0.507812 reg : 57.707241 stop count : 0 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 1 Loss 66.738514 acc : 0.496496 reg : 55.905422 stop count : 0 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "                                                       \n",
      "Test set: Average loss: 6.2039, Accuracy: 145.99999964237213/300 (49%)\n",
      "Epoch 2 Loss 56.478401 acc : 0.625000 reg : 55.578365 stop count : 1 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 2 Loss 56.238825 acc : 0.531250 reg : 54.564629 stop count : 1 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 2 Loss 55.969395 acc : 0.505208 reg : 54.310394 stop count : 1 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 2 Loss 55.421824 acc : 0.488281 reg : 52.612896 stop count : 1 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 2 Loss 54.699168 acc : 0.481250 reg : 50.529991 stop count : 1 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 2 Loss 54.183612 acc : 0.471354 reg : 50.115646 stop count : 1 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 2 Loss 53.716424 acc : 0.468750 reg : 49.828785 stop count : 1 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 2 Loss 53.263056 acc : 0.458984 reg : 48.818829 stop count : 1 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 2 Loss 52.734830 acc : 0.458333 reg : 47.437473 stop count : 1 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 2 Loss 52.374400 acc : 0.470313 reg : 48.206028 stop count : 1 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 2 Loss 52.016941 acc : 0.471496 reg : 47.453613 stop count : 1 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "                                                       \n",
      "Test set: Average loss: 4.5934, Accuracy: 148.99999904632568/300 (50%)\n",
      "Epoch 3 Loss 47.089836 acc : 0.468750 reg : 46.200779 stop count : 0 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 3 Loss 47.014938 acc : 0.484375 reg : 45.883240 stop count : 0 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 3 Loss 46.641310 acc : 0.453125 reg : 44.844082 stop count : 0 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 3 Loss 46.319859 acc : 0.453125 reg : 44.231991 stop count : 0 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 3 Loss 46.272356 acc : 0.456250 reg : 45.163101 stop count : 0 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 3 Loss 45.941540 acc : 0.453125 reg : 43.444393 stop count : 0 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 3 Loss 45.643922 acc : 0.466518 reg : 42.996632 stop count : 0 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 3 Loss 45.254695 acc : 0.464844 reg : 41.610561 stop count : 0 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 3 Loss 45.034216 acc : 0.468750 reg : 42.378613 stop count : 0 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 3 Loss 44.841856 acc : 0.471875 reg : 42.171646 stop count : 0 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 3 Loss 44.607125 acc : 0.483523 reg : 41.610451 stop count : 0 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "                                                       \n",
      "Test set: Average loss: 3.8285, Accuracy: 158.99999904632568/300 (53%)\n",
      "Epoch 4 Loss 41.738178 acc : 0.609375 reg : 40.859898 stop count : 0 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 4 Loss 41.658081 acc : 0.578125 reg : 40.729946 stop count : 0 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 4 Loss 41.604321 acc : 0.562500 reg : 40.761951 stop count : 0 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 4 Loss 41.394924 acc : 0.546875 reg : 39.959797 stop count : 0 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 4 Loss 41.312830 acc : 0.540625 reg : 40.195137 stop count : 0 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 4 Loss 41.111425 acc : 0.539062 reg : 39.357616 stop count : 0 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 4 Loss 40.945643 acc : 0.526786 reg : 38.965149 stop count : 0 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 4 Loss 40.786139 acc : 0.511719 reg : 38.782272 stop count : 0 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 4 Loss 40.526127 acc : 0.498264 reg : 37.522755 stop count : 0 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 4 Loss 40.207951 acc : 0.498437 reg : 36.602051 stop count : 0 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 4 Loss 39.956305 acc : 0.495549 reg : 36.557125 stop count : 0 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "                                                       \n",
      "Test set: Average loss: 3.8366, Accuracy: 160.99999904632568/300 (54%)\n",
      "Epoch 5 Loss 38.250736 acc : 0.421875 reg : 37.411552 stop count : 1 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 5 Loss 37.242516 acc : 0.492188 reg : 35.449440 stop count : 1 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 5 Loss 37.222696 acc : 0.515625 reg : 36.378857 stop count : 1 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 5 Loss 37.004834 acc : 0.515625 reg : 35.477135 stop count : 1 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 5 Loss 36.726318 acc : 0.509375 reg : 34.765083 stop count : 1 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 5 Loss 36.627240 acc : 0.502604 reg : 35.237335 stop count : 1 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 5 Loss 36.369336 acc : 0.517857 reg : 33.948860 stop count : 1 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 5 Loss 36.128891 acc : 0.531250 reg : 33.706333 stop count : 1 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 5 Loss 35.936808 acc : 0.519097 reg : 33.346951 stop count : 1 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 5 Loss 35.698939 acc : 0.521875 reg : 32.612640 stop count : 1 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 5 Loss 35.360016 acc : 0.525947 reg : 31.298107 stop count : 1 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "                                                       \n",
      "Test set: Average loss: 4.1451, Accuracy: 163.00000071525574/300 (54%)\n",
      "Epoch 6 Loss 32.935493 acc : 0.609375 reg : 32.183750 stop count : 2 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 6 Loss 32.895721 acc : 0.539062 reg : 31.824800 stop count : 2 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 6 Loss 32.443218 acc : 0.531250 reg : 30.715055 stop count : 2 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "Epoch 6 Loss 32.182452 acc : 0.507812 reg : 30.491995 stop count : 2 lamb : 0.8659721768663098 lamb_enp : 3.263178723042085\n",
      "  0%|          | 0/100 [01:10<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 10\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[0;32m      5\u001b[0m space \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlamb\u001b[39m\u001b[38;5;124m'\u001b[39m: hp\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlamb\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m5\u001b[39m),\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlamb_entropy\u001b[39m\u001b[38;5;124m'\u001b[39m: hp\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlamb_entropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m      8\u001b[0m }\n\u001b[1;32m---> 10\u001b[0m best \u001b[38;5;241m=\u001b[39m \u001b[43mfmin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_evals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pop75\\anaconda3\\envs\\Lee\\Lib\\site-packages\\hyperopt\\fmin.py:586\u001b[0m, in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[0;32m    583\u001b[0m rval\u001b[38;5;241m.\u001b[39mcatch_eval_exceptions \u001b[38;5;241m=\u001b[39m catch_eval_exceptions\n\u001b[0;32m    585\u001b[0m \u001b[38;5;66;03m# next line is where the fmin is actually executed\u001b[39;00m\n\u001b[1;32m--> 586\u001b[0m \u001b[43mrval\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexhaust\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_argmin:\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(trials\u001b[38;5;241m.\u001b[39mtrials) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\pop75\\anaconda3\\envs\\Lee\\Lib\\site-packages\\hyperopt\\fmin.py:364\u001b[0m, in \u001b[0;36mFMinIter.exhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexhaust\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    363\u001b[0m     n_done \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials)\n\u001b[1;32m--> 364\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_evals\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mn_done\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblock_until_done\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masynchronous\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\pop75\\anaconda3\\envs\\Lee\\Lib\\site-packages\\hyperopt\\fmin.py:300\u001b[0m, in \u001b[0;36mFMinIter.run\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    297\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoll_interval_secs)\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;66;03m# -- loop over trials and do the jobs directly\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserial_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials\u001b[38;5;241m.\u001b[39mrefresh()\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials_save_file \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\pop75\\anaconda3\\envs\\Lee\\Lib\\site-packages\\hyperopt\\fmin.py:178\u001b[0m, in \u001b[0;36mFMinIter.serial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    176\u001b[0m ctrl \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mCtrl(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrials, current_trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdomain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctrl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    180\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob exception: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[1;32mc:\\Users\\pop75\\anaconda3\\envs\\Lee\\Lib\\site-packages\\hyperopt\\base.py:892\u001b[0m, in \u001b[0;36mDomain.evaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;66;03m# -- the \"work\" of evaluating `config` can be written\u001b[39;00m\n\u001b[0;32m    885\u001b[0m     \u001b[38;5;66;03m#    either into the pyll part (self.expr)\u001b[39;00m\n\u001b[0;32m    886\u001b[0m     \u001b[38;5;66;03m#    or the normal Python part (self.fn)\u001b[39;00m\n\u001b[0;32m    887\u001b[0m     pyll_rval \u001b[38;5;241m=\u001b[39m pyll\u001b[38;5;241m.\u001b[39mrec_eval(\n\u001b[0;32m    888\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpr,\n\u001b[0;32m    889\u001b[0m         memo\u001b[38;5;241m=\u001b[39mmemo,\n\u001b[0;32m    890\u001b[0m         print_node_on_error\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrec_eval_print_node_on_error,\n\u001b[0;32m    891\u001b[0m     )\n\u001b[1;32m--> 892\u001b[0m     rval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpyll_rval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rval, (\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39mnumber)):\n\u001b[0;32m    895\u001b[0m     dict_rval \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m(rval), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m: STATUS_OK}\n",
      "Cell \u001b[1;32mIn[24], line 167\u001b[0m, in \u001b[0;36msearch\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;66;03m# 모델 학습 및 평가\u001b[39;00m\n\u001b[0;32m    166\u001b[0m train_process \u001b[38;5;241m=\u001b[39m Early_stop_train(feature_model, optimizer, criterion)\n\u001b[1;32m--> 167\u001b[0m \u001b[43mtrain_process\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_feature_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mres\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;66;03m#feature_model.KAN.plot(beta=3,scale=2)\u001b[39;00m\n\u001b[0;32m    169\u001b[0m feature_model\u001b[38;5;241m.\u001b[39mKAN \u001b[38;5;241m=\u001b[39m feature_model\u001b[38;5;241m.\u001b[39mKAN\u001b[38;5;241m.\u001b[39mprune()\n",
      "Cell \u001b[1;32mIn[7], line 67\u001b[0m, in \u001b[0;36mEarly_stop_train.train_model\u001b[1;34m(self, train_loader, test_loader, epochs, res, lamb, lamb_entropy)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X_train,y_train \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 67\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m     reg_ \u001b[38;5;241m=\u001b[39m lamb\u001b[38;5;241m*\u001b[39mreg(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mKAN\u001b[38;5;241m.\u001b[39macts_scale,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mKAN,lamb_entropy\u001b[38;5;241m=\u001b[39mlamb_entropy)\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\pop75\\anaconda3\\envs\\Lee\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pop75\\anaconda3\\envs\\Lee\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[24], line 129\u001b[0m, in \u001b[0;36mFeature_model.forward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    127\u001b[0m input1 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSigmoid()(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mKAN(input1))\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mpi\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m#input1 = torch.concat([input1,input1_copy],dim=1)\u001b[39;00m\n\u001b[1;32m--> 129\u001b[0m input2 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSigmoid()(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mKAN\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput2\u001b[49m\u001b[43m)\u001b[49m)\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mpi\n\u001b[0;32m    130\u001b[0m \u001b[38;5;66;03m#input2 = torch.concat([input2,input2_copy],dim=1)\u001b[39;00m\n\u001b[0;32m    131\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mKernal(input1,input2)\n",
      "File \u001b[1;32mc:\\Users\\pop75\\anaconda3\\envs\\Lee\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pop75\\anaconda3\\envs\\Lee\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pop75\\anaconda3\\envs\\Lee\\Lib\\site-packages\\kan\\KAN.py:311\u001b[0m, in \u001b[0;36mKAN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macts\u001b[38;5;241m.\u001b[39mappend(x)  \u001b[38;5;66;03m# acts shape: (batch, width[l])\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth):\n\u001b[1;32m--> 311\u001b[0m     x_numerical, preacts, postacts_numerical, postspline \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mact_fun\u001b[49m\u001b[43m[\u001b[49m\u001b[43ml\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    313\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msymbolic_enabled \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    314\u001b[0m         x_symbolic, postacts_symbolic \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msymbolic_fun[l](x)\n",
      "File \u001b[1;32mc:\\Users\\pop75\\anaconda3\\envs\\Lee\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pop75\\anaconda3\\envs\\Lee\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pop75\\anaconda3\\envs\\Lee\\Lib\\site-packages\\kan\\KANLayer.py:172\u001b[0m, in \u001b[0;36mKANLayer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    170\u001b[0m preacts \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mreshape(batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_dim)\n\u001b[0;32m    171\u001b[0m base \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_fun(x)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# shape (batch, size)\u001b[39;00m\n\u001b[1;32m--> 172\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[43mcoef2curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrid\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight_sharing\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight_sharing\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# shape (size, batch)\u001b[39;00m\n\u001b[0;32m    173\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# shape (batch, size)\u001b[39;00m\n\u001b[0;32m    174\u001b[0m postspline \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mclone()\u001b[38;5;241m.\u001b[39mreshape(batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_dim)\n",
      "File \u001b[1;32mc:\\Users\\pop75\\anaconda3\\envs\\Lee\\Lib\\site-packages\\kan\\spline.py:100\u001b[0m, in \u001b[0;36mcoef2curve\u001b[1;34m(x_eval, grid, coef, k, device)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03mconverting B-spline coefficients to B-spline curves. Evaluate x on B-spline curves (summing up B_batch results over B-spline basis).\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03mtorch.Size([5, 100])\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# x_eval: (size, batch), grid: (size, grid), coef: (size, coef)\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# coef: (size, coef), B_batch: (size, coef, batch), summer over coef\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m y_eval \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mij,ijk->ik\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoef\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y_eval\n",
      "File \u001b[1;32mc:\\Users\\pop75\\anaconda3\\envs\\Lee\\Lib\\site-packages\\torch\\functional.py:198\u001b[0m, in \u001b[0;36meinsum\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;66;03m# Overwriting reason:\u001b[39;00m\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;66;03m# This dispatches to two ATen functions depending on the type of\u001b[39;00m\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;66;03m# split_size_or_sections. The branching code is in _tensor.py, which we\u001b[39;00m\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;66;03m# call here.\u001b[39;00m\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39msplit(split_size_or_sections, dim)\n\u001b[1;32m--> 198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meinsum\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    199\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"einsum(equation, *operands) -> Tensor\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m    Sums the product of the elements of the input :attr:`operands` along dimensions specified using a notation\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m                [ 0.3311,  5.5201, -3.0356]])\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopt_einsum\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mopt_einsum\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "space = {\n",
    "    'lamb': hp.uniform('lamb',0,5),\n",
    "    'lamb_entropy': hp.uniform('lamb_entropy',0,10)\n",
    "}\n",
    "\n",
    "best = fmin(fn=search, space=space, algo=tpe.suggest, max_evals=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
