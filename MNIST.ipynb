{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "vJl4rYpKBAEk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import sys\n",
        "import copy\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "lr = 0.01\n",
        "PCA_dim = 8\n",
        "CLS_num = 2\n",
        "\n",
        "\n",
        "# 데이터 전처리 설정\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "# 데이터셋 로드\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=8, n_informative=5, n_redundant=3, n_classes=2, random_state=42)\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\"\"\"\n",
        "train_dataset = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST('../data', train=False, transform=transform)\n",
        "train_mask = (train_dataset.targets >= 0) & (train_dataset.targets <= CLS_num-1)\n",
        "test_mask = (test_dataset.targets >= 0) & (test_dataset.targets <= CLS_num-1)\n",
        "\n",
        "train_dataset.data = train_dataset.data[train_mask]\n",
        "train_dataset.targets = train_dataset.targets[train_mask]\n",
        "test_dataset.data = test_dataset.data[test_mask]\n",
        "test_dataset.targets = test_dataset.targets[test_mask]\n",
        "\n",
        "# 데이터를 NumPy 배열로 변환\n",
        "x_train = train_dataset.data.numpy().reshape(-1, 784)\n",
        "x_test = test_dataset.data.numpy().reshape(-1, 784)\n",
        "y_train = train_dataset.targets.numpy()\n",
        "y_test = test_dataset.targets.numpy()\"\"\"\n",
        "\n",
        "# PCA로 feature 축소\n",
        "pca = PCA(n_components=PCA_dim)\n",
        "x_train_pca = pca.fit_transform(x_train)\n",
        "x_test_pca = pca.transform(x_test)\n",
        "\n",
        "# 정규화 (표준 스케일러 사용)\n",
        "scaler = StandardScaler()\n",
        "x_train_pca = scaler.fit_transform(x_train_pca)\n",
        "x_test_pca = scaler.transform(x_test_pca)\n",
        "\n",
        "# PyTorch Tensor로 변환\n",
        "x_train_pca, y_train = torch.tensor(x_train_pca, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long)\n",
        "x_test_pca, y_test = torch.tensor(x_test_pca, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "\n",
        "class Feature_data_loader(Dataset):\n",
        "    def __init__(self,x_train,y_train):\n",
        "        self.feature1 = x_train\n",
        "        temp = copy.deepcopy(x_train)\n",
        "        shuffle = torch.randperm(len(temp))\n",
        "        self.feature2 = temp[shuffle]\n",
        "\n",
        "        self.y1 = y_train\n",
        "        temp_y = copy.deepcopy(y_train)\n",
        "        self.y2 = temp_y[shuffle]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.feature1)\n",
        "    def __getitem__(self,idx):\n",
        "        input1 = self.feature1[idx]\n",
        "        input2 = self.feature2[idx]\n",
        "        if self.y1[idx] == self.y2[idx]:\n",
        "            label = torch.tensor(1.).float()\n",
        "        else:\n",
        "            label = torch.tensor(0.).float()\n",
        "        return [input1,input2],label\n",
        "\n",
        "\n",
        "# DataLoader 생성\n",
        "\n",
        "\n",
        "feature_loader = DataLoader(Feature_data_loader(x_train_pca, y_train.float()),batch_size=batch_size,shuffle=True)\n",
        "test_feature_loader = DataLoader(Feature_data_loader(x_test_pca, y_test.float()),batch_size=batch_size,shuffle=False)\n",
        "train_loader = DataLoader(TensorDataset(x_train_pca, y_train), batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(x_test_pca, y_test), batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "N4Y4dnYJBAEt"
      },
      "outputs": [],
      "source": [
        "def accuracy(pred, true):\n",
        "    # 예측값이 로짓 혹은 확률값인 경우, 최대 값을 가진 인덱스를 구함 (가장 확률이 높은 클래스)\n",
        "    pred = pred.detach().cpu()\n",
        "    true = true.cpu()\n",
        "    try:\n",
        "        pred_labels = torch.argmax(pred, dim=1)\n",
        "    except:\n",
        "        pred_labels = torch.round(pred)\n",
        "    # 예측 레이블과 실제 레이블이 일치하는 경우를 계산\n",
        "    correct = (pred_labels == true).sum()\n",
        "    # 정확도를 계산\n",
        "    acc = correct / true.size(0)\n",
        "    return acc.item()\n",
        "\n",
        "class Early_stop_train():\n",
        "    def __init__(self,model, optimizer, criterion):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.criterion = criterion\n",
        "\n",
        "\n",
        "\n",
        "        self.loss_list = [1e100]\n",
        "        self.stop_count = 0\n",
        "\n",
        "    def train_model(self,train_loader,test_loader=None ,epochs=200,res = 10):\n",
        "        self.model.train()\n",
        "        for epoch in range(epochs):\n",
        "            if self.stop_count>=res:\n",
        "                break\n",
        "            loss_val,_ = self.test(test_loader)\n",
        "            self.loss_list.append(loss_val)\n",
        "\n",
        "            if self.loss_list[-1]>=np.min(self.loss_list[:-1]):\n",
        "                self.stop_count+=1\n",
        "            else:\n",
        "                self.stop_count = 0\n",
        "            loss_list = []\n",
        "            acc_list = []\n",
        "            for X_train,y_train in train_loader:\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                output = self.model(X_train)\n",
        "\n",
        "                loss = self.criterion(output.squeeze(), y_train)\n",
        "\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                loss_list.append(loss.item())\n",
        "                acc = accuracy(output,y_train)\n",
        "                acc_list.append(acc)\n",
        "\n",
        "                sys.stdout.write(f\"\\rEpoch {epoch+1} Loss {np.mean(loss_list):4f} acc : {np.mean(acc_list):4f} stop count : {self.stop_count}\")\n",
        "\n",
        "\n",
        "    def test(self,test_loader):\n",
        "        if test_loader is None:\n",
        "            return 0,0\n",
        "        else:\n",
        "            #self.model.eval()\n",
        "            test_loss = 0\n",
        "            correct = 0\n",
        "            with torch.no_grad():\n",
        "                for data, target in test_loader:\n",
        "                    data, target = data, target\n",
        "                    output = self.model(data)\n",
        "                    test_loss += self.criterion(output.squeeze(), target).item()\n",
        "\n",
        "                    correct += accuracy(output,target)*len(output)\n",
        "\n",
        "            print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)')\n",
        "            return test_loss,correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "9k3d3GfMBAEv",
        "outputId": "12102841-2511-4734-c1a8-1100ee35e2fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 3.0220, Accuracy: 102.0/200 (51%)\n",
            "Epoch 1 Loss 0.858949 acc : 0.501202 stop count : 0\n",
            "Test set: Average loss: 3.5289, Accuracy: 115.0/200 (58%)\n",
            "Epoch 2 Loss 0.740482 acc : 0.568510 stop count : 1\n",
            "Test set: Average loss: 3.6243, Accuracy: 108.0/200 (54%)\n",
            "Epoch 3 Loss 0.688772 acc : 0.603365 stop count : 2\n",
            "Test set: Average loss: 3.3827, Accuracy: 111.0/200 (56%)\n",
            "Epoch 4 Loss 0.656782 acc : 0.632212 stop count : 3\n",
            "Test set: Average loss: 3.1398, Accuracy: 109.0/200 (54%)\n",
            "Epoch 5 Loss 0.625734 acc : 0.659856 stop count : 4\n",
            "Test set: Average loss: 3.1329, Accuracy: 113.0/200 (56%)\n",
            "Epoch 6 Loss 0.601383 acc : 0.686298 stop count : 5\n",
            "Test set: Average loss: 3.0653, Accuracy: 116.0/200 (58%)\n",
            "Epoch 7 Loss 0.575819 acc : 0.715144 stop count : 6\n",
            "Test set: Average loss: 2.9768, Accuracy: 117.0/200 (58%)\n",
            "Epoch 8 Loss 0.567589 acc : 0.717548 stop count : 0\n",
            "Test set: Average loss: 2.9588, Accuracy: 118.0/200 (59%)\n",
            "Epoch 9 Loss 0.547498 acc : 0.735577 stop count : 0\n",
            "Test set: Average loss: 2.9416, Accuracy: 117.0/200 (58%)\n",
            "Epoch 10 Loss 0.536780 acc : 0.740385 stop count : 0\n",
            "Test set: Average loss: 2.9362, Accuracy: 118.0/200 (59%)\n",
            "Epoch 11 Loss 0.524330 acc : 0.748798 stop count : 0\n",
            "Test set: Average loss: 2.9464, Accuracy: 116.0/200 (58%)\n",
            "Epoch 12 Loss 0.511048 acc : 0.754808 stop count : 1\n",
            "Test set: Average loss: 2.8684, Accuracy: 116.0/200 (58%)\n",
            "Epoch 13 Loss 0.503750 acc : 0.765625 stop count : 0\n",
            "Test set: Average loss: 2.9463, Accuracy: 118.0/200 (59%)\n",
            "Epoch 14 Loss 0.495703 acc : 0.770433 stop count : 1\n",
            "Test set: Average loss: 2.8684, Accuracy: 118.0/200 (59%)\n",
            "Epoch 15 Loss 0.474165 acc : 0.783654 stop count : 2\n",
            "Test set: Average loss: 2.8894, Accuracy: 119.0/200 (60%)\n",
            "Epoch 16 Loss 0.467539 acc : 0.784856 stop count : 3\n",
            "Test set: Average loss: 2.9055, Accuracy: 122.0/200 (61%)\n",
            "Epoch 17 Loss 0.462508 acc : 0.792067 stop count : 4\n",
            "Test set: Average loss: 2.8261, Accuracy: 118.0/200 (59%)\n",
            "Epoch 18 Loss 0.456577 acc : 0.801683 stop count : 0\n",
            "Test set: Average loss: 2.8849, Accuracy: 124.0/200 (62%)\n",
            "Epoch 19 Loss 0.443793 acc : 0.810096 stop count : 1\n",
            "Test set: Average loss: 2.8425, Accuracy: 126.0/200 (63%)\n",
            "Epoch 20 Loss 0.437231 acc : 0.817308 stop count : 2\n",
            "Test set: Average loss: 2.8698, Accuracy: 127.0/200 (64%)\n",
            "Epoch 21 Loss 0.425335 acc : 0.816106 stop count : 3\n",
            "Test set: Average loss: 2.8020, Accuracy: 130.0/200 (65%)\n",
            "Epoch 22 Loss 0.425749 acc : 0.820913 stop count : 0\n",
            "Test set: Average loss: 2.8828, Accuracy: 132.0/200 (66%)\n",
            "Epoch 23 Loss 0.420274 acc : 0.826923 stop count : 1\n",
            "Test set: Average loss: 2.8115, Accuracy: 132.0/200 (66%)\n",
            "Epoch 24 Loss 0.412930 acc : 0.837740 stop count : 2\n",
            "Test set: Average loss: 2.8535, Accuracy: 132.0/200 (66%)\n",
            "Epoch 25 Loss 0.406896 acc : 0.838942 stop count : 3\n",
            "Test set: Average loss: 2.9080, Accuracy: 131.0/200 (66%)\n",
            "Epoch 26 Loss 0.405373 acc : 0.846154 stop count : 4\n",
            "Test set: Average loss: 2.7734, Accuracy: 132.0/200 (66%)\n",
            "Epoch 27 Loss 0.411446 acc : 0.841346 stop count : 0\n",
            "Test set: Average loss: 2.8119, Accuracy: 132.0/200 (66%)\n",
            "Epoch 28 Loss 0.400396 acc : 0.843750 stop count : 1\n",
            "Test set: Average loss: 2.9322, Accuracy: 131.0/200 (66%)\n",
            "Epoch 29 Loss 0.391602 acc : 0.848558 stop count : 2\n",
            "Test set: Average loss: 2.8369, Accuracy: 134.0/200 (67%)\n",
            "Epoch 30 Loss 0.383785 acc : 0.852163 stop count : 3\n",
            "Test set: Average loss: 2.9835, Accuracy: 132.0/200 (66%)\n",
            "Epoch 31 Loss 0.387850 acc : 0.858173 stop count : 4\n",
            "Test set: Average loss: 2.9877, Accuracy: 131.0/200 (66%)\n",
            "Epoch 32 Loss 0.376010 acc : 0.856971 stop count : 5\n",
            "Test set: Average loss: 2.9485, Accuracy: 132.0/200 (66%)\n",
            "Epoch 33 Loss 0.370400 acc : 0.862981 stop count : 6\n",
            "Test set: Average loss: 2.9892, Accuracy: 131.0/200 (66%)\n",
            "Epoch 34 Loss 0.360012 acc : 0.867788 stop count : 7\n",
            "Test set: Average loss: 3.1170, Accuracy: 130.0/200 (65%)\n",
            "Epoch 35 Loss 0.367306 acc : 0.862981 stop count : 8\n",
            "Test set: Average loss: 3.1536, Accuracy: 134.0/200 (67%)\n",
            "Epoch 36 Loss 0.357538 acc : 0.865385 stop count : 9\n",
            "Test set: Average loss: 3.0185, Accuracy: 133.0/200 (66%)\n",
            "Epoch 37 Loss 0.357022 acc : 0.871394 stop count : 10\n",
            "Test set: Average loss: 3.0846, Accuracy: 137.0/200 (68%)\n",
            "Epoch 38 Loss 0.348141 acc : 0.872596 stop count : 11\n",
            "Test set: Average loss: 3.1079, Accuracy: 132.0/200 (66%)\n",
            "Epoch 39 Loss 0.349181 acc : 0.867788 stop count : 12\n",
            "Test set: Average loss: 3.1098, Accuracy: 134.0/200 (67%)\n",
            "Epoch 40 Loss 0.343286 acc : 0.872596 stop count : 13\n",
            "Test set: Average loss: 3.1763, Accuracy: 137.0/200 (68%)\n",
            "Epoch 41 Loss 0.340743 acc : 0.871394 stop count : 14\n",
            "Test set: Average loss: 3.0246, Accuracy: 133.0/200 (66%)\n",
            "Epoch 42 Loss 0.335840 acc : 0.871394 stop count : 15\n",
            "\n",
            " Test start \n",
            "\n",
            "\n",
            "\n",
            "Test set: Average loss: 2.9792, Accuracy: 80.0/200 (40%)\n",
            "Epoch 1 Loss 0.660717 acc : 0.667067 stop count : 0\n",
            "Test set: Average loss: 2.5078, Accuracy: 159.0/200 (80%)\n",
            "Epoch 2 Loss 0.511754 acc : 0.927885 stop count : 0\n",
            "Test set: Average loss: 2.2570, Accuracy: 162.0/200 (81%)\n",
            "Epoch 3 Loss 0.384739 acc : 0.929087 stop count : 0\n",
            "Test set: Average loss: 2.0964, Accuracy: 163.0/200 (82%)\n",
            "Epoch 4 Loss 0.311165 acc : 0.926683 stop count : 0\n",
            "Test set: Average loss: 2.0481, Accuracy: 164.0/200 (82%)\n",
            "Epoch 5 Loss 0.289000 acc : 0.919471 stop count : 0\n",
            "Test set: Average loss: 1.9968, Accuracy: 167.0/200 (84%)\n",
            "Epoch 6 Loss 0.266668 acc : 0.925481 stop count : 0\n",
            "Test set: Average loss: 1.9684, Accuracy: 169.0/200 (84%)\n",
            "Epoch 7 Loss 0.253496 acc : 0.925481 stop count : 0\n",
            "Test set: Average loss: 1.9375, Accuracy: 169.0/200 (84%)\n",
            "Epoch 8 Loss 0.244960 acc : 0.926683 stop count : 0\n",
            "Test set: Average loss: 1.9449, Accuracy: 169.0/200 (84%)\n",
            "Epoch 9 Loss 0.251659 acc : 0.920673 stop count : 1\n",
            "Test set: Average loss: 1.9172, Accuracy: 169.0/200 (84%)\n",
            "Epoch 10 Loss 0.238921 acc : 0.926683 stop count : 0\n",
            "Test set: Average loss: 1.9332, Accuracy: 169.0/200 (84%)\n",
            "Epoch 11 Loss 0.238676 acc : 0.926683 stop count : 1\n",
            "Test set: Average loss: 1.9215, Accuracy: 169.0/200 (84%)\n",
            "Epoch 12 Loss 0.234814 acc : 0.925481 stop count : 2\n",
            "Test set: Average loss: 1.9062, Accuracy: 169.0/200 (84%)\n",
            "Epoch 13 Loss 0.235217 acc : 0.924279 stop count : 0\n",
            "Test set: Average loss: 1.9075, Accuracy: 169.0/200 (84%)\n",
            "Epoch 14 Loss 0.237425 acc : 0.925481 stop count : 1\n",
            "Test set: Average loss: 1.9460, Accuracy: 169.0/200 (84%)\n",
            "Epoch 15 Loss 0.239894 acc : 0.923077 stop count : 2\n",
            "Test set: Average loss: 1.9145, Accuracy: 169.0/200 (84%)\n",
            "Epoch 16 Loss 0.227611 acc : 0.926683 stop count : 3\n",
            "Test set: Average loss: 1.9012, Accuracy: 168.0/200 (84%)\n",
            "Epoch 17 Loss 0.230738 acc : 0.924279 stop count : 0\n",
            "Test set: Average loss: 1.9441, Accuracy: 169.0/200 (84%)\n",
            "Epoch 18 Loss 0.229237 acc : 0.926683 stop count : 1\n",
            "Test set: Average loss: 1.9093, Accuracy: 168.0/200 (84%)\n",
            "Epoch 19 Loss 0.229759 acc : 0.925481 stop count : 2\n",
            "Test set: Average loss: 1.9393, Accuracy: 169.0/200 (84%)\n",
            "Epoch 20 Loss 0.230731 acc : 0.926683 stop count : 3\n",
            "Test set: Average loss: 1.9252, Accuracy: 168.0/200 (84%)\n",
            "Epoch 21 Loss 0.229818 acc : 0.926683 stop count : 4\n",
            "Test set: Average loss: 1.9346, Accuracy: 168.0/200 (84%)\n",
            "Epoch 22 Loss 0.225103 acc : 0.929087 stop count : 5\n",
            "Test set: Average loss: 1.9308, Accuracy: 168.0/200 (84%)\n",
            "Test Accuracy: 168.00\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "from collections import OrderedDict\n",
        "import math\n",
        "\n",
        "result_list_classical = []\n",
        "\n",
        "# 데이터 로드 및 전처리\n",
        "\"\"\"\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "pca = PCA(n_components=PCA_dim)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.PCA_dim, random_state=seed)\n",
        "\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32)\"\"\"\n",
        "\n",
        "# Pennylane 장치 설정\n",
        "dev = qml.device(\"default.qubit\", wires=PCA_dim)\n",
        "\n",
        "\n",
        "def ZZFeatureMapLayer(features, wires):\n",
        "    \"\"\"사용자 정의 ZZFeatureMap 레이어\"\"\"\n",
        "    index = 0\n",
        "    for i in wires:\n",
        "        qml.Hadamard(wires=i)\n",
        "        qml.RZ(features[:,index], wires=i)\n",
        "        index += 1\n",
        "\n",
        "    for j in range(0, len(wires)-1):\n",
        "        qml.CNOT(wires=[j, j+1])\n",
        "        qml.RZ((features[:,index]), wires=j+1)\n",
        "        qml.CNOT(wires=[j, j+1])\n",
        "        index+=1\n",
        "\n",
        "def ansatz(params):\n",
        "    for j in range(len(params)):\n",
        "        # 각 큐비트에 대해 RX, RY, RZ 회전 적용\n",
        "        for i in range(len(params[0])):\n",
        "            qml.RY(params[j, i, 0], wires=i)\n",
        "            qml.RZ(params[j, i, 1], wires=i)\n",
        "\n",
        "        # 인접한 큐비트 간 CNOT 게이트로 엔탱글링\n",
        "        if j == len(params)-1:\n",
        "            pass\n",
        "        else:\n",
        "            for i in range(len(params[0])-1):\n",
        "                qml.CNOT(wires=[i, i+1])\n",
        "\n",
        "\n",
        "# 양자 레이어 정의\n",
        "@qml.qnode(dev, interface='torch', diff_method=\"backprop\")\n",
        "def QuantumLayer(features,params):\n",
        "    ZZFeatureMapLayer(features, wires=range(PCA_dim))\n",
        "    ansatz(params)\n",
        "    return qml.probs(wires=range(math.ceil(math.log2(CLS_num))))\n",
        "\n",
        "\n",
        "## 양자 커널\n",
        "@qml.qnode(dev, interface='torch', diff_method=\"backprop\")\n",
        "def Kernal(features1,features2):\n",
        "    ZZFeatureMapLayer(features1, wires=range(PCA_dim))\n",
        "    qml.adjoint(ZZFeatureMapLayer)(features2,wires=range(PCA_dim))\n",
        "    return qml.probs(wires=range(PCA_dim))\n",
        "\n",
        "\n",
        "class Feature_model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Feature_model,self).__init__()\n",
        "        self.cls = nn.Sequential(OrderedDict([('cls1', nn.Linear(PCA_dim,PCA_dim*4)),('relu1', nn.ReLU()),('cls2', nn.Linear(PCA_dim*4,PCA_dim*4)),('relu1', nn.ReLU()),('cls3', nn.Linear(PCA_dim*4,PCA_dim*2-1)),('sigmoid', nn.ReLU())]))\n",
        "        self.Kernal = Kernal\n",
        "    def forward(self,inputs):\n",
        "        epsilon = 1e-6\n",
        "        input1 = inputs[0]\n",
        "        input2 = inputs[1]\n",
        "        input1 = self.cls(input1)*np.pi\n",
        "        input2 = self.cls(input2)*np.pi\n",
        "        output = self.Kernal(input1,input2)\n",
        "        output = output.type(torch.float32)\n",
        "        return output[:,0].clamp(min=epsilon, max=1-epsilon)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 하이브리드 모델 정의\n",
        "class HybridModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(HybridModel, self).__init__()\n",
        "        self.cls = feature_model.cls\n",
        "\n",
        "        self.quantum_layer = QuantumLayer\n",
        "        self.Q_params = nn.Parameter((torch.rand([PCA_dim,PCA_dim,2])*2-1)*np.pi,requires_grad=True)\n",
        "    def forward(self, x):\n",
        "        x = self.cls(x)*np.pi\n",
        "        #print(qml.draw(self.quantum_layer)(x,self.Q_params))\n",
        "        quantum_output = self.quantum_layer(x,self.Q_params)\n",
        "        quantum_output = quantum_output.type(torch.float32)\n",
        "        return torch.log(quantum_output)\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.cls_layer_1 = nn.Linear(PCA_dim,PCA_dim*PCA_dim)\n",
        "        self.cls_layer_2 = nn.Linear(PCA_dim*PCA_dim,PCA_dim*PCA_dim-1)\n",
        "        self.output_layer = nn.Linear(PCA_dim*PCA_dim-1,PCA_dim)\n",
        "    def forward(self, x):\n",
        "        x = self.cls_layer_1(x)\n",
        "        x = nn.ReLU()(x)\n",
        "        x = self.cls_layer_2(x)\n",
        "        x = nn.ReLU()(x)\n",
        "        output = self.output_layer(x)\n",
        "        return output\n",
        "# 모델, 손실 함수, 최적화 설정\n",
        "\n",
        "\n",
        "feature_model = Feature_model(); criterion = nn.BCELoss()\n",
        "#model = Model(); criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(feature_model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "# 모델 학습 및 평가\n",
        "train_process = Early_stop_train(feature_model, optimizer, criterion)\n",
        "train_process.train_model(feature_loader,test_feature_loader,epochs=50,res=15)\n",
        "model = HybridModel(); criterion = nn.NLLLoss()\n",
        "for param in model.cls.parameters():\n",
        "    param.requires_grad = False\n",
        "#model.load_state_dict(para_dict)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "print('\\n\\n Test start \\n\\n')\n",
        "train_process = Early_stop_train(model, optimizer, criterion)\n",
        "train_process.train_model(train_loader,test_loader,epochs=50,res=5)\n",
        "\n",
        "_,acc = train_process.test(test_loader)\n",
        "result_list_classical.append(acc)\n",
        "print(f\"Test Accuracy: {acc:.2f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 데이터 생성\n",
        "X, y = make_classification(n_samples=1000, n_features=8, n_informative=5, n_redundant=3, n_classes=2, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# PCA로 특성 수 줄이기 (옵션)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "pca = PCA(n_components=8)  # 차원 축소\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "# 텐서로 변환\n",
        "X_train_tensor = torch.tensor(X_train_pca, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test_pca, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
        "\n",
        "# 신경망 모델 정의\n",
        "class BinaryClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BinaryClassifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(8, 64)\n",
        "        self.fc2 = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "model = BinaryClassifier()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# 훈련\n",
        "def train_model(model, criterion, optimizer, epochs=200):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_train_tensor).squeeze()\n",
        "        loss = criterion(outputs, y_train_tensor)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "train_model(model, criterion, optimizer)\n",
        "\n",
        "# 평가\n",
        "def evaluate_model(model, X, y):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(X).squeeze()\n",
        "        predicted = (outputs > 0.5).float()\n",
        "        accuracy = (predicted == y).float().mean()\n",
        "    return accuracy\n",
        "\n",
        "accuracy = evaluate_model(model, X_test_tensor, y_test_tensor)\n",
        "accuracy"
      ],
      "metadata": {
        "id": "dEzeq3mPIYbK",
        "outputId": "bbf271a9-086f-4478-8e10-3d25063280cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.8850)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}