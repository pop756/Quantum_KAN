{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vJl4rYpKBAEk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import sys\n",
        "import copy\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "lr = 0.01\n",
        "PCA_dim = 8\n",
        "CLS_num = 2\n",
        "\n",
        "\n",
        "\n",
        "with open('./data.pkl','rb') as file:\n",
        "    data = pickle.load(file)\n",
        "X = data['X']\n",
        "y = data['Y']\n",
        "\n",
        "\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "def Fit_to_quantum(X,PCA_dim):\n",
        "    pca = PCA(n_components=PCA_dim)\n",
        "    X_pca = pca.fit_transform(X)\n",
        "    return X_pca\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "# PyTorch Tensor로 변환\n",
        "x_train_pca, y_train = torch.tensor(x_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long)\n",
        "x_test_pca, y_test = torch.tensor(x_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "\n",
        "class Feature_data_loader(Dataset):\n",
        "    def __init__(self,x_train,y_train):\n",
        "        self.feature1 = x_train\n",
        "        temp = copy.deepcopy(x_train)\n",
        "        shuffle = torch.randperm(len(temp))\n",
        "        self.feature2 = temp[shuffle]\n",
        "        self.y1 = y_train\n",
        "        temp_y = copy.deepcopy(y_train)\n",
        "        self.y2 = temp_y[shuffle]\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.feature1)\n",
        "    def __getitem__(self,idx):\n",
        "        input1 = self.feature1[idx]\n",
        "        input2 = self.feature2[idx]\n",
        "        if self.y1[idx] == self.y2[idx]:\n",
        "            label = torch.tensor(1.).float()\n",
        "        else:\n",
        "            label = torch.tensor(0.).float()\n",
        "        return [input1,input2],label\n",
        "\n",
        "\n",
        "# DataLoader 생성\n",
        "\n",
        "\n",
        "feature_loader = DataLoader(Feature_data_loader(x_train_pca, y_train.float()),batch_size=batch_size,shuffle=True)\n",
        "test_feature_loader = DataLoader(Feature_data_loader(x_test_pca, y_test.float()),batch_size=batch_size,shuffle=False)\n",
        "train_loader = DataLoader(TensorDataset(x_train_pca, y_train), batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(x_test_pca, y_test), batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "N4Y4dnYJBAEt"
      },
      "outputs": [],
      "source": [
        "def accuracy(pred, true):\n",
        "    # 예측값이 로짓 혹은 확률값인 경우, 최대 값을 가진 인덱스를 구함 (가장 확률이 높은 클래스)\n",
        "    pred = pred.detach().cpu()\n",
        "    true = true.cpu()\n",
        "    try:\n",
        "        pred_labels = torch.argmax(pred, dim=1)\n",
        "    except:\n",
        "        pred_labels = torch.round(pred)\n",
        "    # 예측 레이블과 실제 레이블이 일치하는 경우를 계산\n",
        "    correct = (pred_labels == true).sum()\n",
        "    # 정확도를 계산\n",
        "    acc = correct / true.size(0)\n",
        "    return acc.item()\n",
        "\n",
        "class Early_stop_train():\n",
        "    def __init__(self,model, optimizer, criterion):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.criterion = criterion\n",
        "\n",
        "\n",
        "\n",
        "        self.loss_list = [1e100]\n",
        "        self.stop_count = 0\n",
        "\n",
        "    def train_model(self,train_loader,test_loader=None ,epochs=200,res = 10):\n",
        "        self.model.train()\n",
        "        for epoch in range(epochs):\n",
        "            if self.stop_count>=res:\n",
        "                break\n",
        "            loss_val,_ = self.test(test_loader)\n",
        "            self.loss_list.append(loss_val)\n",
        "\n",
        "            if self.loss_list[-1]>=np.min(self.loss_list[:-1]):\n",
        "                self.stop_count+=1\n",
        "            else:\n",
        "                self.stop_count = 0\n",
        "            loss_list = []\n",
        "            acc_list = []\n",
        "            for X_train,y_train in train_loader:\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                output = self.model(X_train)\n",
        "\n",
        "                loss = self.criterion(output.squeeze(), y_train)\n",
        "\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                loss_list.append(loss.item())\n",
        "                acc = accuracy(output,y_train)\n",
        "                acc_list.append(acc)\n",
        "\n",
        "                sys.stdout.write(f\"\\rEpoch {epoch+1} Loss {np.mean(loss_list):4f} acc : {np.mean(acc_list):4f} stop count : {self.stop_count}\")\n",
        "\n",
        "\n",
        "    def test(self,test_loader):\n",
        "        if test_loader is None:\n",
        "            return 0,0\n",
        "        else:\n",
        "            #self.model.eval()\n",
        "            test_loss = 0\n",
        "            correct = 0\n",
        "            with torch.no_grad():\n",
        "                for data, target in test_loader:\n",
        "                    data, target = data, target\n",
        "                    output = self.model(data)\n",
        "                    test_loss += self.criterion(output.squeeze(), target).item()\n",
        "\n",
        "                    correct += accuracy(output,target)*len(output)\n",
        "\n",
        "            print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)')\n",
        "            return test_loss,correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9k3d3GfMBAEv",
        "outputId": "12102841-2511-4734-c1a8-1100ee35e2fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 4.1084, Accuracy: 154.9999988079071/300 (52%)\n",
            "Epoch 1 Loss 0.795286 acc : 0.510038 stop count : 0\n",
            "Test set: Average loss: 3.7490, Accuracy: 153.00000047683716/300 (51%)\n",
            "Epoch 2 Loss 0.707609 acc : 0.593939 stop count : 0\n",
            "Test set: Average loss: 3.5751, Accuracy: 175.99999952316284/300 (59%)\n",
            "Epoch 3 Loss 0.655442 acc : 0.640057 stop count : 0\n",
            "Test set: Average loss: 3.3174, Accuracy: 186.99999928474426/300 (62%)\n",
            "Epoch 4 Loss 0.616702 acc : 0.666951 stop count : 0\n",
            "Test set: Average loss: 3.1143, Accuracy: 196.0/300 (65%)\n",
            "Epoch 5 Loss 0.581034 acc : 0.693087 stop count : 0\n",
            "Test set: Average loss: 2.9217, Accuracy: 207.99999904632568/300 (69%)\n",
            "Epoch 6 Loss 0.549797 acc : 0.735227 stop count : 0\n",
            "Test set: Average loss: 2.7084, Accuracy: 224.0/300 (75%)\n",
            "Epoch 7 Loss 0.523570 acc : 0.753314 stop count : 0\n",
            "Test set: Average loss: 2.5675, Accuracy: 234.00000071525574/300 (78%)\n",
            "Epoch 8 Loss 0.510740 acc : 0.756723 stop count : 0\n",
            "Test set: Average loss: 2.4668, Accuracy: 233.99999904632568/300 (78%)\n",
            "Epoch 9 Loss 0.495185 acc : 0.761553 stop count : 0\n",
            "Test set: Average loss: 2.3402, Accuracy: 239.00000071525574/300 (80%)\n",
            "Epoch 10 Loss 0.479766 acc : 0.764394 stop count : 0\n",
            "Test set: Average loss: 2.2950, Accuracy: 243.00000071525574/300 (81%)\n",
            "Epoch 11 Loss 0.469330 acc : 0.784470 stop count : 0\n",
            "Test set: Average loss: 2.2175, Accuracy: 240.00000071525574/300 (80%)\n",
            "Epoch 12 Loss 0.460013 acc : 0.788258 stop count : 0\n",
            "Test set: Average loss: 2.1524, Accuracy: 245.00000071525574/300 (82%)\n",
            "Epoch 13 Loss 0.451759 acc : 0.791572 stop count : 0\n",
            "Test set: Average loss: 2.1014, Accuracy: 246.99999976158142/300 (82%)\n",
            "Epoch 14 Loss 0.441067 acc : 0.800379 stop count : 0\n",
            "Test set: Average loss: 2.0799, Accuracy: 245.00000071525574/300 (82%)\n",
            "Epoch 15 Loss 0.435226 acc : 0.805682 stop count : 0\n",
            "Test set: Average loss: 2.0283, Accuracy: 245.00000071525574/300 (82%)\n",
            "Epoch 16 Loss 0.425472 acc : 0.811458 stop count : 0\n",
            "Test set: Average loss: 2.0011, Accuracy: 246.00000071525574/300 (82%)\n",
            "Epoch 17 Loss 0.421247 acc : 0.808144 stop count : 0\n",
            "Test set: Average loss: 1.9664, Accuracy: 249.00000071525574/300 (83%)\n",
            "Epoch 18 Loss 0.414843 acc : 0.814110 stop count : 0\n",
            "Test set: Average loss: 1.9314, Accuracy: 250.99999976158142/300 (84%)\n",
            "Epoch 19 Loss 0.407536 acc : 0.821496 stop count : 0\n",
            "Test set: Average loss: 1.9140, Accuracy: 250.99999976158142/300 (84%)\n",
            "Epoch 20 Loss 0.403049 acc : 0.817140 stop count : 0\n",
            "Test set: Average loss: 1.8862, Accuracy: 253.00000047683716/300 (84%)\n",
            "Epoch 21 Loss 0.398211 acc : 0.825568 stop count : 0\n",
            "Test set: Average loss: 1.8725, Accuracy: 251.9999988079071/300 (84%)\n",
            "Epoch 22 Loss 0.394914 acc : 0.829545 stop count : 0\n",
            "Test set: Average loss: 1.8462, Accuracy: 252.9999988079071/300 (84%)\n",
            "Epoch 23 Loss 0.394016 acc : 0.828220 stop count : 0\n",
            "Test set: Average loss: 1.8390, Accuracy: 251.9999988079071/300 (84%)\n",
            "Epoch 24 Loss 0.386123 acc : 0.836648 stop count : 0\n",
            "Test set: Average loss: 1.8129, Accuracy: 255.9999988079071/300 (85%)\n",
            "Epoch 25 Loss 0.383484 acc : 0.833807 stop count : 0\n",
            "Test set: Average loss: 1.7923, Accuracy: 255.00000047683716/300 (85%)\n",
            "Epoch 26 Loss 0.378621 acc : 0.838920 stop count : 0\n",
            "Test set: Average loss: 1.7819, Accuracy: 254.00000047683716/300 (85%)\n",
            "Epoch 27 Loss 0.374993 acc : 0.837311 stop count : 0\n",
            "Test set: Average loss: 1.7575, Accuracy: 255.00000047683716/300 (85%)\n",
            "Epoch 28 Loss 0.372345 acc : 0.836932 stop count : 0\n",
            "Test set: Average loss: 1.7643, Accuracy: 253.9999988079071/300 (85%)\n",
            "Epoch 29 Loss 0.370764 acc : 0.845739 stop count : 1\n",
            "Test set: Average loss: 1.7590, Accuracy: 253.9999988079071/300 (85%)\n",
            "Epoch 30 Loss 0.368887 acc : 0.844413 stop count : 2\n",
            "Test set: Average loss: 1.7335, Accuracy: 254.9999988079071/300 (85%)\n",
            "Epoch 31 Loss 0.365359 acc : 0.842898 stop count : 0\n",
            "Test set: Average loss: 1.7319, Accuracy: 256.9999988079071/300 (86%)\n",
            "Epoch 32 Loss 0.363342 acc : 0.844886 stop count : 0\n",
            "Test set: Average loss: 1.7188, Accuracy: 255.9999988079071/300 (85%)\n",
            "Epoch 33 Loss 0.361854 acc : 0.844034 stop count : 0\n",
            "Test set: Average loss: 1.7231, Accuracy: 258.00000047683716/300 (86%)\n",
            "Epoch 34 Loss 0.356622 acc : 0.844413 stop count : 1\n",
            "Test set: Average loss: 1.7233, Accuracy: 257.9999988079071/300 (86%)\n",
            "Epoch 35 Loss 0.355563 acc : 0.848295 stop count : 2\n",
            "Test set: Average loss: 1.7228, Accuracy: 257.00000047683716/300 (86%)\n",
            "Epoch 36 Loss 0.354893 acc : 0.845455 stop count : 3\n",
            "Test set: Average loss: 1.7143, Accuracy: 256.9999988079071/300 (86%)\n",
            "Epoch 37 Loss 0.352156 acc : 0.850095 stop count : 0\n",
            "Test set: Average loss: 1.7012, Accuracy: 256.9999988079071/300 (86%)\n",
            "Epoch 38 Loss 0.349524 acc : 0.851326 stop count : 0\n",
            "Test set: Average loss: 1.7122, Accuracy: 255.9999988079071/300 (85%)\n",
            "Epoch 39 Loss 0.346999 acc : 0.850095 stop count : 1\n",
            "Test set: Average loss: 1.6962, Accuracy: 256.9999988079071/300 (86%)\n",
            "Epoch 40 Loss 0.346040 acc : 0.850189 stop count : 0\n",
            "Test set: Average loss: 1.6817, Accuracy: 256.9999988079071/300 (86%)\n",
            "Epoch 41 Loss 0.344589 acc : 0.847348 stop count : 0\n",
            "Test set: Average loss: 1.7106, Accuracy: 256.9999988079071/300 (86%)\n",
            "Epoch 42 Loss 0.345258 acc : 0.847254 stop count : 1\n",
            "Test set: Average loss: 1.6991, Accuracy: 254.9999988079071/300 (85%)\n",
            "Epoch 43 Loss 0.340210 acc : 0.846212 stop count : 2\n",
            "Test set: Average loss: 1.6963, Accuracy: 258.00000047683716/300 (86%)\n",
            "Epoch 44 Loss 0.339881 acc : 0.848674 stop count : 3\n",
            "Test set: Average loss: 1.6699, Accuracy: 258.00000047683716/300 (86%)\n",
            "Epoch 45 Loss 0.337199 acc : 0.848201 stop count : 0\n",
            "Test set: Average loss: 1.6964, Accuracy: 255.9999988079071/300 (85%)\n",
            "Epoch 46 Loss 0.336215 acc : 0.851705 stop count : 1\n",
            "Test set: Average loss: 1.6854, Accuracy: 259.00000047683716/300 (86%)\n",
            "Epoch 47 Loss 0.337545 acc : 0.851231 stop count : 2\n",
            "Test set: Average loss: 1.6823, Accuracy: 260.00000047683716/300 (87%)\n",
            "Epoch 48 Loss 0.335631 acc : 0.850189 stop count : 3\n",
            "Test set: Average loss: 1.7076, Accuracy: 257.00000047683716/300 (86%)\n",
            "Epoch 49 Loss 0.333518 acc : 0.848864 stop count : 4\n",
            "Test set: Average loss: 1.6681, Accuracy: 258.00000047683716/300 (86%)\n",
            "Epoch 50 Loss 0.335037 acc : 0.854451 stop count : 0\n",
            "\n",
            " Test start \n",
            "\n",
            "\n",
            "\n",
            "Test set: Average loss: 3.4169, Accuracy: 153.0/300 (51%)\n",
            "Epoch 1 Loss 0.602261 acc : 0.749621 stop count : 0\n",
            "Test set: Average loss: 2.5871, Accuracy: 276.0000002384186/300 (92%)\n",
            "Epoch 2 Loss 0.479715 acc : 0.914489 stop count : 0\n",
            "Test set: Average loss: 2.1901, Accuracy: 279.0000002384186/300 (93%)\n",
            "Epoch 3 Loss 0.414416 acc : 0.918561 stop count : 0\n",
            "Test set: Average loss: 1.9090, Accuracy: 278.0000002384186/300 (93%)\n",
            "Epoch 4 Loss 0.368228 acc : 0.914299 stop count : 0\n",
            "Test set: Average loss: 1.7087, Accuracy: 278.0000002384186/300 (93%)\n",
            "Epoch 5 Loss 0.334654 acc : 0.917235 stop count : 0\n",
            "Test set: Average loss: 1.5725, Accuracy: 279.0000002384186/300 (93%)\n",
            "Epoch 6 Loss 0.309899 acc : 0.918655 stop count : 0\n",
            "Test set: Average loss: 1.4741, Accuracy: 277.0000002384186/300 (92%)\n",
            "Epoch 7 Loss 0.293164 acc : 0.917330 stop count : 0\n",
            "Test set: Average loss: 1.4156, Accuracy: 276.99999928474426/300 (92%)\n",
            "Epoch 8 Loss 0.283731 acc : 0.918561 stop count : 0\n",
            "Test set: Average loss: 1.3734, Accuracy: 277.99999928474426/300 (93%)\n",
            "Epoch 9 Loss 0.276537 acc : 0.918182 stop count : 0\n",
            "Test set: Average loss: 1.3411, Accuracy: 276.99999928474426/300 (92%)\n",
            "Epoch 10 Loss 0.269747 acc : 0.918466 stop count : 0\n",
            "Test set: Average loss: 1.3114, Accuracy: 276.99999928474426/300 (92%)\n",
            "Epoch 11 Loss 0.264390 acc : 0.920076 stop count : 0\n",
            "Test set: Average loss: 1.2850, Accuracy: 277.99999928474426/300 (93%)\n",
            "Epoch 12 Loss 0.259001 acc : 0.921307 stop count : 0\n",
            "Test set: Average loss: 1.2665, Accuracy: 276.99999928474426/300 (92%)\n",
            "Epoch 13 Loss 0.254865 acc : 0.918845 stop count : 0\n",
            "Test set: Average loss: 1.2497, Accuracy: 276.99999928474426/300 (92%)\n",
            "Epoch 14 Loss 0.251657 acc : 0.920170 stop count : 0\n",
            "Test set: Average loss: 1.2349, Accuracy: 278.99999928474426/300 (93%)\n",
            "Epoch 15 Loss 0.249488 acc : 0.919886 stop count : 0\n",
            "Test set: Average loss: 1.2232, Accuracy: 277.99999928474426/300 (93%)\n",
            "Epoch 16 Loss 0.246732 acc : 0.917140 stop count : 0\n",
            "Test set: Average loss: 1.2104, Accuracy: 278.99999928474426/300 (93%)\n",
            "Epoch 17 Loss 0.244310 acc : 0.918277 stop count : 0\n",
            "Test set: Average loss: 1.1993, Accuracy: 278.99999928474426/300 (93%)\n",
            "Epoch 18 Loss 0.241699 acc : 0.921686 stop count : 0\n",
            "Test set: Average loss: 1.1892, Accuracy: 278.99999928474426/300 (93%)\n",
            "Epoch 19 Loss 0.239049 acc : 0.918939 stop count : 0\n",
            "Test set: Average loss: 1.1790, Accuracy: 278.99999928474426/300 (93%)\n",
            "Epoch 20 Loss 0.238600 acc : 0.918466 stop count : 0\n",
            "Test set: Average loss: 1.1707, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 21 Loss 0.237035 acc : 0.916951 stop count : 0\n",
            "Test set: Average loss: 1.1660, Accuracy: 277.99999928474426/300 (93%)\n",
            "Epoch 22 Loss 0.235489 acc : 0.917235 stop count : 0\n",
            "Test set: Average loss: 1.1584, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 23 Loss 0.234386 acc : 0.915530 stop count : 0\n",
            "Test set: Average loss: 1.1528, Accuracy: 277.99999928474426/300 (93%)\n",
            "Epoch 24 Loss 0.232905 acc : 0.917330 stop count : 0\n",
            "Test set: Average loss: 1.1463, Accuracy: 277.99999928474426/300 (93%)\n",
            "Epoch 25 Loss 0.232899 acc : 0.915341 stop count : 0\n",
            "Test set: Average loss: 1.1467, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 26 Loss 0.232113 acc : 0.917235 stop count : 1\n",
            "Test set: Average loss: 1.1426, Accuracy: 276.99999928474426/300 (92%)\n",
            "Epoch 27 Loss 0.231735 acc : 0.918277 stop count : 0\n",
            "Test set: Average loss: 1.1359, Accuracy: 277.99999928474426/300 (93%)\n",
            "Epoch 28 Loss 0.230725 acc : 0.918466 stop count : 0\n",
            "Test set: Average loss: 1.1349, Accuracy: 277.99999928474426/300 (93%)\n",
            "Epoch 29 Loss 0.230106 acc : 0.917235 stop count : 0\n",
            "Test set: Average loss: 1.1364, Accuracy: 278.99999928474426/300 (93%)\n",
            "Epoch 30 Loss 0.228398 acc : 0.915530 stop count : 1\n",
            "Test set: Average loss: 1.1259, Accuracy: 277.99999928474426/300 (93%)\n",
            "Epoch 31 Loss 0.224340 acc : 0.906250 stop count : 0"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[13], line 147\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Test start \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    146\u001b[0m train_process \u001b[38;5;241m=\u001b[39m Early_stop_train(model, optimizer, criterion)\n\u001b[1;32m--> 147\u001b[0m \u001b[43mtrain_process\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mres\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m _,acc \u001b[38;5;241m=\u001b[39m train_process\u001b[38;5;241m.\u001b[39mtest(test_loader)\n\u001b[0;32m    150\u001b[0m result_list_classical\u001b[38;5;241m.\u001b[39mappend(acc)\n",
            "Cell \u001b[1;32mIn[12], line 53\u001b[0m, in \u001b[0;36mEarly_stop_train.train_model\u001b[1;34m(self, train_loader, test_loader, epochs, res)\u001b[0m\n\u001b[0;32m     50\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy(output,y_train)\n\u001b[0;32m     51\u001b[0m acc_list\u001b[38;5;241m.\u001b[39mappend(acc)\n\u001b[1;32m---> 53\u001b[0m \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\r\u001b[39;49;00m\u001b[38;5;124;43mEpoch \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m Loss \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_list\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[38;5;124;43m4f\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m acc : \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43macc_list\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[38;5;124;43m4f\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m stop count : \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop_count\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\pop75\\anaconda3\\envs\\Lee\\Lib\\site-packages\\ipykernel\\iostream.py:648\u001b[0m, in \u001b[0;36mOutStream.write\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    646\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpub_thread\u001b[38;5;241m.\u001b[39mschedule(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flush)\n\u001b[0;32m    647\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 648\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_schedule_flush\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(string)\n",
            "File \u001b[1;32mc:\\Users\\pop75\\anaconda3\\envs\\Lee\\Lib\\site-packages\\ipykernel\\iostream.py:545\u001b[0m, in \u001b[0;36mOutStream._schedule_flush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_schedule_in_thread\u001b[39m():\n\u001b[0;32m    543\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_io_loop\u001b[38;5;241m.\u001b[39mcall_later(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush_interval, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flush)\n\u001b[1;32m--> 545\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpub_thread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_schedule_in_thread\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\pop75\\anaconda3\\envs\\Lee\\Lib\\site-packages\\ipykernel\\iostream.py:251\u001b[0m, in \u001b[0;36mIOPubThread.schedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_events\u001b[38;5;241m.\u001b[39mappend(f)\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;66;03m# wake event thread (message content is ignored)\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event_pipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    253\u001b[0m     f()\n",
            "File \u001b[1;32mc:\\Users\\pop75\\anaconda3\\envs\\Lee\\Lib\\site-packages\\zmq\\sugar\\socket.py:696\u001b[0m, in \u001b[0;36mSocket.send\u001b[1;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[0;32m    689\u001b[0m         data \u001b[38;5;241m=\u001b[39m zmq\u001b[38;5;241m.\u001b[39mFrame(\n\u001b[0;32m    690\u001b[0m             data,\n\u001b[0;32m    691\u001b[0m             track\u001b[38;5;241m=\u001b[39mtrack,\n\u001b[0;32m    692\u001b[0m             copy\u001b[38;5;241m=\u001b[39mcopy \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    693\u001b[0m             copy_threshold\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy_threshold,\n\u001b[0;32m    694\u001b[0m         )\n\u001b[0;32m    695\u001b[0m     data\u001b[38;5;241m.\u001b[39mgroup \u001b[38;5;241m=\u001b[39m group\n\u001b[1;32m--> 696\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrack\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mzmq\\\\backend\\\\cython\\\\socket.pyx:742\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mzmq\\\\backend\\\\cython\\\\socket.pyx:789\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mzmq\\\\backend\\\\cython\\\\socket.pyx:250\u001b[0m, in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\pop75\\anaconda3\\envs\\Lee\\Lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd:13\u001b[0m, in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "from collections import OrderedDict\n",
        "import math\n",
        "\n",
        "result_list_classical = []\n",
        "\n",
        "# 데이터 로드 및 전처리\n",
        "\"\"\"\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "pca = PCA(n_components=PCA_dim)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.PCA_dim, random_state=seed)\n",
        "\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32)\"\"\"\n",
        "\n",
        "# Pennylane 장치 설정\n",
        "dev = qml.device(\"default.qubit\", wires=PCA_dim)\n",
        "\n",
        "\n",
        "def ZZFeatureMapLayer(features, wires):\n",
        "    \"\"\"사용자 정의 ZZFeatureMap 레이어\"\"\"\n",
        "    index = 0\n",
        "    for i in wires:\n",
        "        qml.Hadamard(wires=i)\n",
        "        qml.RZ(features[:,index], wires=i)\n",
        "        index += 1\n",
        "\n",
        "    for j in range(0, len(wires)-1):\n",
        "        qml.CNOT(wires=[j, j+1])\n",
        "        qml.RZ((features[:,index]), wires=j+1)\n",
        "        qml.CNOT(wires=[j, j+1])\n",
        "        index+=1\n",
        "\n",
        "def ansatz(params):\n",
        "    for j in range(len(params)):\n",
        "        # 각 큐비트에 대해 RX, RY, RZ 회전 적용\n",
        "        for i in range(len(params[0])):\n",
        "            qml.RY(params[j, i, 0], wires=i)\n",
        "            qml.RZ(params[j, i, 1], wires=i)\n",
        "\n",
        "        # 인접한 큐비트 간 CNOT 게이트로 엔탱글링\n",
        "        if j == len(params)-1:\n",
        "            pass\n",
        "        else:\n",
        "            for i in range(len(params[0])-1):\n",
        "                qml.CNOT(wires=[i, i+1])\n",
        "\n",
        "\n",
        "# 양자 레이어 정의\n",
        "@qml.qnode(dev, interface='torch', diff_method=\"backprop\")\n",
        "def QuantumLayer(features,params):\n",
        "    ZZFeatureMapLayer(features, wires=range(PCA_dim))\n",
        "    ansatz(params)\n",
        "    return qml.probs(wires=range(math.ceil(math.log2(CLS_num))))\n",
        "\n",
        "\n",
        "## 양자 커널\n",
        "@qml.qnode(dev, interface='torch', diff_method=\"backprop\")\n",
        "def Kernal(features1,features2):\n",
        "    ZZFeatureMapLayer(features1, wires=range(PCA_dim))\n",
        "    qml.adjoint(ZZFeatureMapLayer)(features2,wires=range(PCA_dim))\n",
        "    return qml.probs(wires=range(PCA_dim))\n",
        "\n",
        "\n",
        "class Feature_model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Feature_model,self).__init__()\n",
        "        self.cls = nn.Sequential(OrderedDict([('cls1', nn.Linear(PCA_dim,PCA_dim*4)),('relu1', nn.ReLU()),('cls2', nn.Linear(PCA_dim*4,PCA_dim*4)),('relu1', nn.ReLU()),('cls3', nn.Linear(PCA_dim*4,PCA_dim*2-1)),('sigmoid', nn.ReLU())]))\n",
        "        self.Kernal = Kernal\n",
        "    def forward(self,inputs):\n",
        "        epsilon = 1e-6\n",
        "        input1 = inputs[0]\n",
        "        input2 = inputs[1]\n",
        "        input1 = self.cls(input1)*np.pi\n",
        "        input2 = self.cls(input2)*np.pi\n",
        "        output = self.Kernal(input1,input2)\n",
        "        output = output.type(torch.float32)\n",
        "        return output[:,0].clamp(min=epsilon, max=1-epsilon)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 하이브리드 모델 정의\n",
        "class HybridModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(HybridModel, self).__init__()\n",
        "        self.cls = feature_model.cls\n",
        "\n",
        "        self.quantum_layer = QuantumLayer\n",
        "        self.Q_params = nn.Parameter((torch.rand([PCA_dim,PCA_dim,2])*2-1)*np.pi,requires_grad=True)\n",
        "    def forward(self, x):\n",
        "        x = self.cls(x)*np.pi\n",
        "        #print(qml.draw(self.quantum_layer)(x,self.Q_params))\n",
        "        quantum_output = self.quantum_layer(x,self.Q_params)\n",
        "        quantum_output = quantum_output.type(torch.float32)\n",
        "        return torch.log(quantum_output)\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.cls_layer_1 = nn.Linear(PCA_dim,PCA_dim*PCA_dim)\n",
        "        self.cls_layer_2 = nn.Linear(PCA_dim*PCA_dim,PCA_dim*PCA_dim-1)\n",
        "        self.output_layer = nn.Linear(PCA_dim*PCA_dim-1,PCA_dim)\n",
        "    def forward(self, x):\n",
        "        x = self.cls_layer_1(x)\n",
        "        x = nn.ReLU()(x)\n",
        "        x = self.cls_layer_2(x)\n",
        "        x = nn.ReLU()(x)\n",
        "        output = self.output_layer(x)\n",
        "        return output\n",
        "# 모델, 손실 함수, 최적화 설정\n",
        "\n",
        "\n",
        "feature_model = Feature_model(); criterion = nn.BCELoss()\n",
        "#model = Model(); criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(feature_model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "# 모델 학습 및 평가\n",
        "train_process = Early_stop_train(feature_model, optimizer, criterion)\n",
        "train_process.train_model(feature_loader,test_feature_loader,epochs=50,res=15)\n",
        "model = HybridModel(); criterion = nn.NLLLoss()\n",
        "for param in model.cls.parameters():\n",
        "    param.requires_grad = False\n",
        "#model.load_state_dict(para_dict)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "print('\\n\\n Test start \\n\\n')\n",
        "train_process = Early_stop_train(model, optimizer, criterion)\n",
        "train_process.train_model(train_loader,test_loader,epochs=50,res=5)\n",
        "\n",
        "_,acc = train_process.test(test_loader)\n",
        "result_list_classical.append(acc)\n",
        "print(f\"Test Accuracy: {acc:.2f}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
