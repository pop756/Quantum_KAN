{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vJl4rYpKBAEk",
        "notebookRunGroups": {
          "groupValue": "2"
        }
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import sys\n",
        "import copy\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "import pandas as pd\n",
        "import pickle\n",
        "\n",
        "\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "lr = 0.01\n",
        "PCA_dim = 8\n",
        "CLS_num = 2\n",
        "\n",
        "\n",
        "\n",
        "with open('./data.pkl','rb') as file:\n",
        "    data = pickle.load(file)\n",
        "X = data['X']\n",
        "y = data['Y']\n",
        "\n",
        "\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "def Fit_to_quantum(X,PCA_dim):\n",
        "    pca = PCA(n_components=PCA_dim)\n",
        "    X_pca = pca.fit_transform(X)\n",
        "    return X_pca\n",
        "    \n",
        "\n",
        "\n",
        "# 정규화 (표준 스케일러 사용)\n",
        "#x_train_pca = Fit_to_quantum(x_train,PCA_dim)\n",
        "#x_test_pca = Fit_to_quantum(x_test,PCA_dim)\n",
        "\n",
        "# PyTorch Tensor로 변환\n",
        "x_train_pca, y_train = torch.tensor(x_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long)\n",
        "x_test_pca, y_test = torch.tensor(x_test, dtype=torch.float32), torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "\n",
        "class Feature_data_loader(Dataset):\n",
        "    def __init__(self,x_train,y_train):\n",
        "        self.feature1 = x_train\n",
        "        temp = copy.deepcopy(x_train)\n",
        "        shuffle = torch.randperm(len(temp))\n",
        "        self.feature2 = temp[shuffle]\n",
        "        \n",
        "        self.y1 = y_train\n",
        "        temp_y = copy.deepcopy(y_train)\n",
        "        self.y2 = temp_y[shuffle]\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.feature1)\n",
        "    def __getitem__(self,idx):\n",
        "        input1 = self.feature1[idx]\n",
        "        input2 = self.feature2[idx]\n",
        "        if self.y1[idx] == self.y2[idx]:\n",
        "            label = torch.tensor(1.).float()\n",
        "        else:\n",
        "            label = torch.tensor(0.).float()\n",
        "        return [input1,input2],label\n",
        "\n",
        "\n",
        "# DataLoader 생성\n",
        "\n",
        "\n",
        "train_loader = DataLoader(TensorDataset(x_train_pca, y_train.float()), batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(x_test_pca, y_test.float()), batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "N4Y4dnYJBAEt",
        "notebookRunGroups": {
          "groupValue": "2"
        }
      },
      "outputs": [],
      "source": [
        "def accuracy(pred, true):\n",
        "    # 예측값이 로짓 혹은 확률값인 경우, 최대 값을 가진 인덱스를 구함 (가장 확률이 높은 클래스)\n",
        "    pred = pred.detach().cpu()\n",
        "    true = true.cpu()\n",
        "    pred_labels = torch.round(pred)\n",
        "    # 예측 레이블과 실제 레이블이 일치하는 경우를 계산\n",
        "    correct = (pred_labels == true).sum()\n",
        "    # 정확도를 계산\n",
        "    acc = correct / true.size(0)\n",
        "    return acc.item()\n",
        "\n",
        "class Early_stop_train():\n",
        "    def __init__(self,model, optimizer, criterion):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.criterion = criterion\n",
        "\n",
        "\n",
        "\n",
        "        self.loss_list = [1e100]\n",
        "        self.stop_count = 0\n",
        "\n",
        "    def train_model(self,train_loader,test_loader=None ,epochs=200,res = 10):\n",
        "        self.model.train()\n",
        "        for epoch in range(epochs):\n",
        "            if self.stop_count>=res:\n",
        "                break\n",
        "            loss_val,_ = self.test(test_loader)\n",
        "            self.loss_list.append(loss_val)\n",
        "\n",
        "            if self.loss_list[-1]>=np.min(self.loss_list[:-1]):\n",
        "                self.stop_count+=1\n",
        "            else:\n",
        "                self.stop_count = 0\n",
        "            loss_list = []\n",
        "            acc_list = []\n",
        "            for X_train,y_train in train_loader:\n",
        "\n",
        "                self.optimizer.zero_grad()\n",
        "                output = self.model(X_train)\n",
        "\n",
        "                loss = self.criterion(output.squeeze(), y_train)\n",
        "\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                loss_list.append(loss.item())\n",
        "                acc = accuracy(output,y_train)\n",
        "                acc_list.append(acc)\n",
        "\n",
        "                sys.stdout.write(f\"\\rEpoch {epoch+1} Loss {np.mean(loss_list):4f} acc : {np.mean(acc_list):4f} stop count : {self.stop_count}\")\n",
        "\n",
        "\n",
        "    def test(self,test_loader):\n",
        "        if test_loader is None:\n",
        "            return 0,0\n",
        "        else:\n",
        "            #self.model.eval()\n",
        "            test_loss = 0\n",
        "            correct = 0\n",
        "            with torch.no_grad():\n",
        "                for data, target in test_loader:\n",
        "                    data, target = data, target\n",
        "                    output = self.model(data)\n",
        "                    test_loss += self.criterion(output.squeeze(), target).item()\n",
        "\n",
        "                    correct += accuracy(output,target)*len(output)\n",
        "\n",
        "            print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)')\n",
        "            return test_loss,correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9k3d3GfMBAEv",
        "outputId": "12102841-2511-4734-c1a8-1100ee35e2fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 3.3810, Accuracy: 192.99999928474426/300 (64%)\n",
            "Epoch 1 Loss 0.679389 acc : 0.637121 stop count : 0\n",
            "Test set: Average loss: 3.3603, Accuracy: 208.00000095367432/300 (69%)\n",
            "Epoch 2 Loss 0.675508 acc : 0.697538 stop count : 0\n",
            "Test set: Average loss: 3.3397, Accuracy: 223.0/300 (74%)\n",
            "Epoch 3 Loss 0.671888 acc : 0.738636 stop count : 0\n",
            "Test set: Average loss: 3.3194, Accuracy: 231.99999976158142/300 (77%)\n",
            "Epoch 4 Loss 0.668139 acc : 0.757860 stop count : 0\n",
            "Test set: Average loss: 3.2993, Accuracy: 235.99999976158142/300 (79%)\n",
            "Epoch 5 Loss 0.664487 acc : 0.771780 stop count : 0\n",
            "Test set: Average loss: 3.2797, Accuracy: 235.00000071525574/300 (78%)\n",
            "Epoch 6 Loss 0.660906 acc : 0.772348 stop count : 0\n",
            "Test set: Average loss: 3.2600, Accuracy: 234.00000071525574/300 (78%)\n",
            "Epoch 7 Loss 0.657210 acc : 0.778693 stop count : 0\n",
            "Test set: Average loss: 3.2406, Accuracy: 237.00000071525574/300 (79%)\n",
            "Epoch 8 Loss 0.653586 acc : 0.784470 stop count : 0\n",
            "Test set: Average loss: 3.2211, Accuracy: 240.99999976158142/300 (80%)\n",
            "Epoch 9 Loss 0.649918 acc : 0.779640 stop count : 0\n",
            "Test set: Average loss: 3.2018, Accuracy: 240.9999988079071/300 (80%)\n",
            "Epoch 10 Loss 0.646348 acc : 0.775663 stop count : 0\n",
            "Test set: Average loss: 3.1815, Accuracy: 241.9999988079071/300 (81%)\n",
            "Epoch 11 Loss 0.642554 acc : 0.777083 stop count : 0\n",
            "Test set: Average loss: 3.1615, Accuracy: 244.00000047683716/300 (81%)\n",
            "Epoch 12 Loss 0.638711 acc : 0.779830 stop count : 0\n",
            "Test set: Average loss: 3.1414, Accuracy: 244.00000047683716/300 (81%)\n",
            "Epoch 13 Loss 0.634868 acc : 0.784470 stop count : 0\n",
            "Test set: Average loss: 3.1206, Accuracy: 245.00000047683716/300 (82%)\n",
            "Epoch 14 Loss 0.631035 acc : 0.781345 stop count : 0\n",
            "Test set: Average loss: 3.0987, Accuracy: 246.00000047683716/300 (82%)\n",
            "Epoch 15 Loss 0.626910 acc : 0.785890 stop count : 0\n",
            "Test set: Average loss: 3.0758, Accuracy: 246.9999988079071/300 (82%)\n",
            "Epoch 16 Loss 0.622607 acc : 0.787216 stop count : 0\n",
            "Test set: Average loss: 3.0526, Accuracy: 246.99999976158142/300 (82%)\n",
            "Epoch 17 Loss 0.618245 acc : 0.789110 stop count : 0\n",
            "Test set: Average loss: 3.0291, Accuracy: 248.99999976158142/300 (83%)\n",
            "Epoch 18 Loss 0.614271 acc : 0.785322 stop count : 0\n",
            "Test set: Average loss: 3.0047, Accuracy: 248.99999976158142/300 (83%)\n",
            "Epoch 19 Loss 0.609723 acc : 0.787027 stop count : 0\n",
            "Test set: Average loss: 2.9820, Accuracy: 247.99999976158142/300 (83%)\n",
            "Epoch 20 Loss 0.605540 acc : 0.789962 stop count : 0\n",
            "Test set: Average loss: 2.9586, Accuracy: 248.99999976158142/300 (83%)\n",
            "Epoch 21 Loss 0.601082 acc : 0.794318 stop count : 0\n",
            "Test set: Average loss: 2.9358, Accuracy: 249.99999976158142/300 (83%)\n",
            "Epoch 22 Loss 0.596808 acc : 0.794318 stop count : 0\n",
            "Test set: Average loss: 2.9123, Accuracy: 249.99999976158142/300 (83%)\n",
            "Epoch 23 Loss 0.592601 acc : 0.795549 stop count : 0\n",
            "Test set: Average loss: 2.8888, Accuracy: 249.99999976158142/300 (83%)\n",
            "Epoch 24 Loss 0.587859 acc : 0.797348 stop count : 0\n",
            "Test set: Average loss: 2.8661, Accuracy: 249.99999976158142/300 (83%)\n",
            "Epoch 25 Loss 0.583709 acc : 0.796780 stop count : 0\n",
            "Test set: Average loss: 2.8429, Accuracy: 250.99999976158142/300 (84%)\n",
            "Epoch 26 Loss 0.579488 acc : 0.796496 stop count : 0\n",
            "Test set: Average loss: 2.8198, Accuracy: 251.99999976158142/300 (84%)\n",
            "Epoch 27 Loss 0.575133 acc : 0.793845 stop count : 0\n",
            "Test set: Average loss: 2.7959, Accuracy: 250.99999976158142/300 (84%)\n",
            "Epoch 28 Loss 0.570359 acc : 0.795928 stop count : 0\n",
            "Test set: Average loss: 2.7729, Accuracy: 250.99999976158142/300 (84%)\n",
            "Epoch 29 Loss 0.565904 acc : 0.798958 stop count : 0\n",
            "Test set: Average loss: 2.7498, Accuracy: 251.99999976158142/300 (84%)\n",
            "Epoch 30 Loss 0.562062 acc : 0.795360 stop count : 0\n",
            "Test set: Average loss: 2.7260, Accuracy: 252.99999976158142/300 (84%)\n",
            "Epoch 31 Loss 0.557386 acc : 0.796591 stop count : 0\n",
            "Test set: Average loss: 2.7018, Accuracy: 252.99999976158142/300 (84%)\n",
            "Epoch 32 Loss 0.552765 acc : 0.798580 stop count : 0\n",
            "Test set: Average loss: 2.6784, Accuracy: 253.99999976158142/300 (85%)\n",
            "Epoch 33 Loss 0.548437 acc : 0.796970 stop count : 0\n",
            "Test set: Average loss: 2.6553, Accuracy: 254.99999976158142/300 (85%)\n",
            "Epoch 34 Loss 0.543878 acc : 0.801610 stop count : 0\n",
            "Test set: Average loss: 2.6318, Accuracy: 254.99999976158142/300 (85%)\n",
            "Epoch 35 Loss 0.539071 acc : 0.799905 stop count : 0\n",
            "Test set: Average loss: 2.6080, Accuracy: 255.99999976158142/300 (85%)\n",
            "Epoch 36 Loss 0.534529 acc : 0.803220 stop count : 0\n",
            "Test set: Average loss: 2.5845, Accuracy: 255.99999976158142/300 (85%)\n",
            "Epoch 37 Loss 0.530057 acc : 0.804545 stop count : 0\n",
            "Test set: Average loss: 2.5605, Accuracy: 256.9999997615814/300 (86%)\n",
            "Epoch 38 Loss 0.525585 acc : 0.805966 stop count : 0\n",
            "Test set: Average loss: 2.5367, Accuracy: 256.9999997615814/300 (86%)\n",
            "Epoch 39 Loss 0.521369 acc : 0.809754 stop count : 0\n",
            "Test set: Average loss: 2.5131, Accuracy: 256.9999997615814/300 (86%)\n",
            "Epoch 40 Loss 0.516579 acc : 0.811458 stop count : 0\n",
            "Test set: Average loss: 2.4898, Accuracy: 255.99999976158142/300 (85%)\n",
            "Epoch 41 Loss 0.511995 acc : 0.815720 stop count : 0\n",
            "Test set: Average loss: 2.4658, Accuracy: 256.9999997615814/300 (86%)\n",
            "Epoch 42 Loss 0.507524 acc : 0.816951 stop count : 0\n",
            "Test set: Average loss: 2.4425, Accuracy: 257.9999997615814/300 (86%)\n",
            "Epoch 43 Loss 0.502822 acc : 0.820076 stop count : 0\n",
            "Test set: Average loss: 2.4197, Accuracy: 257.9999997615814/300 (86%)\n",
            "Epoch 44 Loss 0.498426 acc : 0.821307 stop count : 0\n",
            "Test set: Average loss: 2.3961, Accuracy: 257.9999997615814/300 (86%)\n",
            "Epoch 45 Loss 0.493818 acc : 0.825758 stop count : 0\n",
            "Test set: Average loss: 2.3724, Accuracy: 258.9999997615814/300 (86%)\n",
            "Epoch 46 Loss 0.489187 acc : 0.829735 stop count : 0\n",
            "Test set: Average loss: 2.3495, Accuracy: 259.9999988079071/300 (87%)\n",
            "Epoch 47 Loss 0.484378 acc : 0.833239 stop count : 0\n",
            "Test set: Average loss: 2.3269, Accuracy: 260.9999988079071/300 (87%)\n",
            "Epoch 48 Loss 0.480076 acc : 0.830114 stop count : 0\n",
            "Test set: Average loss: 2.3038, Accuracy: 259.9999988079071/300 (87%)\n",
            "Epoch 49 Loss 0.475468 acc : 0.834470 stop count : 0\n",
            "Test set: Average loss: 2.2807, Accuracy: 260.9999988079071/300 (87%)\n",
            "Epoch 50 Loss 0.471113 acc : 0.837216 stop count : 0\n",
            "Test set: Average loss: 2.2577, Accuracy: 260.9999988079071/300 (87%)\n",
            "Epoch 51 Loss 0.466305 acc : 0.841667 stop count : 0\n",
            "Test set: Average loss: 2.2351, Accuracy: 261.9999988079071/300 (87%)\n",
            "Epoch 52 Loss 0.462190 acc : 0.841004 stop count : 0\n",
            "Test set: Average loss: 2.2128, Accuracy: 264.00000047683716/300 (88%)\n",
            "Epoch 53 Loss 0.457276 acc : 0.845928 stop count : 0\n",
            "Test set: Average loss: 2.1904, Accuracy: 262.9999988079071/300 (88%)\n",
            "Epoch 54 Loss 0.453035 acc : 0.848485 stop count : 0\n",
            "Test set: Average loss: 2.1686, Accuracy: 263.9999988079071/300 (88%)\n",
            "Epoch 55 Loss 0.448114 acc : 0.851610 stop count : 0\n",
            "Test set: Average loss: 2.1461, Accuracy: 265.00000047683716/300 (88%)\n",
            "Epoch 56 Loss 0.444001 acc : 0.853977 stop count : 0\n",
            "Test set: Average loss: 2.1244, Accuracy: 265.00000047683716/300 (88%)\n",
            "Epoch 57 Loss 0.439186 acc : 0.857292 stop count : 0\n",
            "Test set: Average loss: 2.1026, Accuracy: 266.00000047683716/300 (89%)\n",
            "Epoch 58 Loss 0.435083 acc : 0.861458 stop count : 0\n",
            "Test set: Average loss: 2.0805, Accuracy: 267.00000047683716/300 (89%)\n",
            "Epoch 59 Loss 0.430897 acc : 0.863826 stop count : 0\n",
            "Test set: Average loss: 2.0589, Accuracy: 267.99999952316284/300 (89%)\n",
            "Epoch 60 Loss 0.425905 acc : 0.864489 stop count : 0\n",
            "Test set: Average loss: 2.0376, Accuracy: 266.99999952316284/300 (89%)\n",
            "Epoch 61 Loss 0.421728 acc : 0.865814 stop count : 0\n",
            "Test set: Average loss: 2.0161, Accuracy: 266.99999952316284/300 (89%)\n",
            "Epoch 62 Loss 0.417307 acc : 0.865720 stop count : 0\n",
            "Test set: Average loss: 1.9941, Accuracy: 266.99999952316284/300 (89%)\n",
            "Epoch 63 Loss 0.413084 acc : 0.865720 stop count : 0\n",
            "Test set: Average loss: 1.9729, Accuracy: 267.99999952316284/300 (89%)\n",
            "Epoch 64 Loss 0.408862 acc : 0.868182 stop count : 0\n",
            "Test set: Average loss: 1.9519, Accuracy: 267.99999952316284/300 (89%)\n",
            "Epoch 65 Loss 0.404529 acc : 0.872822 stop count : 0\n",
            "Test set: Average loss: 1.9307, Accuracy: 269.0000011920929/300 (90%)\n",
            "Epoch 66 Loss 0.400341 acc : 0.876799 stop count : 0\n",
            "Test set: Average loss: 1.9105, Accuracy: 269.0000011920929/300 (90%)\n",
            "Epoch 67 Loss 0.396052 acc : 0.877178 stop count : 0\n",
            "Test set: Average loss: 1.8899, Accuracy: 270.0000011920929/300 (90%)\n",
            "Epoch 68 Loss 0.392009 acc : 0.876894 stop count : 0\n",
            "Test set: Average loss: 1.8693, Accuracy: 270.0000011920929/300 (90%)\n",
            "Epoch 69 Loss 0.388045 acc : 0.877083 stop count : 0\n",
            "Test set: Average loss: 1.8487, Accuracy: 269.0000011920929/300 (90%)\n",
            "Epoch 70 Loss 0.383654 acc : 0.880114 stop count : 0\n",
            "Test set: Average loss: 1.8294, Accuracy: 268.0000011920929/300 (89%)\n",
            "Epoch 71 Loss 0.379556 acc : 0.882670 stop count : 0\n",
            "Test set: Average loss: 1.8102, Accuracy: 269.0000011920929/300 (90%)\n",
            "Epoch 72 Loss 0.376531 acc : 0.883617 stop count : 0\n",
            "Test set: Average loss: 1.7916, Accuracy: 269.0000011920929/300 (90%)\n",
            "Epoch 73 Loss 0.371787 acc : 0.887121 stop count : 0\n",
            "Test set: Average loss: 1.7731, Accuracy: 269.0000011920929/300 (90%)\n",
            "Epoch 74 Loss 0.367948 acc : 0.889962 stop count : 0\n",
            "Test set: Average loss: 1.7545, Accuracy: 269.0000011920929/300 (90%)\n",
            "Epoch 75 Loss 0.364373 acc : 0.892708 stop count : 0\n",
            "Test set: Average loss: 1.7363, Accuracy: 269.0000011920929/300 (90%)\n",
            "Epoch 76 Loss 0.360396 acc : 0.892992 stop count : 0\n",
            "Test set: Average loss: 1.7187, Accuracy: 269.0000011920929/300 (90%)\n",
            "Epoch 77 Loss 0.356805 acc : 0.892898 stop count : 0\n",
            "Test set: Average loss: 1.7021, Accuracy: 270.0000011920929/300 (90%)\n",
            "Epoch 78 Loss 0.353295 acc : 0.895928 stop count : 0\n",
            "Test set: Average loss: 1.6854, Accuracy: 269.0000011920929/300 (90%)\n",
            "Epoch 79 Loss 0.350231 acc : 0.894223 stop count : 0\n",
            "Test set: Average loss: 1.6695, Accuracy: 270.0000011920929/300 (90%)\n",
            "Epoch 80 Loss 0.346844 acc : 0.897159 stop count : 0\n",
            "Test set: Average loss: 1.6536, Accuracy: 270.0000011920929/300 (90%)\n",
            "Epoch 81 Loss 0.343825 acc : 0.898201 stop count : 0\n",
            "Test set: Average loss: 1.6382, Accuracy: 272.0000011920929/300 (91%)\n",
            "Epoch 82 Loss 0.340011 acc : 0.897538 stop count : 0\n",
            "Test set: Average loss: 1.6235, Accuracy: 271.0000011920929/300 (90%)\n",
            "Epoch 83 Loss 0.337159 acc : 0.897159 stop count : 0\n",
            "Test set: Average loss: 1.6088, Accuracy: 271.0000011920929/300 (90%)\n",
            "Epoch 84 Loss 0.334323 acc : 0.896970 stop count : 0\n",
            "Test set: Average loss: 1.5947, Accuracy: 271.0000011920929/300 (90%)\n",
            "Epoch 85 Loss 0.331249 acc : 0.897159 stop count : 0\n",
            "Test set: Average loss: 1.5808, Accuracy: 271.0000011920929/300 (90%)\n",
            "Epoch 86 Loss 0.327835 acc : 0.899148 stop count : 0\n",
            "Test set: Average loss: 1.5677, Accuracy: 272.0000011920929/300 (91%)\n",
            "Epoch 87 Loss 0.325811 acc : 0.898580 stop count : 0\n",
            "Test set: Average loss: 1.5536, Accuracy: 272.0000011920929/300 (91%)\n",
            "Epoch 88 Loss 0.322582 acc : 0.897348 stop count : 0\n",
            "Test set: Average loss: 1.5411, Accuracy: 272.0000011920929/300 (91%)\n",
            "Epoch 89 Loss 0.320202 acc : 0.898580 stop count : 0\n",
            "Test set: Average loss: 1.5286, Accuracy: 272.0000011920929/300 (91%)\n",
            "Epoch 90 Loss 0.317590 acc : 0.900000 stop count : 0\n",
            "Test set: Average loss: 1.5158, Accuracy: 272.0000011920929/300 (91%)\n",
            "Epoch 91 Loss 0.315427 acc : 0.899621 stop count : 0\n",
            "Test set: Average loss: 1.5032, Accuracy: 273.0000002384186/300 (91%)\n",
            "Epoch 92 Loss 0.312217 acc : 0.901610 stop count : 0\n",
            "Test set: Average loss: 1.4909, Accuracy: 273.0000002384186/300 (91%)\n",
            "Epoch 93 Loss 0.309603 acc : 0.898864 stop count : 0\n",
            "Test set: Average loss: 1.4802, Accuracy: 273.0000002384186/300 (91%)\n",
            "Epoch 94 Loss 0.307638 acc : 0.898295 stop count : 0\n",
            "Test set: Average loss: 1.4685, Accuracy: 273.0000002384186/300 (91%)\n",
            "Epoch 95 Loss 0.304694 acc : 0.901610 stop count : 0\n",
            "Test set: Average loss: 1.4572, Accuracy: 273.0000002384186/300 (91%)\n",
            "Epoch 96 Loss 0.302721 acc : 0.901231 stop count : 0\n",
            "Test set: Average loss: 1.4460, Accuracy: 275.0000002384186/300 (92%)\n",
            "Epoch 97 Loss 0.299902 acc : 0.904545 stop count : 0\n",
            "Test set: Average loss: 1.4351, Accuracy: 275.0000002384186/300 (92%)\n",
            "Epoch 98 Loss 0.298509 acc : 0.903788 stop count : 0\n",
            "Test set: Average loss: 1.4241, Accuracy: 275.0000002384186/300 (92%)\n",
            "Epoch 99 Loss 0.295835 acc : 0.904356 stop count : 0\n",
            "Test set: Average loss: 1.4135, Accuracy: 275.0000002384186/300 (92%)\n",
            "Epoch 100 Loss 0.293837 acc : 0.905587 stop count : 0\n",
            "Test set: Average loss: 1.4041, Accuracy: 275.0000002384186/300 (92%)\n",
            "Epoch 101 Loss 0.291783 acc : 0.908523 stop count : 0\n",
            "Test set: Average loss: 1.3948, Accuracy: 275.0000002384186/300 (92%)\n",
            "Epoch 102 Loss 0.290035 acc : 0.911174 stop count : 0\n",
            "Test set: Average loss: 1.3851, Accuracy: 275.0000002384186/300 (92%)\n",
            "Epoch 103 Loss 0.287314 acc : 0.913163 stop count : 0\n",
            "Test set: Average loss: 1.3760, Accuracy: 274.0000002384186/300 (91%)\n",
            "Epoch 104 Loss 0.285826 acc : 0.912879 stop count : 0\n",
            "Test set: Average loss: 1.3675, Accuracy: 274.0000002384186/300 (91%)\n",
            "Epoch 105 Loss 0.283775 acc : 0.912973 stop count : 0\n",
            "Test set: Average loss: 1.3591, Accuracy: 274.0000002384186/300 (91%)\n",
            "Epoch 106 Loss 0.281817 acc : 0.914489 stop count : 0\n",
            "Test set: Average loss: 1.3507, Accuracy: 274.0000002384186/300 (91%)\n",
            "Epoch 107 Loss 0.280272 acc : 0.914394 stop count : 0\n",
            "Test set: Average loss: 1.3421, Accuracy: 274.0000002384186/300 (91%)\n",
            "Epoch 108 Loss 0.278651 acc : 0.914110 stop count : 0\n",
            "Test set: Average loss: 1.3345, Accuracy: 275.0000002384186/300 (92%)\n",
            "Epoch 109 Loss 0.276965 acc : 0.914205 stop count : 0\n",
            "Test set: Average loss: 1.3273, Accuracy: 275.0000002384186/300 (92%)\n",
            "Epoch 110 Loss 0.275487 acc : 0.915625 stop count : 0\n",
            "Test set: Average loss: 1.3203, Accuracy: 276.99999928474426/300 (92%)\n",
            "Epoch 111 Loss 0.274097 acc : 0.915436 stop count : 0\n",
            "Test set: Average loss: 1.3135, Accuracy: 276.99999928474426/300 (92%)\n",
            "Epoch 112 Loss 0.271982 acc : 0.915909 stop count : 0\n",
            "Test set: Average loss: 1.3063, Accuracy: 276.0000002384186/300 (92%)\n",
            "Epoch 113 Loss 0.270751 acc : 0.914205 stop count : 0\n",
            "Test set: Average loss: 1.2997, Accuracy: 276.99999928474426/300 (92%)\n",
            "Epoch 114 Loss 0.269454 acc : 0.914110 stop count : 0\n",
            "Test set: Average loss: 1.2928, Accuracy: 276.99999928474426/300 (92%)\n",
            "Epoch 115 Loss 0.267504 acc : 0.914489 stop count : 0\n",
            "Test set: Average loss: 1.2863, Accuracy: 276.99999928474426/300 (92%)\n",
            "Epoch 116 Loss 0.266668 acc : 0.914110 stop count : 0\n",
            "Test set: Average loss: 1.2801, Accuracy: 275.99999928474426/300 (92%)\n",
            "Epoch 117 Loss 0.264746 acc : 0.914394 stop count : 0\n",
            "Test set: Average loss: 1.2739, Accuracy: 275.99999928474426/300 (92%)\n",
            "Epoch 118 Loss 0.263397 acc : 0.914489 stop count : 0\n",
            "Test set: Average loss: 1.2685, Accuracy: 275.99999928474426/300 (92%)\n",
            "Epoch 119 Loss 0.262643 acc : 0.914205 stop count : 0\n",
            "Test set: Average loss: 1.2627, Accuracy: 275.99999928474426/300 (92%)\n",
            "Epoch 120 Loss 0.261140 acc : 0.914394 stop count : 0\n",
            "Test set: Average loss: 1.2571, Accuracy: 275.99999928474426/300 (92%)\n",
            "Epoch 121 Loss 0.260274 acc : 0.914110 stop count : 0\n",
            "Test set: Average loss: 1.2521, Accuracy: 275.99999928474426/300 (92%)\n",
            "Epoch 122 Loss 0.258733 acc : 0.914489 stop count : 0\n",
            "Test set: Average loss: 1.2470, Accuracy: 275.99999928474426/300 (92%)\n",
            "Epoch 123 Loss 0.258135 acc : 0.913920 stop count : 0\n",
            "Test set: Average loss: 1.2419, Accuracy: 275.99999928474426/300 (92%)\n",
            "Epoch 124 Loss 0.256227 acc : 0.914678 stop count : 0\n",
            "Test set: Average loss: 1.2367, Accuracy: 275.99999928474426/300 (92%)\n",
            "Epoch 125 Loss 0.255550 acc : 0.914299 stop count : 0\n",
            "Test set: Average loss: 1.2319, Accuracy: 275.99999928474426/300 (92%)\n",
            "Epoch 126 Loss 0.255163 acc : 0.914015 stop count : 0\n",
            "Test set: Average loss: 1.2273, Accuracy: 275.99999928474426/300 (92%)\n",
            "Epoch 127 Loss 0.253927 acc : 0.914110 stop count : 0\n",
            "Test set: Average loss: 1.2236, Accuracy: 275.99999928474426/300 (92%)\n",
            "Epoch 128 Loss 0.252228 acc : 0.914489 stop count : 0\n",
            "Test set: Average loss: 1.2188, Accuracy: 275.99999928474426/300 (92%)\n",
            "Epoch 129 Loss 0.251824 acc : 0.914015 stop count : 0\n",
            "Test set: Average loss: 1.2147, Accuracy: 275.99999928474426/300 (92%)\n",
            "Epoch 130 Loss 0.250420 acc : 0.914299 stop count : 0\n",
            "Test set: Average loss: 1.2106, Accuracy: 276.99999928474426/300 (92%)\n",
            "Epoch 131 Loss 0.249610 acc : 0.912973 stop count : 0\n",
            "Test set: Average loss: 1.2067, Accuracy: 277.99999928474426/300 (93%)\n",
            "Epoch 132 Loss 0.248437 acc : 0.912879 stop count : 0\n",
            "Test set: Average loss: 1.2035, Accuracy: 277.99999928474426/300 (93%)\n",
            "Epoch 133 Loss 0.247538 acc : 0.912973 stop count : 0\n",
            "Test set: Average loss: 1.2001, Accuracy: 276.99999928474426/300 (92%)\n",
            "Epoch 134 Loss 0.246980 acc : 0.912689 stop count : 0\n",
            "Test set: Average loss: 1.1966, Accuracy: 278.99999928474426/300 (93%)\n",
            "Epoch 135 Loss 0.246510 acc : 0.912784 stop count : 0\n",
            "Test set: Average loss: 1.1923, Accuracy: 278.99999928474426/300 (93%)\n",
            "Epoch 136 Loss 0.245031 acc : 0.912879 stop count : 0\n",
            "Test set: Average loss: 1.1892, Accuracy: 278.99999928474426/300 (93%)\n",
            "Epoch 137 Loss 0.244444 acc : 0.914394 stop count : 0\n",
            "Test set: Average loss: 1.1859, Accuracy: 278.99999928474426/300 (93%)\n",
            "Epoch 138 Loss 0.243330 acc : 0.914489 stop count : 0\n",
            "Test set: Average loss: 1.1832, Accuracy: 278.99999928474426/300 (93%)\n",
            "Epoch 139 Loss 0.242940 acc : 0.914299 stop count : 0\n",
            "Test set: Average loss: 1.1805, Accuracy: 278.99999928474426/300 (93%)\n",
            "Epoch 140 Loss 0.242390 acc : 0.914205 stop count : 0\n",
            "Test set: Average loss: 1.1773, Accuracy: 278.99999928474426/300 (93%)\n",
            "Epoch 141 Loss 0.241965 acc : 0.914015 stop count : 0\n",
            "Test set: Average loss: 1.1742, Accuracy: 278.99999928474426/300 (93%)\n",
            "Epoch 142 Loss 0.240684 acc : 0.915720 stop count : 0\n",
            "Test set: Average loss: 1.1714, Accuracy: 278.99999928474426/300 (93%)\n",
            "Epoch 143 Loss 0.239846 acc : 0.915909 stop count : 0\n",
            "Test set: Average loss: 1.1692, Accuracy: 278.99999928474426/300 (93%)\n",
            "Epoch 144 Loss 0.239511 acc : 0.915625 stop count : 0\n",
            "Test set: Average loss: 1.1663, Accuracy: 278.99999928474426/300 (93%)\n",
            "Epoch 145 Loss 0.238230 acc : 0.916004 stop count : 0\n",
            "Test set: Average loss: 1.1640, Accuracy: 278.99999928474426/300 (93%)\n",
            "Epoch 146 Loss 0.237907 acc : 0.915909 stop count : 0\n",
            "Test set: Average loss: 1.1608, Accuracy: 278.99999928474426/300 (93%)\n",
            "Epoch 147 Loss 0.237445 acc : 0.917045 stop count : 0\n",
            "Test set: Average loss: 1.1586, Accuracy: 278.99999928474426/300 (93%)\n",
            "Epoch 148 Loss 0.236856 acc : 0.917140 stop count : 0\n",
            "Test set: Average loss: 1.1560, Accuracy: 278.99999928474426/300 (93%)\n",
            "Epoch 149 Loss 0.236362 acc : 0.917045 stop count : 0\n",
            "Test set: Average loss: 1.1532, Accuracy: 278.99999928474426/300 (93%)\n",
            "Epoch 150 Loss 0.235107 acc : 0.917424 stop count : 0\n",
            "Test set: Average loss: 1.1515, Accuracy: 278.99999928474426/300 (93%)\n",
            "Epoch 151 Loss 0.234657 acc : 0.917140 stop count : 0\n",
            "Test set: Average loss: 1.1490, Accuracy: 278.99999928474426/300 (93%)\n",
            "Epoch 152 Loss 0.233891 acc : 0.917424 stop count : 0\n",
            "Test set: Average loss: 1.1470, Accuracy: 278.99999928474426/300 (93%)\n",
            "Epoch 153 Loss 0.233808 acc : 0.917140 stop count : 0\n",
            "Test set: Average loss: 1.1458, Accuracy: 278.99999928474426/300 (93%)\n",
            "Epoch 154 Loss 0.233198 acc : 0.917045 stop count : 0\n",
            "Test set: Average loss: 1.1438, Accuracy: 278.99999928474426/300 (93%)\n",
            "Epoch 155 Loss 0.233253 acc : 0.916951 stop count : 0\n",
            "Test set: Average loss: 1.1418, Accuracy: 278.99999928474426/300 (93%)\n",
            "Epoch 156 Loss 0.232347 acc : 0.917235 stop count : 0\n",
            "Test set: Average loss: 1.1397, Accuracy: 278.99999928474426/300 (93%)\n",
            "Epoch 157 Loss 0.231690 acc : 0.918561 stop count : 0\n",
            "Test set: Average loss: 1.1381, Accuracy: 278.99999928474426/300 (93%)\n",
            "Epoch 158 Loss 0.231740 acc : 0.918277 stop count : 0\n",
            "Test set: Average loss: 1.1356, Accuracy: 278.99999928474426/300 (93%)\n",
            "Epoch 159 Loss 0.230820 acc : 0.918466 stop count : 0\n",
            "Test set: Average loss: 1.1339, Accuracy: 278.99999928474426/300 (93%)\n",
            "Epoch 160 Loss 0.230358 acc : 0.918466 stop count : 0\n",
            "Test set: Average loss: 1.1324, Accuracy: 278.99999928474426/300 (93%)\n",
            "Epoch 161 Loss 0.229708 acc : 0.918561 stop count : 0\n",
            "Test set: Average loss: 1.1308, Accuracy: 278.99999928474426/300 (93%)\n",
            "Epoch 162 Loss 0.228941 acc : 0.918750 stop count : 0\n",
            "Test set: Average loss: 1.1290, Accuracy: 278.99999928474426/300 (93%)\n",
            "Epoch 163 Loss 0.228822 acc : 0.918750 stop count : 0\n",
            "Test set: Average loss: 1.1283, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 164 Loss 0.228552 acc : 0.918655 stop count : 0\n",
            "Test set: Average loss: 1.1266, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 165 Loss 0.227924 acc : 0.920076 stop count : 0\n",
            "Test set: Average loss: 1.1249, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 166 Loss 0.227839 acc : 0.920076 stop count : 0\n",
            "Test set: Average loss: 1.1236, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 167 Loss 0.226880 acc : 0.920076 stop count : 0\n",
            "Test set: Average loss: 1.1220, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 168 Loss 0.226417 acc : 0.920265 stop count : 0\n",
            "Test set: Average loss: 1.1208, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 169 Loss 0.225997 acc : 0.919886 stop count : 0\n",
            "Test set: Average loss: 1.1199, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 170 Loss 0.226097 acc : 0.921212 stop count : 0\n",
            "Test set: Average loss: 1.1183, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 171 Loss 0.225330 acc : 0.921307 stop count : 0\n",
            "Test set: Average loss: 1.1172, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 172 Loss 0.225101 acc : 0.921496 stop count : 0\n",
            "Test set: Average loss: 1.1166, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 173 Loss 0.224430 acc : 0.921496 stop count : 0\n",
            "Test set: Average loss: 1.1156, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 174 Loss 0.224776 acc : 0.922822 stop count : 0\n",
            "Test set: Average loss: 1.1134, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 175 Loss 0.224448 acc : 0.922633 stop count : 0\n",
            "Test set: Average loss: 1.1125, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 176 Loss 0.223570 acc : 0.922727 stop count : 0\n",
            "Test set: Average loss: 1.1120, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 177 Loss 0.222659 acc : 0.923106 stop count : 0\n",
            "Test set: Average loss: 1.1107, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 178 Loss 0.223210 acc : 0.922727 stop count : 0\n",
            "Test set: Average loss: 1.1102, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 179 Loss 0.222391 acc : 0.922727 stop count : 0\n",
            "Test set: Average loss: 1.1087, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 180 Loss 0.221832 acc : 0.923106 stop count : 0\n",
            "Test set: Average loss: 1.1073, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 181 Loss 0.221406 acc : 0.923106 stop count : 0\n",
            "Test set: Average loss: 1.1064, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 182 Loss 0.221148 acc : 0.923011 stop count : 0\n",
            "Test set: Average loss: 1.1056, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 183 Loss 0.220835 acc : 0.923106 stop count : 0\n",
            "Test set: Average loss: 1.1057, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 184 Loss 0.220510 acc : 0.923011 stop count : 1\n",
            "Test set: Average loss: 1.1047, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 185 Loss 0.220830 acc : 0.922633 stop count : 0\n",
            "Test set: Average loss: 1.1040, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 186 Loss 0.219692 acc : 0.923295 stop count : 0\n",
            "Test set: Average loss: 1.1027, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 187 Loss 0.220416 acc : 0.922917 stop count : 0\n",
            "Test set: Average loss: 1.1015, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 188 Loss 0.219708 acc : 0.922633 stop count : 0\n",
            "Test set: Average loss: 1.1007, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 189 Loss 0.219356 acc : 0.923011 stop count : 0\n",
            "Test set: Average loss: 1.1001, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 190 Loss 0.219453 acc : 0.922538 stop count : 0\n",
            "Test set: Average loss: 1.0996, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 191 Loss 0.218613 acc : 0.922917 stop count : 0\n",
            "Test set: Average loss: 1.0991, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 192 Loss 0.218725 acc : 0.922822 stop count : 0\n",
            "Test set: Average loss: 1.0983, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 193 Loss 0.218003 acc : 0.923011 stop count : 0\n",
            "Test set: Average loss: 1.0982, Accuracy: 280.99999928474426/300 (94%)\n",
            "Epoch 194 Loss 0.218618 acc : 0.921117 stop count : 0\n",
            "Test set: Average loss: 1.0965, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 195 Loss 0.218150 acc : 0.921212 stop count : 0\n",
            "Test set: Average loss: 1.0965, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 196 Loss 0.217615 acc : 0.922727 stop count : 1\n",
            "Test set: Average loss: 1.0963, Accuracy: 280.99999928474426/300 (94%)\n",
            "Epoch 197 Loss 0.216998 acc : 0.923011 stop count : 0\n",
            "Test set: Average loss: 1.0954, Accuracy: 280.99999928474426/300 (94%)\n",
            "Epoch 198 Loss 0.217268 acc : 0.921307 stop count : 0\n",
            "Test set: Average loss: 1.0956, Accuracy: 280.99999928474426/300 (94%)\n",
            "Epoch 199 Loss 0.217360 acc : 0.922254 stop count : 1\n",
            "Test set: Average loss: 1.0952, Accuracy: 280.99999928474426/300 (94%)\n",
            "Epoch 200 Loss 0.216206 acc : 0.922917 stop count : 0\n",
            "Test set: Average loss: 1.0942, Accuracy: 280.99999928474426/300 (94%)\n",
            "Epoch 201 Loss 0.216127 acc : 0.921496 stop count : 0\n",
            "Test set: Average loss: 1.0937, Accuracy: 280.99999928474426/300 (94%)\n",
            "Epoch 202 Loss 0.216289 acc : 0.922633 stop count : 0\n",
            "Test set: Average loss: 1.0930, Accuracy: 280.99999928474426/300 (94%)\n",
            "Epoch 203 Loss 0.215889 acc : 0.921402 stop count : 0\n",
            "Test set: Average loss: 1.0924, Accuracy: 280.99999928474426/300 (94%)\n",
            "Epoch 204 Loss 0.215459 acc : 0.921402 stop count : 0\n",
            "Test set: Average loss: 1.0919, Accuracy: 280.99999928474426/300 (94%)\n",
            "Epoch 205 Loss 0.215748 acc : 0.922633 stop count : 0\n",
            "Test set: Average loss: 1.0913, Accuracy: 280.99999928474426/300 (94%)\n",
            "Epoch 206 Loss 0.214932 acc : 0.921402 stop count : 0\n",
            "Test set: Average loss: 1.0917, Accuracy: 280.99999928474426/300 (94%)\n",
            "Epoch 207 Loss 0.215142 acc : 0.919697 stop count : 1\n",
            "Test set: Average loss: 1.0908, Accuracy: 280.99999928474426/300 (94%)\n",
            "Epoch 208 Loss 0.214680 acc : 0.921402 stop count : 0\n",
            "Test set: Average loss: 1.0908, Accuracy: 280.99999928474426/300 (94%)\n",
            "Epoch 209 Loss 0.214899 acc : 0.921117 stop count : 1\n",
            "Test set: Average loss: 1.0906, Accuracy: 280.99999928474426/300 (94%)\n",
            "Epoch 210 Loss 0.214656 acc : 0.921307 stop count : 0\n",
            "Test set: Average loss: 1.0903, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 211 Loss 0.213598 acc : 0.921496 stop count : 0\n",
            "Test set: Average loss: 1.0896, Accuracy: 280.99999928474426/300 (94%)\n",
            "Epoch 212 Loss 0.213924 acc : 0.921307 stop count : 0\n",
            "Test set: Average loss: 1.0890, Accuracy: 280.99999928474426/300 (94%)\n",
            "Epoch 213 Loss 0.213322 acc : 0.921686 stop count : 0\n",
            "Test set: Average loss: 1.0893, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 214 Loss 0.213468 acc : 0.921307 stop count : 1\n",
            "Test set: Average loss: 1.0888, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 215 Loss 0.213258 acc : 0.921496 stop count : 0\n",
            "Test set: Average loss: 1.0885, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 216 Loss 0.213493 acc : 0.921307 stop count : 0\n",
            "Test set: Average loss: 1.0876, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 217 Loss 0.212660 acc : 0.921402 stop count : 0\n",
            "Test set: Average loss: 1.0876, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 218 Loss 0.212234 acc : 0.921591 stop count : 1\n",
            "Test set: Average loss: 1.0877, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 219 Loss 0.212306 acc : 0.921591 stop count : 2\n",
            "Test set: Average loss: 1.0873, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 220 Loss 0.212400 acc : 0.921496 stop count : 0\n",
            "Test set: Average loss: 1.0869, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 221 Loss 0.211993 acc : 0.921496 stop count : 0\n",
            "Test set: Average loss: 1.0861, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 222 Loss 0.212147 acc : 0.921496 stop count : 0\n",
            "Test set: Average loss: 1.0864, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 223 Loss 0.212098 acc : 0.921212 stop count : 1\n",
            "Test set: Average loss: 1.0859, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 224 Loss 0.212078 acc : 0.921212 stop count : 0\n",
            "Test set: Average loss: 1.0858, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 225 Loss 0.211482 acc : 0.921402 stop count : 0\n",
            "Test set: Average loss: 1.0856, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 226 Loss 0.211312 acc : 0.921591 stop count : 0\n",
            "Test set: Average loss: 1.0862, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 227 Loss 0.211210 acc : 0.921307 stop count : 1\n",
            "Test set: Average loss: 1.0861, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 228 Loss 0.210815 acc : 0.919792 stop count : 2\n",
            "Test set: Average loss: 1.0851, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 229 Loss 0.210548 acc : 0.920076 stop count : 0\n",
            "Test set: Average loss: 1.0851, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 230 Loss 0.210934 acc : 0.920076 stop count : 0\n",
            "Test set: Average loss: 1.0852, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 231 Loss 0.210461 acc : 0.920076 stop count : 1\n",
            "Test set: Average loss: 1.0858, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 232 Loss 0.209709 acc : 0.920360 stop count : 2\n",
            "Test set: Average loss: 1.0851, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 233 Loss 0.210226 acc : 0.919886 stop count : 0\n",
            "Test set: Average loss: 1.0851, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 234 Loss 0.210044 acc : 0.919886 stop count : 1\n",
            "Test set: Average loss: 1.0846, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 235 Loss 0.210433 acc : 0.919792 stop count : 0\n",
            "Test set: Average loss: 1.0843, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 236 Loss 0.210048 acc : 0.919792 stop count : 0\n",
            "Test set: Average loss: 1.0839, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 237 Loss 0.209613 acc : 0.919886 stop count : 0\n",
            "Test set: Average loss: 1.0839, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 238 Loss 0.208969 acc : 0.920076 stop count : 0\n",
            "Test set: Average loss: 1.0842, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 239 Loss 0.209283 acc : 0.919981 stop count : 1\n",
            "Test set: Average loss: 1.0840, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 240 Loss 0.209132 acc : 0.920265 stop count : 2\n",
            "Test set: Average loss: 1.0844, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 241 Loss 0.209046 acc : 0.919981 stop count : 3\n",
            "Test set: Average loss: 1.0843, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 242 Loss 0.209476 acc : 0.919508 stop count : 4\n",
            "Test set: Average loss: 1.0838, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 243 Loss 0.208750 acc : 0.921496 stop count : 0\n",
            "Test set: Average loss: 1.0836, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 244 Loss 0.209014 acc : 0.922822 stop count : 0\n",
            "Test set: Average loss: 1.0838, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 245 Loss 0.208098 acc : 0.921686 stop count : 1\n",
            "Test set: Average loss: 1.0838, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 246 Loss 0.207976 acc : 0.921780 stop count : 2\n",
            "Test set: Average loss: 1.0833, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 247 Loss 0.208878 acc : 0.921307 stop count : 0\n",
            "Test set: Average loss: 1.0840, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 248 Loss 0.207654 acc : 0.922917 stop count : 1\n",
            "Test set: Average loss: 1.0835, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 249 Loss 0.208735 acc : 0.923958 stop count : 2\n",
            "Test set: Average loss: 1.0832, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 250 Loss 0.207544 acc : 0.924432 stop count : 0\n",
            "Test set: Average loss: 1.0831, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 251 Loss 0.207380 acc : 0.922917 stop count : 0\n",
            "Test set: Average loss: 1.0824, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 252 Loss 0.207355 acc : 0.924432 stop count : 0\n",
            "Test set: Average loss: 1.0829, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 253 Loss 0.207296 acc : 0.924527 stop count : 1\n",
            "Test set: Average loss: 1.0827, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 254 Loss 0.206840 acc : 0.924527 stop count : 2\n",
            "Test set: Average loss: 1.0824, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 255 Loss 0.207283 acc : 0.924337 stop count : 3\n",
            "Test set: Average loss: 1.0829, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 256 Loss 0.207747 acc : 0.923958 stop count : 4\n",
            "Test set: Average loss: 1.0819, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 257 Loss 0.206539 acc : 0.922917 stop count : 0\n",
            "Test set: Average loss: 1.0825, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 258 Loss 0.206896 acc : 0.924148 stop count : 1\n",
            "Test set: Average loss: 1.0828, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 259 Loss 0.206921 acc : 0.924337 stop count : 2\n",
            "Test set: Average loss: 1.0837, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 260 Loss 0.206415 acc : 0.922822 stop count : 3\n",
            "Test set: Average loss: 1.0829, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 261 Loss 0.206482 acc : 0.922822 stop count : 4\n",
            "Test set: Average loss: 1.0828, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 262 Loss 0.206528 acc : 0.924148 stop count : 5\n",
            "Test set: Average loss: 1.0830, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 263 Loss 0.206277 acc : 0.922917 stop count : 6\n",
            "Test set: Average loss: 1.0821, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 264 Loss 0.206414 acc : 0.922822 stop count : 7\n",
            "Test set: Average loss: 1.0823, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 265 Loss 0.207142 acc : 0.923769 stop count : 8\n",
            "Test set: Average loss: 1.0823, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 266 Loss 0.206292 acc : 0.922633 stop count : 9\n",
            "Test set: Average loss: 1.0824, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 267 Loss 0.205760 acc : 0.924432 stop count : 10\n",
            "Test set: Average loss: 1.0830, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 268 Loss 0.205403 acc : 0.924432 stop count : 11\n",
            "Test set: Average loss: 1.0835, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 269 Loss 0.205452 acc : 0.924337 stop count : 12\n",
            "Test set: Average loss: 1.0829, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 270 Loss 0.205821 acc : 0.923011 stop count : 13\n",
            "Test set: Average loss: 1.0828, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 271 Loss 0.205919 acc : 0.923958 stop count : 14\n",
            "Test set: Average loss: 1.0837, Accuracy: 279.99999928474426/300 (93%)\n",
            "Epoch 272 Loss 0.205228 acc : 0.924242 stop count : 15\n",
            "Test set: Average loss: 1.0831, Accuracy: 279.99999928474426/300 (93%)\n",
            "Test Accuracy: 280.00\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from collections import OrderedDict\n",
        "import math\n",
        "from kan import KAN\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.cls_layer_1 = nn.Linear(PCA_dim,PCA_dim*PCA_dim)\n",
        "        self.cls_layer_2 = nn.Linear(PCA_dim*PCA_dim,PCA_dim*2-1)\n",
        "        self.output_layer = nn.Linear(2*PCA_dim-1,1)\n",
        "    def forward(self, x):\n",
        "        x = self.cls_layer_1(x)\n",
        "        x = nn.ReLU()(x)\n",
        "        x = self.cls_layer_2(x)\n",
        "        x = nn.ReLU()(x)\n",
        "        output = self.output_layer(x)\n",
        "        output = nn.Sigmoid()(output)\n",
        "        output = torch.squeeze(output)\n",
        "        return output\n",
        "# 모델, 손실 함수, 최적화 설정\n",
        "\n",
        "\n",
        "\n",
        "model = Model(); criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_process = Early_stop_train(model, optimizer, criterion)\n",
        "train_process.train_model(train_loader,test_loader,epochs=5000,res=15)\n",
        "\n",
        "_,acc = train_process.test(test_loader)\n",
        "print(f\"Test Accuracy: {acc:.2f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from kan import KAN, create_dataset\n",
        "def reg(acts_scale,KAN_layer, factor=1,lamb_l1=1.,lamb_entropy=2.,lamb_coef=0.,lamb_coefdiff=0.):\n",
        "\n",
        "    def nonlinear(x, th=1e-16):\n",
        "        return (x < th) * x * factor + (x > th) * (x + (factor - 1) * th)\n",
        "\n",
        "    reg_ = 0.\n",
        "    for i in range(len(acts_scale)):\n",
        "        vec = acts_scale[i].reshape(-1, )\n",
        "\n",
        "        p = vec / torch.sum(vec)\n",
        "        l1 = torch.sum(nonlinear(vec))\n",
        "        entropy = - torch.sum(p * torch.log2(p + 1e-4))\n",
        "        reg_ += lamb_l1 * l1 + lamb_entropy * entropy  # both l1 and entropy\n",
        "\n",
        "    # regularize coefficient to encourage spline to be zero\n",
        "    for i in range(len(KAN_layer.act_fun)):\n",
        "        coeff_l1 = torch.sum(torch.mean(torch.abs(KAN_layer.act_fun[i].coef), dim=1))\n",
        "        coeff_diff_l1 = torch.sum(torch.mean(torch.abs(torch.diff(KAN_layer.act_fun[i].coef)), dim=1))\n",
        "        reg_ += lamb_coef * coeff_l1 + lamb_coefdiff * coeff_diff_l1\n",
        "\n",
        "    return reg_\n",
        "def accuracy(pred, true):\n",
        "    # 예측값이 로짓 혹은 확률값인 경우, 최대 값을 가진 인덱스를 구함 (가장 확률이 높은 클래스)\n",
        "    pred = pred.detach().cpu()\n",
        "    true = true.cpu()\n",
        "    try:\n",
        "        pred_labels = torch.argmax(pred, dim=1)\n",
        "    except:\n",
        "        pred_labels = torch.round(pred)\n",
        "    # 예측 레이블과 실제 레이블이 일치하는 경우를 계산\n",
        "    correct = (pred_labels == true).sum()\n",
        "    # 정확도를 계산\n",
        "    acc = correct / true.size(0)\n",
        "    return acc.item() \n",
        "\n",
        "class Early_stop_train():\n",
        "    def __init__(self,model, optimizer, criterion):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.criterion = criterion\n",
        "        \n",
        "\n",
        "        \n",
        "        self.loss_list = [1e100]\n",
        "        self.acc_list = []\n",
        "        self.stop_count = 0\n",
        "        \n",
        "    def train_model(self,train_loader,test_loader=None ,epochs=200,res = 10,lamb=0.):\n",
        "        #self.model.train()\n",
        "        \n",
        "        for epoch in range(epochs):\n",
        "            if self.stop_count>=res:\n",
        "                break\n",
        "            loss_val,_ = self.test(test_loader)\n",
        "            self.loss_list.append(loss_val)\n",
        "            \n",
        "            if self.loss_list[-1]>=np.min(self.loss_list[:-1]):\n",
        "                self.stop_count+=1\n",
        "            else:\n",
        "                self.optimal = self.model.state_dict()\n",
        "                self.stop_count = 0\n",
        "            loss_list = []\n",
        "            acc_list = []\n",
        "            for X_train,y_train in train_loader:\n",
        "                self.optimizer.zero_grad()\n",
        "                output = self.model(X_train)\n",
        "                reg_ = lamb*reg(self.model.KAN.acts_scale,self.model.KAN)\n",
        "                try:\n",
        "                    loss = self.criterion(output.squeeze(), y_train)+reg_\n",
        "                except:\n",
        "                    print(output)\n",
        "                    raise\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                loss_list.append(loss.item())\n",
        "                acc = accuracy(output,y_train)\n",
        "                acc_list.append(acc)\n",
        "                sys.stdout.write(f\"\\rEpoch {epoch+1} Loss {np.mean(loss_list):4f} acc : {np.mean(acc_list):4f} reg : {reg_:4f} stop count : {self.stop_count}\")\n",
        "        self.model.load_state_dict(self.optimal)\n",
        "    def test(self,test_loader):\n",
        "        if test_loader is None:\n",
        "            return 0,0\n",
        "        else:\n",
        "            #self.model.eval()\n",
        "            test_loss = 0\n",
        "            correct = 0\n",
        "            with torch.no_grad():\n",
        "                for data, target in test_loader:\n",
        "                    output = self.model(data)\n",
        "\n",
        "                    test_loss += self.criterion(output.squeeze(), target).item()\n",
        "                    \n",
        "                    correct += accuracy(output,target)*len(output)\n",
        "\n",
        "            print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)')\n",
        "            return test_loss,correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test set: Average loss: 4.7787, Accuracy: 137.0/300 (46%)\n",
            "Epoch 1 Loss 0.854547 acc : 0.564205 reg : 0.143961 stop count : 0\n",
            "Test set: Average loss: 2.8329, Accuracy: 197.00000023841858/300 (66%)\n",
            "Epoch 2 Loss 0.655222 acc : 0.803314 reg : 0.147836 stop count : 0\n",
            "Test set: Average loss: 2.0591, Accuracy: 256.00000047683716/300 (85%)\n",
            "Epoch 3 Loss 0.522999 acc : 0.855492 reg : 0.151723 stop count : 0\n",
            "Test set: Average loss: 1.5426, Accuracy: 269.0000002384186/300 (90%)\n",
            "Epoch 4 Loss 0.445240 acc : 0.898485 reg : 0.159091 stop count : 0\n",
            "Test set: Average loss: 1.2626, Accuracy: 272.99999952316284/300 (91%)\n",
            "Epoch 5 Loss 0.398724 acc : 0.908523 reg : 0.161038 stop count : 0\n",
            "Test set: Average loss: 1.1947, Accuracy: 277.99999952316284/300 (93%)\n",
            "Epoch 6 Loss 0.379580 acc : 0.928598 reg : 0.160288 stop count : 0\n",
            "Test set: Average loss: 1.1574, Accuracy: 276.99999952316284/300 (92%)\n",
            "Epoch 7 Loss 0.360878 acc : 0.921307 reg : 0.160668 stop count : 0\n",
            "Test set: Average loss: 1.1207, Accuracy: 279.99999952316284/300 (93%)\n",
            "Epoch 8 Loss 0.353451 acc : 0.928598 reg : 0.158235 stop count : 0\n",
            "Test set: Average loss: 1.1257, Accuracy: 280.99999952316284/300 (94%)\n",
            "Epoch 9 Loss 0.341463 acc : 0.929830 reg : 0.154135 stop count : 1\n",
            "Test set: Average loss: 1.1124, Accuracy: 280.99999952316284/300 (94%)\n",
            "Epoch 10 Loss 0.332433 acc : 0.928598 reg : 0.153711 stop count : 0\n",
            "Test set: Average loss: 1.1312, Accuracy: 280.99999952316284/300 (94%)\n",
            "Epoch 11 Loss 0.326147 acc : 0.932670 reg : 0.156279 stop count : 1\n",
            "Test set: Average loss: 1.0903, Accuracy: 280.99999952316284/300 (94%)\n",
            "Epoch 12 Loss 0.319728 acc : 0.935890 reg : 0.152456 stop count : 0\n",
            "Test set: Average loss: 1.1175, Accuracy: 282.99999952316284/300 (94%)\n",
            "Epoch 13 Loss 0.314328 acc : 0.940057 reg : 0.151270 stop count : 1\n",
            "Test set: Average loss: 1.1131, Accuracy: 280.99999952316284/300 (94%)\n",
            "Epoch 14 Loss 0.307922 acc : 0.938542 reg : 0.149571 stop count : 2\n",
            "Test set: Average loss: 1.1624, Accuracy: 277.00000047683716/300 (92%)\n",
            "Epoch 15 Loss 0.302818 acc : 0.945644 reg : 0.150546 stop count : 3\n",
            "Test set: Average loss: 1.1157, Accuracy: 280.99999952316284/300 (94%)\n",
            "Epoch 16 Loss 0.292786 acc : 0.939867 reg : 0.153950 stop count : 4\n",
            "Test set: Average loss: 1.1944, Accuracy: 277.99999952316284/300 (93%)\n",
            "Epoch 17 Loss 0.292726 acc : 0.941477 reg : 0.152123 stop count : 5\n",
            "Test set: Average loss: 1.1973, Accuracy: 276.99999952316284/300 (92%)\n",
            "Epoch 18 Loss 0.284020 acc : 0.949811 reg : 0.150037 stop count : 6\n",
            "Test set: Average loss: 1.1584, Accuracy: 278.00000047683716/300 (93%)\n",
            "Epoch 19 Loss 0.274488 acc : 0.952936 reg : 0.150209 stop count : 7\n",
            "Test set: Average loss: 1.3059, Accuracy: 273.99999952316284/300 (91%)\n",
            "Epoch 20 Loss 0.283386 acc : 0.949716 reg : 0.151924 stop count : 8\n",
            "Test set: Average loss: 1.2575, Accuracy: 280.0000011920929/300 (93%)\n",
            "Epoch 21 Loss 0.268474 acc : 0.957292 reg : 0.149299 stop count : 9\n",
            "Test set: Average loss: 1.1972, Accuracy: 277.99999952316284/300 (93%)\n",
            "Epoch 22 Loss 0.261293 acc : 0.958523 reg : 0.152738 stop count : 10\n",
            "Test set: Average loss: 1.2046, Accuracy: 280.0000011920929/300 (93%)\n",
            "Epoch 23 Loss 0.254600 acc : 0.960038 reg : 0.149027 stop count : 11\n",
            "Test set: Average loss: 1.2685, Accuracy: 279.99999952316284/300 (93%)\n",
            "Epoch 24 Loss 0.252490 acc : 0.964205 reg : 0.151070 stop count : 12\n",
            "Test set: Average loss: 1.1635, Accuracy: 281.99999952316284/300 (94%)\n",
            "Epoch 25 Loss 0.258293 acc : 0.957292 reg : 0.150345 stop count : 13\n",
            "Test set: Average loss: 1.3417, Accuracy: 275.0000011920929/300 (92%)\n",
            "Epoch 26 Loss 0.246802 acc : 0.961364 reg : 0.147824 stop count : 14\n",
            "Test set: Average loss: 1.2343, Accuracy: 279.0000011920929/300 (93%)\n",
            "Epoch 27 Loss 0.242295 acc : 0.965625 reg : 0.153239 stop count : 15\n",
            "Test set: Average loss: 1.3459, Accuracy: 276.99999952316284/300 (92%)\n",
            "Test Accuracy: 277.00\n"
          ]
        }
      ],
      "source": [
        "from kan import KAN\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.KAN = KAN([PCA_dim,PCA_dim*2-1,1])\n",
        "    def forward(self, x):\n",
        "        output = self.KAN(x)\n",
        "        output = nn.Sigmoid()(output)\n",
        "        output = torch.squeeze(output)\n",
        "        return output\n",
        "\n",
        "\n",
        "model = Model(); criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_process = Early_stop_train(model, optimizer, criterion)\n",
        "train_process.train_model(train_loader,test_loader,epochs=50,res=15,lamb=0.005)\n",
        "\n",
        "_,acc = train_process.test(test_loader)\n",
        "print(f\"Test Accuracy: {acc:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
